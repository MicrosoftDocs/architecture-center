{
    "articles": [{
            "tags": [
                "all-items",
                "alternative-choices",
                "data-flow",
                "example-code",
                "example-workload",
                "fasttrack",
                "github",
                "hpc",
                "is-deployable",
                "media",
                "pricing-calculator",
                "pricing-guidance"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/infrastructure/video-rendering.yml",
            "http_url": "/azure/architecture/example-scenario/infrastructure/video-rendering",
            "word_count": 1271,
            "read_time": "5 min read",
            "Title": "3D video rendering",
            "MetaDescription": "Use Azure Batch to manage existing Windows or Linux applications, including AutoDesk Maya and Blender, to run large-scale 3D video render jobs in Azure.",
            "category": [
                "compute"
            ],
            "image": "/azure/architecture/example-scenario/infrastructure/media/architecture-video-rendering.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\infrastructure\\media\\architecture-video-rendering.png",
            "publish_date": "7/13/2018",
            "deployable": "https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2Fmspnp%2Fsolution-architectures%2Fmaster%2Fhpc%2Fbatchcreatewithpools.json",
            "pricing_calculator": "https://azure.com/e/9ac25baf44ef49c3a6b156935ee9544c",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "Summary": "<p>3D video rendering is a time consuming process that requires a significant amount of CPU time to complete. On a single machine, the process of generating a video file from static assets can take hours or even days depending on the length and complexity of the video you are producing. Many companies will purchase either expensive high end desktop computers to perform these tasks, or invest in large render farms that they can submit jobs to. However, by taking advantage of Azure Batch, that power is available to you when you need it and shuts itself down when you don't, all without any capital investment.</p>\n<p>Batch gives you a consistent management experience and job scheduling, whether you select Windows Server or Linux compute nodes. With Batch, you can use your existing Windows or Linux applications, including AutoDesk Maya and Blender, to run large-scale render jobs in Azure.</p>",
            "Flow": {
                "FlowStep_A": "Upload input files and the applications to process those files to your Azure Storage account.",
                "FlowStep_B": "Create a Batch pool of compute nodes in your Batch account, a job to run the workload on the pool, and tasks in the job.",
                "FlowStep_C": "Download input files and the applications to Batch.",
                "FlowStep_D": "Monitor task execution.",
                "FlowStep_E": "Upload task output.",
                "FlowStep_F": "Download output files."
            },
            "sample_code": true,
            "github_url": "https://github.com/azurebigcompute/BigComputeLabs/tree/master/Azure%20Batch%20Masterclass%20Labs",
            "name": "video-rendering",
            "popularity": 209,
            "topic": "Compute"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "example-workload",
                "hpc",
                "pricing-calculator",
                "pricing-guidance"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/apps/hpc-saas.yml",
            "http_url": "/azure/architecture/example-scenario/apps/hpc-saas",
            "word_count": 1106,
            "read_time": "5 min read",
            "Title": "A computer-aided engineering service",
            "MetaDescription": "Provide a software-as-a-service (SaaS) platform for computer-aided engineering (CAE) on Azure.",
            "category": [
                "compute"
            ],
            "image": "/azure/architecture/example-scenario/apps/media/architecture-hpc-saas.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\apps\\media\\architecture-hpc-saas.png",
            "publish_date": "8/22/2018",
            "pricing_calculator": "https://azure.com/e/3cb9ccdc893f41ffbcdb00c328178ccf",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-machines/linux/sizes-hpc\">H-series virtual machines</a> are used to run compute-intensive simulations such as molecular modeling and computational fluid dynamics. The solution also takes advantage of technologies like remote direct memory access (RDMA) connectivity and InfiniBand networking.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-machines/windows/sizes-gpu\">NV-series virtual machines</a> give engineers high-end workstation functionality from a standard web browser. These virtual machines have NVIDIA Tesla M60 GPUs that support advanced rendering and can run single precision workloads.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-machines/linux/sizes-general\">General purpose virtual machines</a> running CentOS handle more traditional workloads such as web applications.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/application-gateway/overview\">Application Gateway</a> load balances the requests coming into the web servers.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/aks/intro-kubernetes\">Azure Kubernetes Service (AKS)</a> is used to run scalable workloads at a lower cost for simulations that don't require the high end capabilities of HPC or GPU virtual machines.</p>",
                "<p><a href=\"https://www.pbsworks.com/PBSProduct.aspx?n=PBS-Works-Suite&amp;c=Overview-and-Capabilities\">Altair PBS Works Suite</a> orchestrates the HPC workflow, ensuring that enough virtual machine instances are available to handle the current load. It also deallocates virtual machines when demand is lower to reduce costs.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/storage/blobs/storage-blobs-introduction\">Blob storage</a> stores files that support the scheduled jobs.</p>"
            ],
            "name": "hpc-saas",
            "popularity": 190,
            "topic": "Compute"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-ai-at-the-edge-'",
                "acom-architecture",
                "ai-at-the-edge",
                "ai-ml",
                "all-items",
                "azure-stack-edge",
                "data-flow",
                "edge-ai",
                "interactive-diagram",
                "machine-learning",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/ai-at-the-edge.md",
            "http_url": "/azure/architecture/solution-ideas/articles/ai-at-the-edge",
            "word_count": 274,
            "read_time": "2 min read",
            "Title": "AI at the Edge with Azure Stack Hub",
            "MetaDescription": "Move AI models to the edge with a solution architecture that includes Azure Stack Hub.",
            "category": [
                "ai-machine-learning",
                "hybrid"
            ],
            "image": "/azure/architecture/solution-ideas/media/ai-at-the-edge.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\ai-at-the-edge.png",
            "publish_date": "9/01/2020",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/machine-learning-studio\">Machine Learning Studio</a>: Easily build, deploy, and manage predictive analytics solutions</p>",
                "<p><a href=\"https://azure.microsoft.com/services/hdinsight\">HDInsight</a>: Provision cloud Hadoop, Spark, R Server, HBase, and Storm clusters</p>",
                "<p><a href=\"https://azure.microsoft.com/services/container-registry\">Container Registry</a>: Store and manage container images across all types of Azure deployments</p>",
                "<p><a href=\"https://azure.microsoft.com/services/kubernetes-service\">Azure Kubernetes Service (AKS)</a>: Simplify the deployment, management, and operations of Kubernetes</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage\">Storage</a>: Durable, highly available, and massively scalable cloud storage</p>",
                "<p><a href=\"https://azure.microsoft.com/overview/azure-stack\">Azure Stack Hub</a>: Build and run innovative hybrid applications across cloud boundaries</p>"
            ],
            "Summary": "<p>With the Azure AI tools and cloud platform, the next generation of AI-enabled hybrid applications can run where your data lives. With Azure Stack Hub, bring a trained AI model to the edge and integrate it with your applications for low-latency intelligence, with no tool or process changes for local applications.</p>",
            "Flow": {
                "FlowStep_A": "Data scientists train a model using Azure Machine Learning workbench and an HDInsight cluster. The model is containerized and put into an Azure Container Registry.",
                "FlowStep_B": "The model is deployed to a Kubernetes cluster on Azure Stack Hub.",
                "FlowStep_C": "End users provide data that's scored against the model.",
                "FlowStep_D": "Insights and anomalies from scoring are placed into a queue.",
                "FlowStep_E": "A function sends compliant data and anomalies to Azure Storage.",
                "FlowStep_F": "Globally relevant and compliant insights are available in the global app.",
                "FlowStep_G": "Data from edge scoring is used to improve the model."
            },
            "name": "ai-at-the-edge",
            "popularity": 173,
            "topic": "AI + Machine Learning",
            "hybrid-topic": "Apps"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-ai-at-the-edge-disconnected-'",
                "acom-architecture",
                "ai-at-the-edge",
                "all-items",
                "azure-stack-edge",
                "data-flow",
                "edge-ai",
                "interactive-diagram",
                "offline-machine-learning",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/ai-at-the-edge-disconnected.md",
            "http_url": "/azure/architecture/solution-ideas/articles/ai-at-the-edge-disconnected",
            "word_count": 289,
            "read_time": "2 min read",
            "Title": "AI at the Edge with Azure Stack Hub - disconnected",
            "MetaDescription": "Move AI models to the edge with a solution architecture that includes Azure Stack. A step-by-step workflow will help you harness the power of edge AI when disconnected from the internet.",
            "category": [
                "ai-machine-learning",
                "hybrid"
            ],
            "image": "/azure/architecture/solution-ideas/media/ai-at-the-edge-disconnected.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\ai-at-the-edge-disconnected.png",
            "publish_date": "9/01/2020",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/hdinsight\">HDInsight</a>: Provision cloud Hadoop, Spark, R Server, HBase, and Storm clusters</p>",
                "<p><a href=\"https://azure.microsoft.com/services/machine-learning-studio\">Machine Learning Studio</a>: Easily build, deploy, and manage predictive analytics solutions</p>",
                "<p><a href=\"https://azure.microsoft.com/services/virtual-machines\">Virtual Machines</a>: Provision Windows and Linux virtual machines in seconds</p>",
                "<p><a href=\"https://azure.microsoft.com/services/kubernetes-service\">Azure Kubernetes Service (AKS)</a>: Simplify the deployment, management, and operations of Kubernetes</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage\">Storage</a>: Durable, highly available, and massively scalable cloud storage</p>",
                "<p><a href=\"https://azure.microsoft.com/overview/azure-stack\">Azure Stack Hub</a>: Build and run innovative hybrid applications across cloud boundaries</p>"
            ],
            "Flow": {
                "FlowStep_A": "Data scientists train a model using Azure Machine Learning and an HDInsight cluster. The model is containerized and put in to an Azure Container Registry.",
                "FlowStep_B": "The model is deployed via steps not represented in the diagram to a Kubernetes cluster on Azure Stack Hub.",
                "FlowStep_C": "End users provide data that is scored against the model.",
                "FlowStep_D": "Insights and anomalies from scoring are placed into storage for later upload.",
                "FlowStep_E": "Globally-relevant and compliant insights are available in the global app.",
                "FlowStep_F": "Data from edge scoring is used to improve the model."
            },
            "name": "ai-at-the-edge-disconnected",
            "popularity": 133,
            "topic": "AI + Machine Learning",
            "hybrid-topic": "Apps"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "fcp",
                "github",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/cognitive-search-with-skillsets.md",
            "http_url": "/azure/architecture/solution-ideas/articles/cognitive-search-with-skillsets",
            "word_count": 892,
            "read_time": "4 min read",
            "Title": "AI enrichment with Azure Cognitive Search",
            "MetaDescription": "Learn how to use Azure Cognitive Search pre-built skills and custom extensibility to enrich large unstructured data sets into indexable structured data.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/cognitive-search-for-ai-enrichment.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\cognitive-search-for-ai-enrichment.png",
            "publish_date": "6/01/2020",
            "Summary": "<p>Large, unstructured datasets like the <a href=\"https://www.archives.gov/research/jfk/2017-release\">JFK Files</a>, which contain over 34,000 pages of documents about the CIA investigation of the 1963 JFK assassination, include typewritten and handwritten notes, photos and diagrams, and other unstructured data that standard search solutions can't parse.</p>\n<p><em>AI enrichment</em> in Azure Cognitive Search can extract and enhance searchable, indexable text from images, blobs, and other unstructured data sources like the JFK Files by using pre-trained machine learning skillsets from the Cognitive Services <a href=\"https://learn.microsoft.com/azure/cognitive-services/computer-vision/home\">Computer Vision</a> and <a href=\"https://learn.microsoft.com/azure/cognitive-services/text-analytics/overview\">Text Analytics</a> APIs. You can also create and attach <a href=\"https://learn.microsoft.com/azure/search/cognitive-search-custom-skill-interface\">custom skills</a> to add special processing for domain-specific data like CIA Cryptonyms. Azure Cognitive Search can then index and search the context.</p>\n<ul>\n<li>\n<p><em>Image processing skills</em> like <a href=\"https://learn.microsoft.com/azure/search/cognitive-search-skill-ocr\">Optical Character Recognition (OCR)</a>, <a href=\"https://learn.microsoft.com/azure/cognitive-services/computer-vision/concept-recognizing-text#read-api\">Read</a>, and <a href=\"https://learn.microsoft.com/azure/search/cognitive-search-skill-image-analysis\">image analysis</a> include object and face detection, tag and caption generation, and celebrity and landmark identification. These skills create text representations of image content, which are searchable using the query capabilities of Azure Cognitive Search.</p>\n</li>\n<li>\n<p><em>Natural language processing</em> skills like <a href=\"https://learn.microsoft.com/azure/search/cognitive-search-skill-entity-recognition\">entity recognition</a>, <a href=\"https://learn.microsoft.com/azure/search/cognitive-search-skill-language-detection\">language detection</a>, <a href=\"https://learn.microsoft.com/azure/search/cognitive-search-skill-keyphrases\">key phrase extraction</a>, and <a href=\"https://learn.microsoft.com/azure/cognitive-services/computer-vision/concept-recognizing-text\">text recognition</a> map unstructured text to searchable and filterable fields in an index.</p>\n</li>\n</ul>\n<p>This example solution uses Azure Cognitive Search AI enrichment to extract meaning from the original complex, unstructured JFK Files dataset. You can <a href=\"https://github.com/microsoft/AzureSearch_JFK_Files\">work through the project</a>, watch the process in action in an <a href=\"https://learn.microsoft.com/shows/AI-Show/Using-Cognitive-Search-to-Understand-the-JFK-Documents\">online video</a>, or explore the JFK Files with an <a href=\"https://aka.ms/jfkfiles-demo\">online demo</a>.</p>",
            "sample_code": true,
            "github_url": "https://github.com/microsoft/AzureSearch_JFK_Files",
            "name": "cognitive-search-with-skillsets",
            "popularity": 0,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "aischool",
                "all-items",
                "example-code",
                "fcp",
                "github",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/ai-for-earth.md",
            "http_url": "/azure/architecture/solution-ideas/articles/ai-for-earth",
            "word_count": 1626,
            "read_time": "7 min read",
            "Title": "AI for Earth",
            "MetaDescription": "Learn how to use the AI for Earth APIs to help build solutions for environmental problems. See other AI for Earth projects and initiatives.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/wildbook-network-diagram.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\wildbook-network-diagram.png",
            "publish_date": "6/23/2020",
            "Summary": "<p>The earth currently faces urgent and accelerating environmental challenges. Climate change, biodiversity and habitat loss, pollution, overpopulation, and food and fresh water shortages need quick and comprehensive mitigation, but can seem so overwhelming that philosopher Timothy Morton calls them <em>hyperobjects</em>, entities so vast and distributed that they're difficult to fully define or comprehend.</p>\n<p>Technology may have contributed to many of these issues, but we need technology to be able to conceptualize or solve them. Artificial intelligence (AI) is one tool that can help us both understand and potentially mitigate global environmental issues.</p>\n<p>AI approaches to environmental challenges require substantial amounts of data, computing power, specialized tools, and expertise. The Microsoft <a href=\"https://www.microsoft.com/ai/ai-for-earth\">AI for Earth</a> initiative provides people and organizations with AI and cloud tools like open data sets, cloud compute grants, open-source APIs, and education to help them address global environmental challenges.</p>\n<p>This article showcases the public Microsoft <a href=\"https://www.microsoft.com/ai/ai-for-earth-tech-resources\">AI for Earth APIs</a>, and how they can work with Azure services and resources to help provide conservation solutions.</p>",
            "sample_code": true,
            "github_url": "https://github.com/wildbookorg",
            "name": "ai-for-earth",
            "popularity": 0,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "acom-architecture",
                "all-items",
                "data-flow",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/aks-api-first.md",
            "http_url": "/azure/architecture/solution-ideas/articles/aks-api-first",
            "word_count": 303,
            "read_time": "2 min read",
            "Title": "API-first SaaS business model",
            "MetaDescription": "Adapt, evolve, and allow faster innovation to turn opportunities into strategic advantages.",
            "category": [
                "containers"
            ],
            "image": "/azure/architecture/solution-ideas/media/aks-api-first.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\aks-api-first.png",
            "publish_date": "4/17/2020",
            "Flow": {
                "FlowStep_A": "API is defined by API developers and published via the API Management portal",
                "FlowStep_B": "Application developers define the microservices and associated logic and deploy to Kubernetes",
                "FlowStep_C": "API users (internal and/or external) use the API developer portal to learn about the API and use them in their applications",
                "FlowStep_D": "Applications access APIs via the API Gateway",
                "FlowStep_E": "API Gateway, after ensuring the API request meets security and other policies e.g. throttling, forwards the request to service running in Kubernetes"
            },
            "name": "aks-api-first",
            "popularity": 0,
            "topic": "Containers"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-adding-a-modern-web-and-mobile-frontend-to-a-legacy-claims-processing-application-'",
                "acom-architecture",
                "all-items",
                "cloud-innovation",
                "cloud-migration",
                "data-flow",
                "interactive-diagram",
                "lift-and-shift-cloud-strategy",
                "lift-and-shift-solution",
                "lift-and-shift-strategy",
                "line-of-business-app",
                "lob-app",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/adding-a-modern-web-and-mobile-frontend-to-a-legacy-claims-processing-application.md",
            "http_url": "/azure/architecture/solution-ideas/articles/adding-a-modern-web-and-mobile-frontend-to-a-legacy-claims-processing-application",
            "word_count": 213,
            "read_time": "1 min read",
            "Title": "Adding a mobile front-end to a legacy app",
            "MetaDescription": "The solution demonstrates modernizing an existing application by consolidating data from multiple business systems into one place and surfacing it through web and mobile frontends. This is targeted at improving employee productivity and to enable faster decision making.",
            "category": [
                "migration"
            ],
            "image": "/azure/architecture/solution-ideas/media/adding-a-modern-web-and-mobile-frontend-to-a-legacy-claims-processing-application.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\adding-a-modern-web-and-mobile-frontend-to-a-legacy-claims-processing-application.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p>Azure <a href=\"https://azure.microsoft.com/services/virtual-machines\">Virtual Machines</a> lets you deploy a Windows Server or Linux image in the cloud. You can select images from a marketplace or use your own customized images.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/sql-database\">Azure SQL Database</a> is a relational database service that lets you rapidly create, extend, and scale relational applications into the cloud.</p>"
            ],
            "Flow": {
                "FlowStep_A": "Customer's mobile app authenticates via Azure Active Directory B2C",
                "FlowStep_B": "Customer's mobile app connects to the back-end web service that aggregates data from different systems using asynchronous connection",
                "FlowStep_C": "Web application connects to SQL database",
                "FlowStep_D": "Power BI connects to SQL database and SharePoint",
                "FlowStep_E": "Logic app pulls data from CRM (Salesforce)'''",
                "FlowStep_F": "Logic app connects to SAP system (on-premises or in the cloud)",
                "FlowStep_G": "Employee mobile app connects to the logic app that orchestrates the business process",
                "FlowStep_H": "Employee mobile app authenticates via Azure Active Directory"
            },
            "name": "adding-a-modern-web-and-mobile-frontend-to-a-legacy-claims-processing-application",
            "popularity": 128,
            "topic": "Migration"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-advanced-analytics-on-big-data-'",
                "acom-architecture",
                "all-items",
                "big-data-architecture",
                "data-flow",
                "interactive-diagram",
                "pricing-calculator",
                "pricing-guidance",
                "real-time-analytics",
                "real-time-data-analytics",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/advanced-analytics-on-big-data.md",
            "http_url": "/azure/architecture/solution-ideas/articles/advanced-analytics-on-big-data",
            "word_count": 431,
            "read_time": "2 min read",
            "Title": "Advanced Analytics Architecture",
            "MetaDescription": "Get near real-time data analytics on streaming services. This big data architecture allows you to combine any data at any scale with custom machine learning.",
            "category": [
                "analytics",
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/advanced-analytics-on-big-data.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\advanced-analytics-on-big-data.png",
            "publish_date": "12/16/2019",
            "pricing_calculator": "https://azure.com/e/96162a623bda4911bb8f631e317affc6",
            "pricing_guidance": "pricing-calculator",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/synapse-analytics\">Azure Synapse Analytics</a> is the fast, flexible and trusted cloud data warehouse that lets you scale, compute and store elastically and independently, with a massively parallel processing architecture.</p>",
                "<p>Azure <a href=\"https://azure.microsoft.com/services/data-factory\">Data Factory</a> is a hybrid data integration service that allows you to create, schedule and orchestrate your ETL/ELT workflows.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage/blobs\">Azure Blob storage</a> is a Massively scalable object storage for any type of unstructured data-images, videos, audio, documents, and more-easily and cost-effectively.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/databricks\">Azure Databricks</a> is a fast, easy, and collaborative Apache Spark-based analytics platform.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cosmos-db\">Azure Cosmos DB</a> is a globally distributed, multi-model database service. Learn how to replicate your data across any number of Azure regions and scale your throughput independent from your storage.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/analysis-services\">Azure Analysis Services</a> is an enterprise grade analytics as a service that lets you govern, deploy, test, and deliver your BI solution with confidence.</p>",
                "<p><a href=\"https://powerbi.microsoft.com\">Power BI</a> is a suite of business analytics tools that deliver insights throughout your organization. Connect to hundreds of data sources, simplify data prep, and drive ad hoc analysis. Produce beautiful reports, then publish them for your organization to consume on the web and across mobile devices.</p>"
            ],
            "Summary": "<p>Transform your data into actionable insights using the best-in-class machine learning tools. This architecture allows you to combine any data at any scale, and to build and deploy custom machine learning models at scale.</p>",
            "Flow": {
                "FlowStep_A": "Bring together all your structured, unstructured and semi-structured data (logs, files, and media) using Azure Data Factory to Azure Data Lake Storage.",
                "FlowStep_B": "Use Azure Databricks to clean and transform the structureless datasets and combine them with structured data from operational databases or data warehouses.",
                "FlowStep_C": "Use scalable machine learning/deep learning techniques, to derive deeper insights from this data using Python, R or Scala, with inbuilt notebook experiences in Azure Databricks.",
                "FlowStep_D": "Leverage native connectors between Azure Databricks and Azure Synapse Analytics to access and move data at scale.",
                "FlowStep_E": "Power users take advantage of the inbuilt capabilities of Azure Databricks to perform root cause determination and raw data analysis.",
                "FlowStep_F": "Query and report on data in [Power BI](/azure/analysis-services/analysis-services-connect-pbi).",
                "FlowStep_G": "Take the insights from Azure Databricks to Azure Cosmos DB to make them accessible through web and mobile apps."
            },
            "name": "advanced-analytics-on-big-data",
            "popularity": 229,
            "topic": "Analytics"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-anomaly-detector-process-'",
                "acom-architecture",
                "all-items",
                "anomaly-detection-model",
                "anomaly-detection-process",
                "anomaly-detector",
                "data-flow",
                "interactive-diagram",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/anomaly-detector-process.md",
            "http_url": "/azure/architecture/solution-ideas/articles/anomaly-detector-process",
            "word_count": 172,
            "read_time": "1 min read",
            "Title": "Anomaly Detector Process",
            "MetaDescription": "Learn more about Anomaly Detector with a step-by-step flowchart that details the process. See how anomaly detection models are selected with time-series data.",
            "category": [
                "analytics",
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/anomaly-detector-process.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\anomaly-detector-process.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/service-bus\">Service Bus</a>: Reliable cloud messaging as a service (MaaS) and simple hybrid integration</p>",
                "<p><a href=\"https://azure.microsoft.com/services/databricks\">Azure Databricks</a>: Fast, easy, and collaborative Apache Spark\u2013based analytics service</p>",
                "<p><a href=\"https://powerbi.microsoft.com\">Power BI</a>: Interactive data visualization BI tools</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage\">Storage Accounts</a>: Durable, highly available, and massively scalable cloud storage</p>"
            ],
            "Summary": "",
            "Flow": {
                "FlowStep_A": "Ingests data from the various stores that contain raw data to be monitored by Anomaly Detector.",
                "FlowStep_B": "Aggregates, samples, and computes the raw data to generate the time series, or calls the Anomaly Detector API directly if the time series are already prepared and gets a response with the detection results.",
                "FlowStep_C": "Queues the anomaly related meta data.",
                "FlowStep_D": "Based on the anomaly related meta data, calls the customized alerting service.",
                "FlowStep_E": "Stores the anomaly detection meta data.",
                "FlowStep_F": "Visualizes the results of the time series anomaly detection."
            },
            "name": "anomaly-detector-process",
            "popularity": 172,
            "topic": "Analytics"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-application-integration-using-event-grid-'",
                "acom-architecture",
                "all-items",
                "application-development",
                "azure",
                "event-grid",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/application-integration-using-event-grid.md",
            "http_url": "/azure/architecture/solution-ideas/articles/application-integration-using-event-grid",
            "word_count": 71,
            "read_time": "1 min read",
            "Title": "Application integration using Event Grid",
            "MetaDescription": "Event Grid connects your app with other services. For example, create an application topic to send your app's event data to Event Grid and take advantage of its reliable delivery, advanced routing, and direct integration with Azure. Alternatively, you can use Event Grid with Logic Apps to process data anywhere, without writing code.",
            "category": [
                "analytics"
            ],
            "image": "/azure/architecture/solution-ideas/media/application-integration-using-event-grid.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\application-integration-using-event-grid.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Event Grid connects your app with other services. For example, create an application topic to send your app's event data to Event Grid and take advantage of its reliable delivery, advanced routing, and direct integration with Azure. Alternatively, you can use Event Grid with Logic Apps to process data anywhere, without writing code.</p>",
            "name": "application-integration-using-event-grid",
            "popularity": 169,
            "topic": "Analytics"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-scalable-ecommerce-web-app-'",
                "acom-architecture",
                "all-items",
                "architect-scalable-e-commerce-web-app",
                "data-flow",
                "ecommerce",
                "interactive-diagram",
                "process-order-payment",
                "scalability",
                "search-for-products",
                "solution-idea",
                "submits-order",
                "web-app",
                "web-apps"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/scalable-ecommerce-web-app.md",
            "http_url": "/azure/architecture/solution-ideas/articles/scalable-ecommerce-web-app",
            "word_count": 209,
            "read_time": "1 min read",
            "Title": "Architect scalable e-commerce web app",
            "MetaDescription": "The e-commerce website includes simple order processing workflows with the help of Azure services. Using Azure Functions and Web Apps, developers can focus on building personalized experiences and let Azure take care of the infrastructure.",
            "category": [
                "web"
            ],
            "image": "/azure/architecture/solution-ideas/media/scalable-ecommerce-web-app.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\scalable-ecommerce-web-app.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/app-service/web\">Web Apps</a>: An App Service Web App runs in a single region, accessible to web and mobile browsers</p>",
                "<p><a href=\"https://azure.microsoft.com/services/sql-database\">Azure SQL Database</a>: Managed, intelligent SQL in the cloud</p>",
                "<p><a href=\"https://azure.microsoft.com/services/functions\">Azure Functions</a>: Process events with serverless code</p>",
                "<p>Application Insights: Detect, triage, and diagnose issues in your web apps and services</p>"
            ],
            "Flow": {
                "FlowStep_A": "User accesses the web app in browser and signs in.",
                "FlowStep_B": "Browser pulls static resources such as images from Azure Content Delivery Network.",
                "FlowStep_C": "User searches for products and queries SQL database.",
                "FlowStep_D": "Web site pulls product catalog from database.",
                "FlowStep_E": "Web app pulls product images from Blob Storage.",
                "FlowStep_F": "Page output is cached in Azure Cache for Redis for better performance.",
                "FlowStep_G": "User submits order and order is placed in the queue.",
                "FlowStep_H": "Azure Functions processes order payment.",
                "FlowStep_I": "Azure Functions makes payment to third party and records payment in SQL database."
            },
            "name": "scalable-ecommerce-web-app",
            "popularity": 214,
            "topic": "Web"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-backup-archive-on-premises-'",
                "acom-architecture",
                "all-items",
                "bcdr",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/backup-archive-on-premises.md",
            "http_url": "/azure/architecture/solution-ideas/articles/backup-archive-on-premises",
            "word_count": 147,
            "read_time": "1 min read",
            "Title": "Archive on-premises data to cloud",
            "MetaDescription": "Archive your on-premises data to Azure Blob storage.",
            "category": [
                "storage",
                "hybrid"
            ],
            "image": "/azure/architecture/solution-ideas/media/backup-archive-cloud-application.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\backup-archive-cloud-application.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p>Azure <a href=\"https://azure.microsoft.com/services/storsimple\">StorSimple</a> appliance running on-premises that can tier data to Azure Blob storage (both hot and cool tier). <a href=\"https://azure.microsoft.com/services/storsimple\">StorSimple</a> can be used to archive data from on-premises to Azure.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage/blobs\">Blob Storage</a>: A cool or archive tier on Azure Blob storage is used to back up data that's less frequently accessed, while a hot tier is used to store data that's frequently accessed.</p>"
            ],
            "name": "backup-archive-on-premises",
            "popularity": 202,
            "topic": "Storage",
            "hybrid-topic": "Data"
        },
        {
            "tags": [
                "all-items",
                "data-flow",
                "example-workload",
                "fcp"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/iot/attestation-provisioning.md",
            "http_url": "/azure/architecture/example-scenario/iot/attestation-provisioning",
            "word_count": 459,
            "read_time": "3 min read",
            "Title": "Attestation, authentication, and provisioning",
            "MetaDescription": "Learn about how devices confirm their identity with, authenticate with, and can be provisioned within Azure IoT Hubs.",
            "category": [
                "iot"
            ],
            "image": "/azure/architecture/example-scenario/iot/media/late-binding-with-dps.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\iot\\media\\late-binding-with-dps.png",
            "publish_date": "8/21/2020",
            "Flow": {
                "FlowStep_A": "The solution developer links the Test and Production IoT clouds to the provisioning service.",
                "FlowStep_B": "The device implements the DPS protocol to find the IoT Hub if it's no longer provisioned. The device is initially provisioned to the Test environment.",
                "FlowStep_C": "Since the device is registered with the Test environment, it connects there and testing occurs.",
                "FlowStep_D": "The developer re-provisions the device to the Production environment and removes it from the Test hub. The Test hub rejects the device the next time it reconnects.",
                "FlowStep_E": "The device connects and re-negotiates the provisioning flow. DPS now directs the device to the Production environment, and the device connects and authenticates there."
            },
            "name": "attestation-provisioning",
            "popularity": 0,
            "topic": "Internet of Things"
        },
        {
            "tags": [
                "acom-architecture",
                "all-items",
                "data-flow",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/auditing-and-risk-compliance.md",
            "http_url": "/azure/architecture/solution-ideas/articles/auditing-and-risk-compliance",
            "word_count": 330,
            "read_time": "2 min read",
            "Title": "Auditing, risk, and compliance management",
            "MetaDescription": "Developers could use knowledge mining to help attorneys quickly identify entities of importance from discovery documents and flag important ideas across documents",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/knowledge-mining-auditing-and-risk-compliance.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\knowledge-mining-auditing-and-risk-compliance.png",
            "publish_date": "12/16/2019",
            "Flow": {
                "FlowStep_A": "This content is enriched by using key phrase extraction, language detection, language translation,entity extraction (organizations and people) and custom models to identify certain regulatory obligations and custom models to identify specific legal terms and clauses",
                "FlowStep_B": "And finally, the user can index data in a searchable internal application or use the data for a searchable web application for financial risks"
            },
            "name": "auditing-and-risk-compliance",
            "popularity": 0,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "all-items",
                "data-flow",
                "example-code",
                "github",
                "pricing-guidance",
                "reference-architecture",
                "seodec18",
                "sql"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/data/enterprise-bi-adf.yml",
            "http_url": "/azure/architecture/reference-architectures/data/enterprise-bi-adf",
            "word_count": 3077,
            "read_time": "13 min read",
            "Title": "Automated enterprise BI",
            "MetaDescription": "Automate an extract, load, and transform (ELT) workflow in Azure using Azure Data Factory with Azure Synapse Analytics.",
            "category": [
                "analytics",
                "databases",
                "integration"
            ],
            "image": "/azure/architecture/reference-architectures/data/images/enterprise-bi-adf.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\data\\images\\enterprise-bi-adf.png",
            "publish_date": "6/03/2020",
            "pricing_guidance": "pricing-for-azure-analysis-services-depends-on-the-tier.-the-reference-implementation-of-this-architecture-uses-the-**developer**-tier,-which-is-recommended-for-evaluation,-development,-and-test-scenarios.-other-tiers-include,-the-**basic**-tier,-which-is-recommended-for-small-production-environment;-the-**standard**-tier-for-mission-critical-production-applications.-for-more-information,-see-[the-right-tier-when-you-need-it](-azure-analysis-services-analysis-services-overview#the-right-tier-when-you-need-it).",
            "Summary": "<p>This reference architecture shows how to perform incremental loading in an <a extract-load-and-transform-elt\">extract, load, and transform (ELT)</a> pipeline. It uses Azure Data Factory to automate the ELT pipeline. The pipeline incrementally moves the latest OLTP data from an on-premises SQL Server database into Azure Synapse. Transactional data is transformed into a tabular model for analysis.</p>\n<p><img alt=\"GitHub logo\" src=\"https://learn.microsoft.com/azure/architecture/_images/github.png\" /> A reference implementation for this architecture is available on <a href=\"https://github.com/mspnp/azure-data-factory-sqldw-elt-pipeline\">GitHub</a>.</p>\n<p><img alt=\"Architecture diagram for automated enterprise BI with Azure Synapse and Azure Data Factory\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/data/images/enterprise-bi-adf.png\" /></p>\n<p>This architecture builds on the one shown in <a >Enterprise BI with Azure Synapse</a>, but adds some features that are important for enterprise data warehousing scenarios.</p>\n<ul>\n<li>Automation of the pipeline using Data Factory.</li>\n<li>Incremental loading.</li>\n<li>Integrating multiple data sources.</li>\n<li>Loading binary data such as geospatial data and images.</li>\n</ul>",
            "Flow": {
                "FlowStep_A": "For each table in the source database, track the cutoff time when the last ELT job ran. Store this information in the data warehouse. (On initial setup, all times are set to '1-1-1900'.)",
                "FlowStep_B": "During the data export step, the cutoff time is passed as a parameter to a set of stored procedures in the source database. These stored procedures query for any records that were changed or created after the cutoff time. For the Sales fact table, the `LastEditedWhen` column is used. For the dimension data, system-versioned temporal tables are used.",
                "FlowStep_C": "When the data migration is complete, update the table that stores the cutoff times."
            },
            "sample_code": true,
            "github_url": "https://github.com/mspnp/azure-data-factory-sqldw-elt-pipeline/blob/master/azure/sqldw_scripts/citypopulation/%5BIntegration%5D.%5BMigrateExternalCityPopulationData%5D.sql",
            "code_languages": [
                "sql"
            ],
            "name": "enterprise-bi-adf",
            "popularity": 232,
            "topic": "Analytics"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "example-workload",
                "fcp",
                "github",
                "pricing-guidance"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/aadsec/azure-ad-security.md",
            "http_url": "/azure/architecture/example-scenario/aadsec/azure-ad-security",
            "word_count": 2174,
            "read_time": "9 min read",
            "Title": "Azure Active Directory IDaaS in Security Operations",
            "MetaDescription": "Learn how security operations teams can use Azure Active Directory identity and access features in an adaptive, integrated zero-trust security architecture.",
            "category": [
                "security"
            ],
            "image": "/azure/architecture/example-scenario/aadsec/media/architecture.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\aadsec\\media\\architecture.png",
            "publish_date": "5/20/2020",
            "pricing_guidance": "pricing",
            "Summary": "<p>This architecture shows how Security Operations Center (SOC) teams can incorporate Azure Active Directory (Azure AD) identity and access capabilities into an overall integrated and layered <em>zero-trust</em> security strategy.</p>\n<p>Network security dominated SOC operations when all services and devices were contained on managed networks in organizations. However, <a href=\"https://www.gartner.com/en/newsroom/press-releases/2019-04-02-gartner-forecasts-worldwide-public-cloud-revenue-to-g\">Gartner</a> predicts that through 2022, the market size of cloud services will grow at a rate nearly three times that of overall IT services. As more companies embrace cloud computing, there's a shift toward treating <a href=\"https://learn.microsoft.com/azure/security/fundamentals/identity-management-best-practices#treat-identity-as-the-primary-security-perimeter\">user identity</a> as the primary security boundary.</p>\n<p>Securing identities in the cloud is a high priority.</p>\n<ul>\n<li>\n<p>Verizon's <a href=\"https://enterprise.verizon.com/resources/reports/dbir/2020/summary-of-findings/\">2020 data breach investigations report</a> stated that 37% involved use of stolen credentials, and 22% of data breaches involved phishing.</p>\n</li>\n<li>\n<p>A 2019 IBM <a href=\"https://www.all-about-security.de/fileadmin/micropages/Fachartikel_28/2019_Cost_of_a_Data_Breach_Report_final.pdf\">study of data breach incidents</a> reported that the average global cost of a data breach was $3.9M, with the US average cost closer to $8.2M.</p>\n</li>\n<li>\n<p>The <a href=\"https://www.microsoft.com/security/blog/2019/02/28/microsoft-security-intelligence-report-volume-24-is-now-available/\">Microsoft 2019 security intelligence report</a> reported that phishing attacks increased by a margin of 250% between January and December of 2018.</p>\n</li>\n</ul>\n<p>The <a href=\"https://www.microsoft.com/security/business/zero-trust\">zero trust security model</a> treats all hosts as if they're internet-facing, and considers the entire network to be potentially compromised and hostile. This approach focuses on building strong authentication, authorization, and encryption, while also providing compartmentalized access and better operational agility.</p>\n<p>Gartner promotes an <a href=\"https://www.gartner.com/smarterwithgartner/build-adaptive-security-architecture-into-your-organization/\">adaptive security architecture</a> that replaces an incident response-based strategy with a <em>prevent-detect-respond-predict</em> model. Adaptive security combines access control, behavioral monitoring, usage management, and discovery with continuous monitoring and analysis.</p>\n<p>The <a href=\"https://gallery.technet.microsoft.com/Cybersecurity-Reference-883fb54c\">Microsoft Cybersecurity Reference Architecture (MCRA)</a> describes Microsoft's cybersecurity capabilities and how they integrate with existing security architectures, including cloud and hybrid environments, that use Azure AD for <em>Identity-as-a-Service (IDaaS)</em>.</p>\n<p>This article advances the zero-trust, adaptive security approach to IDaaS, emphasizing components available on the Azure AD platform.</p>",
            "sample_code": true,
            "github_url": "https://github.com/MarkSimos/MicrosoftSecurity/blob/master/Azure%20Security%20Compass%201.1/AzureSecurityCompassIndex.md",
            "name": "azure-ad-security",
            "popularity": 0,
            "topic": "Security"
        },
        {
            "tags": [
                "all-items",
                "fcp",
                "reference-architecture",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "hybrid/arc-hybrid-kubernetes.md",
            "http_url": "/azure/architecture/hybrid/arc-hybrid-kubernetes",
            "word_count": 1952,
            "read_time": "8 min read",
            "Title": "Azure Arc hybrid management and deployment for Kubernetes clusters",
            "MetaDescription": "Using Azure Arc to register Kubernetes clusters hosted outside of Azure, and using Azure tools to manage these clusters along with clusters hosted in Azure Kubernetes Service.",
            "category": [
                "hybrid",
                "management-and-governance"
            ],
            "image": "/azure/architecture/hybrid/images/arc-hybrid-kubernetes.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\hybrid\\images\\arc-hybrid-kubernetes.png",
            "publish_date": "7/23/2020",
            "Summary": "<p>This reference architecture demonstrates how Azure Arc extends Kubernetes cluster management and configuration across customer data centers, edge locations, and multiple cloud environments. You can use Azure Arc to register Kubernetes clusters hosted outside of Microsoft Azure, and use Azure tools to manage these clusters alongside clusters hosted in Azure Kubernetes Service (AKS).\n<img alt=\"An Azure Arc for Kubernetes topology diagram.\" src=\"https://learn.microsoft.com/azure/architecture/hybrid/images/arc-hybrid-kubernetes.png\" /></p>\n<p><em>Download a <a href=\"https://arch-center.azureedge.net/arc-hybrid-kubernetes.vsdx\">Visio file</a> of this architecture.</em></p>\n<p>Typical uses for this architecture include:</p>\n<ul>\n<li>Managing on-premises Kubernetes clusters alongside clusters hosted in AKS for inventory, grouping, and tagging.</li>\n<li>Monitoring Kubernetes clusters across hybrid environments using Azure Monitor.</li>\n<li>Deploying and enforcing policies for Kubernetes clusters across hybrid environments using Azure Policy.</li>\n<li>Deploying and enforcing GitOps using Azure Policy.</li>\n</ul>",
            "visio_diagram": "https://arch-center.azureedge.net/arc-hybrid-kubernetes.vsdx",
            "name": "arc-hybrid-kubernetes",
            "popularity": 0,
            "topic": "Management and Governance",
            "hybrid-topic": "Management"
        },
        {
            "tags": [
                "all-items",
                "fcp",
                "reference-architecture",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "hybrid/azure-update-mgmt.md",
            "http_url": "/azure/architecture/hybrid/azure-update-mgmt",
            "word_count": 3789,
            "read_time": "14 min read",
            "Title": "Azure Automation Update Management",
            "MetaDescription": "Manage operating system updates with Update Management in Azure Automation",
            "category": [
                "hybrid",
                "management-and-governance",
                "networking"
            ],
            "image": "/azure/architecture/hybrid/images/azure-update-mgmt.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\hybrid\\images\\azure-update-mgmt.png",
            "publish_date": "7/16/2020",
            "Summary": "<p>This reference architecture illustrates how to design a hybrid update management solution to manage updates on both Microsoft Azure and on-premises Windows and Linux computers.</p>\n<p><img alt=\"Azure Update management is configuration component of Azure Automation. Windows and Linux computers, both in Azure and on-premises, send assessment information about missing updates to the Log Analytics workspace. Azure Automation then uses that information to create a schedule for automatic deployment of the missing updates.\" src=\"https://learn.microsoft.com/azure/architecture/hybrid/images/azure-update-mgmt.png\" /></p>\n<p><em>Download a <a href=\"https://arch-center.azureedge.net/azure-update-mgmt.vsdx\">Visio file</a> of this architecture.</em></p>\n<p>Typical uses for this architecture include:</p>\n<ul>\n<li>Managing updates across on-premises and in Azure using the Update Management component of Automation Account.</li>\n<li>Using scheduled deployments to orchestrate the installation of updates within a defined maintenance window.</li>\n</ul>",
            "visio_diagram": "https://arch-center.azureedge.net/azure-update-mgmt.vsdx",
            "name": "azure-update-mgmt",
            "popularity": 0,
            "topic": "Management and Governance",
            "hybrid-topic": "Management"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "fcp",
                "powershell",
                "reference-architecture",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "hybrid/azure-automation-hybrid.md",
            "http_url": "/azure/architecture/hybrid/azure-automation-hybrid",
            "word_count": 3509,
            "read_time": "13 min read",
            "Title": "Azure Automation in a hybrid environment",
            "MetaDescription": "Azure Automation leveraged for both on-premises and cloud environments",
            "category": [
                "hybrid",
                "management-and-governance"
            ],
            "image": "/azure/architecture/hybrid/images/azure-automation-hybrid.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\hybrid\\images\\azure-automation-hybrid.png",
            "publish_date": "7/23/2020",
            "Summary": "<p>This reference architecture illustrates how to extend automation to on-premises or other cloud providers. It describes the services that must be deployed in Azure to provide automated management and configuration across on-premises or other cloud providers. The same architecture can be applied on Azure virtual machines (VMs) that reside behind a firewall, with outbound connectivity over the 443 TCP port.</p>\n<p><img alt=\"Azure Automation in a hybrid environment\" src=\"https://learn.microsoft.com/azure/architecture/hybrid/images/azure-automation-hybrid.png\" /></p>\n<p><em>Download a <a href=\"https://arch-center.azureedge.net/azure-automation-hybrid.vsdx\">Visio file</a> of this architecture.</em></p>\n<p>Typical uses for this architecture include:</p>\n<ul>\n<li>Automated management and configuration across Azure, on-premises, or other cloud providers.  </li>\n<li>Automation of Azure virtual machines (VMs) that reside behind a firewall, with outbound connectivity over the 443 TCP port.</li>\n</ul>",
            "visio_diagram": "https://arch-center.azureedge.net/azure-automation-hybrid.vsdx",
            "code_languages": [
                "powershell"
            ],
            "sample_code": true,
            "name": "azure-automation-hybrid",
            "popularity": 0,
            "topic": "Management and Governance",
            "hybrid-topic": "Management"
        },
        {
            "tags": [
                "all-items",
                "example-workload"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/firewalls/index.md",
            "http_url": "/azure/architecture/example-scenario/firewalls",
            "word_count": 1521,
            "read_time": "7 min read",
            "Title": "Azure Firewall Architecture Guide",
            "MetaDescription": "Use proven customer engagement practices to design firewalls and proxies in Azure for traditional infrastructure workloads.",
            "category": [
                "networking"
            ],
            "image": "/azure/architecture/example-scenario/firewalls/images/standard-lb-inbound.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\firewalls\\images\\standard-lb-inbound.png",
            "publish_date": "5/15/2020",
            "Summary": "<p>The cloud is changing the way infrastructure is designed, including the design of firewalls as the network is not physical or in virtual LANs anymore. Not all features of a physical network are available in a virtual network (VNet). This includes the use of floating IP addresses or broadcast traffic and that influences the implementation of HA architectures. Load balancers for <em>Network Virtual Appliances (NVAs)</em> can/must be implemented in a certain way to achieve a highly available (HA) architecture within a virtual network. This guide presents a structured approach for designing HA firewalls (FWs) in Azure using third-party virtual appliances.</p>",
            "name": "firewalls",
            "popularity": 0,
            "topic": "Networking"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "fcp",
                "github",
                "reference-architecture",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "hybrid/azure-functions-hybrid.md",
            "http_url": "/azure/architecture/hybrid/azure-functions-hybrid",
            "word_count": 1266,
            "read_time": "5 min read",
            "Title": "Azure Functions in a hybrid environment",
            "MetaDescription": "Azure Functions being utilized from on-premises virtual machines",
            "category": [
                "hybrid",
                "web"
            ],
            "image": "/azure/architecture/hybrid/images/azure-functions-hybrid.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\hybrid\\images\\azure-functions-hybrid.png",
            "publish_date": "6/29/2020",
            "Summary": "<p>This reference architecture illustrates multiple local branches of an organization that's spread out geographically. Each location is using a Microsoft Azure function app that's configured with the Premium plan in a nearby cloud region. The developers in this architecture are monitoring all the Azure function apps by using Azure Monitor as a single pane of glass.</p>\n<p><img alt=\"The diagram illustrates multiple local virtual machines (VMs) that are connected to Azure Functions in different regions. Developers are monitoring their function apps by using Azure Monitor.\" src=\"https://learn.microsoft.com/azure/architecture/hybrid/images/azure-functions-hybrid.png\" /></p>\n<p><em>Download a <a href=\"https://arch-center.azureedge.net/azure-functions-hybrid.vsdx\">Visio file</a> of this architecture.</em></p>\n<p>Typical uses for this architecture include:</p>\n<ul>\n<li>Organizations with many physical locations that are connected to a virtual network in Azure to communicate with Azure Functions.</li>\n<li>High-growth workloads that are using Azure Functions locally and maintaining the option to use Azure for any unexpected bursts in work.</li>\n</ul>",
            "sample_code": true,
            "github_url": "https://github.com/azure/azure-functions-core-tools",
            "visio_diagram": "https://arch-center.azureedge.net/azure-functions-hybrid.vsdx",
            "name": "azure-functions-hybrid",
            "popularity": 0,
            "topic": "Web",
            "hybrid-topic": "Apps"
        },
        {
            "tags": [
                "all-items",
                "data-flow",
                "example-code",
                "github",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/iot.yml",
            "http_url": "/azure/architecture/reference-architectures/iot",
            "word_count": 2920,
            "read_time": "12 min read",
            "Title": "Azure IoT reference architecture",
            "MetaDescription": "Recommended architecture for IoT applications on Azure using PaaS (platform-as-a-service) components",
            "category": [
                "iot",
                "featured"
            ],
            "image": "/azure/architecture/reference-architectures/_images/iot-refarch.svg",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\_images\\iot-refarch.svg",
            "publish_date": "9/10/2020",
            "Summary": "<p>This reference architecture shows a recommended architecture for IoT applications on Azure using PaaS (platform-as-a-service) components.</p>\n<p><img alt=\"Diagram of the architecture\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/_images/iot-refarch.svg\" /></p>\n<p>IoT applications can be described as <strong>things</strong> (devices) sending data that generates <strong>insights</strong>. These insights generate <strong>actions</strong> to improve a business or process. An example is an engine (the thing) sending temperature data. This data is used to evaluate whether the engine is performing as expected (the insight). The insight is used to proactively prioritize the maintenance schedule for the engine (the action).</p>\n<p>This reference architecture uses Azure PaaS (platform-as-a-service) components. Another recommended option for building IoT solutions on Azure is:</p>\n<ul>\n<li><a href=\"https://learn.microsoft.com/azure/iot-central/\">Azure IoT Central</a>. IoT Central is a fully managed SaaS (software-as-a-service) solution. It abstracts the technical choices and lets you focus on your solution exclusively. This simplicity comes with a tradeoff in being less customizable than a PaaS-based solution.</li>\n</ul>\n<p>At a high level, there are two ways to process telemetry data, hot path and cold path. The difference has to do with requirements for latency and data access.</p>\n<ul>\n<li>The <strong>hot path</strong> analyzes data in near-real-time, as it arrives. In the hot path, telemetry must be processed with very low latency. The hot path is typically implemented using a stream processing engine. The output may trigger an alert, or be written to a structured format that can be queried using analytical tools.</li>\n<li>The <strong>cold path</strong> performs batch processing at longer intervals (hourly or daily). The cold path typically operates over large volumes of data, but the results don't need to be as timely as the hot path. In the cold path, raw telemetry is captured and then fed into a batch process.</li>\n</ul>",
            "Flow": {
                "FlowStep_A": ""
            },
            "sample_code": true,
            "github_url": "https://github.com/mspnp/iot-guidance",
            "name": "iot",
            "popularity": 234,
            "topic": "Internet of Things"
        },
        {
            "tags": [
                "all-items",
                "cse",
                "data-flow",
                "example-workload",
                "fcp"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/mlops/aml-decision-tree.md",
            "http_url": "/azure/architecture/example-scenario/mlops/aml-decision-tree",
            "word_count": 1602,
            "read_time": "6 min read",
            "Title": "Azure Machine Learning decision guide for optimal tool selection",
            "MetaDescription": "How to choose the best services for building an end-to-end machine learning pipeline from experimentation to deployment.",
            "category": [
                "developer-tools",
                "hybrid"
            ],
            "image": "/azure/architecture/example-scenario/mlops/media/dt-no-code-option.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\mlops\\media\\dt-no-code-option.png",
            "publish_date": "7/07/2020",
            "Summary": "<p>Microsoft Azure offers a myriad of services and capabilities. Building an end-to-end machine learning pipeline from experimentation to deployment often requires bringing together a set of services from across Azure. While it may be possible to have one pipeline do it all, there are tradeoffs when you don't use the services for what they're best at.</p>\n<p>So, then you have to ask the question: When is it worth it to adopt each service for your use case? The answer often depends on different details that are not necessarily related to the functional requirements. The main factors are:</p>\n<ul>\n<li>\n<p>The skillsets on your team.</p>\n</li>\n<li>\n<p>How the Azure service plugs into your existing architecture.</p>\n</li>\n<li>\n<p>The maintainability of the solution that you build using the service.</p>\n</li>\n<li>\n<p>The cost of these services at scale.</p>\n</li>\n</ul>\n<p>This document focuses on Azure services that you can use to support data or machine learning workloads. While not exhaustive, this document covers the most popular Azure service options for supporting the end-to-end workflow:</p>\n<ol>\n<li>\n<p>Experimentation</p>\n</li>\n<li>\n<p>Overall Orchestration/Scheduling</p>\n</li>\n<li>\n<p>Data Transfer</p>\n</li>\n<li>\n<p>Data Transformation</p>\n</li>\n<li>\n<p>Model Training</p>\n</li>\n<li>\n<p>Model Deployment</p>\n</li>\n<li>\n<p>Monitoring</p>\n</li>\n</ol>",
            "Flow": {
                "FlowStep_A": "Experimentation",
                "FlowStep_B": "Overall Orchestration/Scheduling",
                "FlowStep_C": "Data Transfer",
                "FlowStep_D": "Data Transformation",
                "FlowStep_E": "Model Training",
                "FlowStep_F": "Model Deployment",
                "FlowStep_G": "Monitoring"
            },
            "name": "aml-decision-tree",
            "popularity": 0,
            "topic": "Developer Tools",
            "hybrid-topic": "Apps"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "data-analytics",
                "data-flow",
                "example-workload",
                "fcp",
                "pricing-guidance"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/dataplate2e/data-platform-end-to-end.md",
            "http_url": "/azure/architecture/example-scenario/dataplate2e/data-platform-end-to-end",
            "word_count": 1787,
            "read_time": "7 min read",
            "Title": "Azure data platform end-to-end",
            "MetaDescription": "Use Azure services to ingest, process, store, serve, and visualize data from different sources.",
            "category": [
                "databases",
                "analytics"
            ],
            "image": "/azure/architecture/example-scenario/dataplate2e/media/azure-data-platform-end-to-end.jpg",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\dataplate2e\\media\\azure-data-platform-end-to-end.jpg",
            "publish_date": "1/31/2020",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "Flow": {
                "FlowStep_A": "Use Azure Synapse PolyBase capabilities for fast ingestion into your data warehouse tables.",
                "FlowStep_B": "Load relevant data from the Azure Synapse data warehouse into Power BI datasets for data visualization. Power BI models implement a semantic model to simplify the analysis of business data and relationships.",
                "FlowStep_C": "Business analysts use Power BI reports and dashboards to analyze data and derive business insights."
            },
            "name": "data-platform-end-to-end",
            "popularity": 0,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "data-flow",
                "fcp",
                "reference-architecture",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "hybrid/azure-stack-backup.md",
            "http_url": "/azure/architecture/hybrid/azure-stack-backup",
            "word_count": 6752,
            "read_time": "26 min read",
            "Title": "Back up files and applications on Azure Stack Hub",
            "MetaDescription": "Backup and restoration of files and applications of VM-based workloads",
            "category": [
                "hybrid",
                "management-and-governance"
            ],
            "image": "/azure/architecture/hybrid/images/azure-stack-backup.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\hybrid\\images\\azure-stack-backup.png",
            "publish_date": "8/06/2020",
            "alternative_choices": "alternative-solutions",
            "Summary": "<p>This document describes the architecture and design considerations of a solution that delivers an optimized approach to backup and restore of files and applications of VM-based user workloads hosted on Azure Stack Hub.</p>\n<p><img alt=\"Diagram illustrating backup of Azure Stack Hub files and applications hosted on Azure VMs, running such workloads as SQL Server, SharePoint Server, Exchange Server, File Server, and Active Directory Domain Services domain controllers. The backup relies on Azure Backup Server running on a Windows Server VM, with a geo-replicated Azure Recovery Services vault providing long-term storage. Initial backups can be performed by using Azure Import/Export service. Optionally, Azure ExpressRoute can provide high-bandwidth connectivity to Azure.\" src=\"https://learn.microsoft.com/azure/architecture/hybrid/images/azure-stack-backup.png\" /></p>\n<p><em>Download a <a href=\"https://arch-center.azureedge.net/azure-stack-backup.vsdx\">Visio file</a> of this architecture.</em></p>\n<p>Backup and restore are essential components of any comprehensive business continuity and disaster recovery strategy. Designing and implementing a consistent and reliable backup approach in a hybrid environment is challenging, but can be considerably simplified through integration with services provided by Microsoft Azure. This applies not only to the workloads running on traditional on-premises infrastructure, but also to those hosted by third-party public and private cloud providers. However, benefits of integration with Azure cloud services are particularly evident when the hybrid environments incorporate Azure Stack portfolio offerings, including the Azure Stack Hub.</p>\n<p>While one of the primary strengths of Azure Stack Hub is its support for the platform-as-a-service (PaaS) model, it also helps customers to modernize their existing infrastructure-as-a-service (IaaS) workloads. Such workloads might include file shares, Microsoft SQL Server databases, Microsoft SharePoint farms, and Microsoft Exchange Server clusters. Migrating them to VMs running on hyperconverged, highly-resilient clusters, with administrative and programming models consistent with Microsoft Azure, results in minimized management and maintenance overhead.</p>\n<p>For implementing backup of files and applications running on Azure Hub Stack VMs, Microsoft recommends a hybrid approach that relies on a combination of cloud and on-premises components to deliver a scalable, performant, resilient, secure, straightforward to manage, and cost-efficient backup solution. The central component of this solution is Microsoft Azure Backup Server (MABS) v3, which is part of the Azure Backup offering. MABS relies on Azure Stack Hub infrastructure for compute, network, and short-term storage resources, while it leverages Azure-based storage to serve as the long-term backup store. This minimizes or eliminates the need to maintain physical backup media such as tapes.</p>\n<blockquote>\n<p>[!Note]\nMABS is based on Microsoft System Center Data Protection Manager (DPM) and provides similar functionality with just a few differences. However, DPM is not supported for use with Azure Stack Hub.</p>\n</blockquote>",
            "Flow": {
                "FlowStep_A": "A customer copies the initial backup data to one or more SATA disks by using the AzureOfflineBackupDiskPrep tool.",
                "FlowStep_B": "The tool automatically generates an Azure Import job and an Azure AD app in the subscription hosting the target Azure Storage account and Azure Recovery Services vault. The purpose of the app is to provide Azure Backup with secure and scoped access to the Azure Import Service, required by the offline seeding process.",
                "FlowStep_C": "The customer ships SATA drives to the Azure datacenter hosting the target Azure Storage account.",
                "FlowStep_D": "Azure datacenter staff copies data from SATA disks to the Azure Storage account.",
                "FlowStep_E": "The workflow triggers a copy from the Azure Storage account to the Azure Recovery Services vault."
            },
            "visio_diagram": "https://arch-center.azureedge.net/azure-stack-backup.vsdx",
            "name": "azure-stack-backup",
            "popularity": 0,
            "topic": "Management and Governance",
            "hybrid-topic": "Management"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-backup-archive-on-premises-applications-'",
                "acom-architecture",
                "all-items",
                "bcdr",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/backup-archive-on-premises-applications.md",
            "http_url": "/azure/architecture/solution-ideas/articles/backup-archive-on-premises-applications",
            "word_count": 266,
            "read_time": "2 min read",
            "Title": "Back up on-premises applications and data to cloud",
            "MetaDescription": "Back up on-premises applications and data with Azure Backup and Blob storage applications. Read documentation on implementing these archiving solutions today.",
            "category": [
                "storage",
                "hybrid"
            ],
            "image": "/azure/architecture/solution-ideas/media/backup-archive-cloud-application.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\backup-archive-cloud-application.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p>Azure <a href=\"https://azure.microsoft.com/services/backup\">Backup Server</a> orchestrates the backup of machines and manages the configuration of the restore procedures. It also has two days of backup data for operational recovery.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/backup\">Azure Backup</a> service runs on the cloud and holds the recovery points, enforces policies, and enables you to manage data and application protection. You don't need to create or manage an Azure Blob storage account when using <a href=\"https://azure.microsoft.com/services/backup\">Azure Backup</a>.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage/blobs\">Blob Storage</a>: Blob storage that partner solutions such as Commvault connect to for backing up data and applications. You need to create and manage Azure Blob storage when using partner solutions.</p>"
            ],
            "name": "backup-archive-on-premises-applications",
            "popularity": 197,
            "topic": "Storage",
            "hybrid-topic": "Data"
        },
        {
            "tags": [
                "all-items",
                "cse",
                "data-flow",
                "example-code",
                "example-workload",
                "fcp",
                "github"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/banking/banking-system-cloud-transformation.md",
            "http_url": "/azure/architecture/example-scenario/banking/banking-system-cloud-transformation",
            "word_count": 2735,
            "read_time": "11 min read",
            "Title": "Banking system cloud transformation on Azure",
            "MetaDescription": "Solution for monitoring banking system infrastructure scalability and performance.",
            "category": [
                "devops"
            ],
            "image": "/azure/architecture/example-scenario/banking/images/banking-system-solution-arch.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\banking\\images\\banking-system-solution-arch.png",
            "publish_date": "8/11/2020",
            "Summary": "<p>This article summarizes the process and components the Microsoft Commercial Software Engineering (CSE) team used to build a solution for a banking customer. For the sake of anonymity, the article refers to the customer as Contoso Bank. It's a major international Financial Services Industry (FSI) organization that wanted to modernize one of its financial transaction systems.</p>\n<p>Contoso Bank wanted to use simulated and actual applications and existing workloads to monitor the reaction of the solution infrastructure for scalability and performance. The solution had to be compatible with the requirements of the existing payment system.</p>",
            "Flow": {
                "FlowStep_A": "One of these services is the EFT Processor, where the solution effectuates the actual transaction, carrying out credit and debit operations.",
                "FlowStep_B": "Next is load testing. It contains a custom solution based on JMeter, Azure Container Instances (ACI), and Terraform.",
                "FlowStep_C": "Finally, monitoring was responsible for integrating load testing results, infrastructure, and application metrics."
            },
            "sample_code": true,
            "github_url": "https://github.com/Azure-Samples/jmeter-aci-terraform",
            "name": "banking-system-cloud-transformation",
            "popularity": 0,
            "topic": "DevOps"
        },
        {
            "tags": [
                "all-items",
                "containers",
                "data-flow",
                "example-code",
                "github",
                "reference-architecture",
                "seojul20",
                "yaml"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/containers/aks/secure-baseline-aks.md",
            "http_url": "/azure/architecture/reference-architectures/containers/aks/secure-baseline-aks",
            "word_count": 7946,
            "read_time": "32 min read",
            "Title": "Baseline architecture for an Azure Kubernetes Service (AKS) cluster",
            "MetaDescription": "Reference architecture for a baseline infrastructure that deploys an Azure Kubernetes Service (AKS) cluster.",
            "category": [
                "containers",
                "kubernetes",
                "aks"
            ],
            "image": "/azure/architecture/reference-architectures/containers/aks/images/secure-baseline-architecture.svg",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\containers\\aks\\images\\secure-baseline-architecture.svg",
            "publish_date": "8/01/2020",
            "Flow": {
                "FlowStep_A": " The ingress controller receives the encrypted traffic through the load balancer. The controller is another TLS termination point for \\*.aks-ingress.contoso.com and forwards the traffic to the workload pods over HTTP. The certificates are stored in Azure Key Vault and mounted into the cluster using the Container Storage Interface (CSI) driver. For more information, see Add secret management."
            },
            "sample_code": true,
            "github_url": "https://github.com/mspnp/aks-secure-baseline",
            "code_languages": [
                "yaml"
            ],
            "name": "secure-baseline-aks",
            "popularity": 0,
            "topic": "Containers"
        },
        {
            "tags": [
                "all-items",
                "integration-services",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/enterprise-integration/basic-enterprise-integration.yml",
            "http_url": "/azure/architecture/reference-architectures/enterprise-integration/basic-enterprise-integration",
            "word_count": 2325,
            "read_time": "9 min read",
            "Title": "Basic enterprise integration on Azure",
            "MetaDescription": "Recommended architecture for implementing a simple enterprise integration pattern using Azure Logic Apps and Azure API Management.",
            "category": [
                "integration",
                "developer-tools",
                "management-and-governance"
            ],
            "image": "/azure/architecture/reference-architectures/enterprise-integration/_images/simple-enterprise-integration.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\enterprise-integration\\_images\\simple-enterprise-integration.png",
            "publish_date": "12/03/2018",
            "Summary": "<p>This reference architecture uses <a href=\"https://azure.microsoft.com/product-categories/integration\">Azure Integration Services</a> to orchestrate calls to enterprise backend systems. The backend systems may include software as a service (SaaS) systems, Azure services, and existing web services in your enterprise.</p>\n<p>Azure Integration Services is a collection of services for integrating applications and data. This architecture uses two of those services: <a >queues and events</a> builds on this basic architecture.</p>\n<p><img alt=\"Architecture diagram - Simple enterprise integration\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/enterprise-integration/_images/simple-enterprise-integration.png\" /></p>",
            "name": "basic-enterprise-integration",
            "popularity": 235,
            "topic": "Integration"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "github",
                "powershell",
                "reference-architecture",
                "seodec18",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/app-service-web-app/basic-web-app.yml",
            "http_url": "/azure/architecture/reference-architectures/app-service-web-app/basic-web-app",
            "word_count": 2874,
            "read_time": "11 min read",
            "Title": "Basic web application",
            "MetaDescription": "Learn about proven practices for a web application that uses Azure App Service and Azure SQL Database by using this reference architecture.",
            "category": [
                "web"
            ],
            "image": "/azure/architecture/reference-architectures/app-service-web-app/images/basic-web-app.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\app-service-web-app\\images\\basic-web-app.png",
            "publish_date": "12/12/2017",
            "Summary": "<p>This reference architecture shows proven practices for a web application that uses <a href=\"https://learn.microsoft.com/azure/app-service\">Azure App Service</a> and <a href=\"https://learn.microsoft.com/azure/sql-database\">Azure SQL Database</a>. <a href=\"#deploy-the-solution\"><strong>Deploy this solution</strong></a>.</p>\n<p><img alt=\"Reference architecture for a basic web application in Azure\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/app-service-web-app/images/basic-web-app.png\" /></p>\n<p><em>Download a <a href=\"https://arch-center.azureedge.net/app-service-reference-architectures.vsdx\">Visio file</a> of this architecture.</em></p>",
            "sample_code": true,
            "github_url": "https://github.com/mspnp/samples/tree/master/solutions/basic-web-app",
            "visio_diagram": "https://arch-center.azureedge.net/app-service-reference-architectures.vsdx",
            "code_languages": [
                "powershell"
            ],
            "name": "basic-web-app",
            "popularity": 237,
            "topic": "Web"
        },
        {
            "tags": [
                "all-items",
                "azcat-ai",
                "example-code",
                "github",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/ai/batch-scoring-deep-learning.md",
            "http_url": "/azure/architecture/reference-architectures/ai/batch-scoring-deep-learning",
            "word_count": 1710,
            "read_time": "7 min read",
            "Title": "Batch scoring for deep learning models",
            "MetaDescription": "This reference architecture shows how to apply neural style transfer to a video, using Azure Machine Learning.",
            "category": [
                "ai-machine-learning",
                "media"
            ],
            "image": "/azure/architecture/reference-architectures/ai/_images/azure-machine-learning-deep-learning-scoring-pipeline.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\ai\\_images\\azure-machine-learning-deep-learning-scoring-pipeline.png",
            "publish_date": "2/06/2019",
            "Summary": "<p>This reference architecture shows how to apply neural style transfer to a video, using Azure Machine Learning. <em>Style transfer</em> is a deep learning technique that composes an existing image in the style of another image. This architecture can be generalized for any scenario that uses batch scoring with deep learning. <a href=\"#deploy-the-solution\"><strong>Deploy this solution</strong></a>.</p>\n<p><img alt=\"Architecture diagram for deep learning models using Azure Machine Learning\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/ai/_images/azure-machine-learning-deep-learning-scoring-pipeline.png\" /></p>\n<p><strong>Scenario</strong>: A media organization has a video whose style they want to change to look like a specific painting. The organization wants to be able to apply this style to all frames of the video in a timely manner and in an automated fashion. For more background about neural style transfer algorithms, see <a href=\"https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf\">Image Style Transfer Using Convolutional Neural Networks</a> (PDF).</p>\n<!-- markdownlint-disable MD033 -->\n\n<p>| Style image: | Input/content video: | Output video: |\n|--------|--------|---------|\n| <img src=\"https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/style_image.jpg\" width=\"300\" alt=\"Picture of a painting in particular art style.\" > | <a href=\"https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/input_video.mp4\" title=\"Input Video\"><img src=\"https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/input_video_image_0.jpg\" width=\"300\" height=\"300\" alt=\"Picture of an animal in a tree in realistic style.\" ></a> <em>click to view video</em> | <a href=\"https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/output_video.mp4\" title=\"Output Video\"><img src=\"https://happypathspublic.blob.core.windows.net/assets/batch_scoring_for_dl/output_video_image_0.jpg\" width=\"300\" height=\"300\" alt=\"Picture of an animal in a tree, stylized to match a painting.\" ></a> <em>click to view video</em> |</p>\n<!-- markdownlint-enable MD033 -->\n\n<p>This reference architecture is designed for workloads that are triggered by the presence of new media in Azure storage.</p>\n<p>Processing involves the following steps:</p>\n<ol>\n<li>Upload a video file to storage.</li>\n<li>The video file triggers a Logic App to send a request to the Azure Machine Learning pipeline published endpoint.</li>\n<li>The pipeline processes the video, applies style transfer with MPI, and postprocesses the video.</li>\n<li>The output is saved back to blob storage once the pipeline is completed.</li>\n</ol>",
            "sample_code": true,
            "github_url": "https://github.com/Azure/Batch-Scoring-Deep-Learning-Models-With-AML",
            "name": "batch-scoring-deep-learning",
            "popularity": 143,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "ai",
                "all-items",
                "azcat-ai",
                "example-code",
                "github",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/ai/batch-scoring-python.md",
            "http_url": "/azure/architecture/reference-architectures/ai/batch-scoring-python",
            "word_count": 1155,
            "read_time": "5 min read",
            "Title": "Batch scoring of Python models on Azure",
            "MetaDescription": "Build a scalable solution for batch scoring models on a schedule in parallel using Azure Machine Learning.",
            "category": [
                "ai-machine-learning",
                "developer-tools"
            ],
            "image": "/azure/architecture/reference-architectures/ai/_images/batch-scoring-python.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\ai\\_images\\batch-scoring-python.png",
            "publish_date": "1/30/2019",
            "Summary": "<p>This reference architecture shows how to build a scalable solution for batch scoring many models on a schedule in parallel using <a href=\"https://learn.microsoft.com/azure/machine-learning/service/overview-what-is-azure-ml\">Azure Machine Learning</a>. The solution can be used as a template and can generalize to different problems.</p>\n<p>A reference implementation for this architecture is available on <a href=\"https://github.com/Microsoft/AMLBatchScoringPipeline\">GitHub</a>.</p>\n<p><img alt=\"Batch scoring of Python models on Azure\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/ai/_images/batch-scoring-python.png\" /></p>\n<p><strong>Scenario</strong>: This solution monitors the operation of a large number of devices in an IoT setting where each device sends sensor readings continuously. Each device is assumed to be associated with pretrained anomaly detection models that need to be used to predict whether a series of measurements, that are aggregated over a predefined time interval, correspond to an anomaly or not. In real-world scenarios, this could be a stream of sensor readings that need to be filtered and aggregated before being used in training or real-time scoring. For simplicity, this solution uses the same data file when executing scoring jobs.</p>\n<p>This reference architecture is designed for workloads that are triggered on a schedule. Processing involves the following steps:</p>\n<ol>\n<li>Send sensor readings for ingestion to Azure Event Hubs.</li>\n<li>Perform stream processing and store the raw data.</li>\n<li>Send the data to a Machine Learning cluster that is ready to start taking work. Each node in the cluster runs a scoring job for a specific sensor.</li>\n<li>Execute the <a href=\"https://learn.microsoft.com/azure/machine-learning/service/how-to-run-batch-predictions\">scoring pipeline</a>, which runs the scoring jobs in parallel using machine learning Python scripts. The pipeline is created, published, and scheduled to run on a predefined interval of time.</li>\n<li>Generate predictions and store them in Blob storage for later consumption.</li>\n</ol>",
            "sample_code": true,
            "github_url": "https://github.com/microsoft/az-ml-batch-score/blob/master/01_DataPrep.ipynb",
            "name": "batch-scoring-python",
            "popularity": 155,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "all-items",
                "azcat-ai",
                "example-code",
                "github",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/ai/batch-scoring-databricks.md",
            "http_url": "/azure/architecture/reference-architectures/ai/batch-scoring-databricks",
            "word_count": 1240,
            "read_time": "5 min read",
            "Title": "Batch scoring of Spark models on Azure Databricks",
            "MetaDescription": "Build a scalable solution for batch scoring an Apache Spark classification model on a schedule using Azure Databricks.",
            "category": [
                "ai-machine-learning",
                "analytics",
                "databases"
            ],
            "image": "/azure/architecture/reference-architectures/ai/_images/batch-scoring-spark-models-databricks.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\ai\\_images\\batch-scoring-spark-models-databricks.png",
            "publish_date": "11/20/2019",
            "Summary": "<p>This reference architecture shows how to build a scalable solution for batch scoring an Apache Spark classification model on a schedule using Azure Databricks, an Apache Spark-based analytics platform optimized for Azure. The solution can be used as a template that can be generalized to other scenarios.</p>\n<p>A reference implementation for this architecture is available on\u00a0<a href=\"https://github.com/Azure/BatchSparkScoringPredictiveMaintenance\">GitHub</a>.</p>\n<p><img alt=\"Batch scoring of Spark models on Azure Databricks\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/ai/_images/batch-scoring-spark-models-databricks.png\" /></p>\n<p><strong>Scenario</strong>: A business in an asset-heavy industry wants to minimize the costs and downtime associated with unexpected mechanical failures. Using IoT data collected from their machines, they can create a predictive maintenance model. This model enables the business to maintain components proactively and repair them before they fail. By maximizing mechanical component use, they can control costs and reduce downtime.</p>\n<p>A predictive maintenance model collects data from the machines and retains historical examples of component failures. The model can then be used to monitor the current state of the components and predict if a given component will fail in the near future. For common use cases and modeling approaches, see <a href=\"https://learn.microsoft.com/azure/machine-learning/team-data-science-process/cortana-analytics-playbook-predictive-maintenance\">Azure AI guide for predictive maintenance solutions</a>.</p>\n<p>This reference architecture is designed for workloads that are triggered by the presence of new data from the component machines. Processing involves the following steps:</p>\n<ol>\n<li>\n<p>Ingest the data from the external data store onto an Azure Databricks data store.</p>\n</li>\n<li>\n<p>Train a machine learning model by transforming the data into a training data set, then building a Spark MLlib model. MLlib consists of most common machine learning algorithms and utilities optimized to take advantage of Spark data scalability capabilities.</p>\n</li>\n<li>\n<p>Apply the trained model to predict (classify) component failures by transforming the data into a scoring data set. Score the data with the Spark MLLib model.</p>\n</li>\n<li>\n<p>Store results on the Databricks data store for post-processing consumption.</p>\n</li>\n</ol>\n<p>Notebooks are provided on\u00a0<a href=\"https://github.com/Azure/BatchSparkScoringPredictiveMaintenance\">GitHub</a> to perform each of these tasks.</p>",
            "sample_code": true,
            "github_url": "https://github.com/Azure/BatchSparkScoringPredictiveMaintenance",
            "name": "batch-scoring-databricks",
            "popularity": 165,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "all-items",
                "azcat-ai",
                "example-code",
                "github",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/ai/batch-scoring-R-models.md",
            "http_url": "/azure/architecture/reference-architectures/ai/batch-scoring-r-models",
            "word_count": 1233,
            "read_time": "5 min read",
            "Title": "Batch scoring with R Models on Azure",
            "MetaDescription": "Perform batch scoring with R models using Azure Batch and a data set based on retail store sales forecasting.",
            "category": [
                "ai-machine-learning",
                "developer-tools"
            ],
            "image": "/azure/architecture/reference-architectures/ai/_images/batch-scoring-r-models.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\ai\\_images\\batch-scoring-r-models.png",
            "publish_date": "3/29/2019",
            "Summary": "<p>This reference architecture shows how to perform batch scoring with R models using Azure Batch. The scenario is based on retail store sales forecasting, but this architecture can be generalized for any scenario requiring the generation of predictions on a larger scale using R models. A reference implementation for this architecture is available on\n<a href=\"https://github.com/Azure/RBatchScoring\">GitHub</a>.</p>\n<p><img alt=\"Architecture diagram\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/ai/_images/batch-scoring-r-models.png\" /></p>\n<p><strong>Scenario</strong>: A supermarket chain needs to forecast sales of products over the upcoming quarter. The forecast allows the company to manage its supply chain better and ensure it can meet demand for products at each of its stores. The company updates its forecasts every week as new sales data from the previous week becomes available and the product marketing strategy for next quarter is set. Quantile forecasts are generated to estimate the uncertainty of the individual sales forecasts.</p>\n<p>Processing involves the following steps:</p>\n<ol>\n<li>\n<p>An Azure Logic App triggers the forecast generation process once per week.</p>\n</li>\n<li>\n<p>The logic app starts an Azure Container Instance running the scheduler Docker container, which triggers the scoring jobs on the Batch cluster.</p>\n</li>\n<li>\n<p>Scoring jobs run in parallel across the nodes of the Batch cluster. Each node:</p>\n<ol>\n<li>\n<p>Pulls the worker Docker image from Docker Hub and starts a container.</p>\n</li>\n<li>\n<p>Reads input data and pre-trained R models from Azure Blob storage.</p>\n</li>\n<li>\n<p>Scores the data to produce the forecasts.</p>\n</li>\n<li>\n<p>Writes the forecast results to blob storage.</p>\n</li>\n</ol>\n</li>\n</ol>\n<p>The figure below shows the forecasted sales for four products (SKUs) in one store. The black line is the sales history, the dashed line is the median (q50) forecast, the pink band represents the twenty-fifth and seventy-fifth percentiles, and the blue band represents the fifth and ninety-fifth percentiles.</p>\n<p><img alt=\"Sales forecasts\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/ai/_images/batch-scoring-sales-forecasts.png\" /></p>",
            "sample_code": true,
            "github_url": "https://github.com/Azure/doAzureParallel/blob/master/docs/32-autoscale.md",
            "name": "batch-scoring-R-models",
            "popularity": 78,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-blockchain-workflow-application-'",
                "acom-architecture",
                "all-items",
                "azure-blockchain",
                "azure-blockchain-service",
                "blockchain",
                "blockchain-workflow-application",
                "data-flow",
                "interactive-diagram",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/blockchain-workflow-application.md",
            "http_url": "/azure/architecture/solution-ideas/articles/blockchain-workflow-application",
            "word_count": 400,
            "read_time": "2 min read",
            "Title": "Blockchain Workflow Application",
            "MetaDescription": "Explore how blockchain is used to digitize workflows and supply chains across organizations with the Blockchain Workflow Application from Microsoft Azure.",
            "category": [
                "blockchain"
            ],
            "image": "/azure/architecture/solution-ideas/media/blockchain-workflow-application.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\blockchain-workflow-application.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/blockchain-service\">Azure Blockchain Service</a>: Build, govern, and expand consortium blockchain networks</p>",
                "<p><a href=\"https://azure.microsoft.com/services/service-bus\">Service Bus</a>: Connect across private and public cloud environments</p>",
                "<p><a href=\"https://azure.microsoft.com/services/iot-central\">Azure IoT Central</a>: Accelerate the creation of IoT solutions</p>",
                "<p>Application Insights: Detect, triage, and diagnose issues in your web apps and services</p>",
                "<p><a href=\"https://azure.microsoft.com/services/event-grid\">Event Grid</a>: Get reliable event delivery at massive scale</p>",
                "<p><a href=\"https://azure.microsoft.com/services/logic-apps\">Logic Apps</a>: Automate the access and use of data across clouds without writing code</p>",
                "<p><a href=\"https://azure.microsoft.com/services/sql-database\">Azure SQL Database</a>: Managed, intelligent SQL in the cloud</p>",
                "<p><a href=\"https://azure.microsoft.com/services/active-directory\">Azure Active Directory</a>: Synchronize on-premises directories and enable single sign-on</p>",
                "<p><a href=\"https://azure.microsoft.com/services/key-vault\">Key Vault</a>: Safeguard and maintain control of keys and other secrets</p>",
                "<p><a href=\"https://azure.microsoft.com/services/app-service\">App Service</a>: Quickly create powerful cloud apps for web and mobile</p>",
                "<p><a href=\"https://azure.microsoft.com/services/virtual-network\">Virtual Network</a>: Provision private networks, optionally connect to on-premises datacenters</p>",
                "<p><a href=\"https://azure.microsoft.com/services/power-bi-embedded\">Power BI Embedded</a>: Embed fully interactive, stunning data visualizations in your applications</p>"
            ],
            "Summary": "<p>Businesses use blockchain to digitize workflows they share with other organizations, such as moving physical assets across supply chains. The anatomy of blockchain apps is similar across use cases. Here, we use Azure Blockchain Service as the foundational managed blockchain network and build a consortium application that can ingest signals from relevant user interfaces and communicate ledger data to consuming apps across the consortium.</p>",
            "Flow": {
                "FlowStep_A": "Relevant apps, devices, and data sources send events or data to a message broker (Azure Service Bus).",
                "FlowStep_B": "The distributed ledger technology (DLT) consumer Logic App fetches the data from the Service Bus and sends to transaction builder which builds and signs the transaction.",
                "FlowStep_C": "The signed transaction gets routed to Azure Blockchain Service (fully managed Ethereum consortium network) via a ledger-specific Logic App connector.",
                "FlowStep_D": "The blockchain data manager captures block and transaction data from configured transaction nodes, decodes events and properties and then sends the data to configured destinations.",
                "FlowStep_E": "Message broker sends ledger data to consuming business applications and off-chain database.",
                "FlowStep_F": "Information is analyzed and visualized using tools such as Power BI by connecting to off-chain database."
            },
            "name": "blockchain-workflow-application",
            "popularity": 167,
            "topic": "Blockchain"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "example-workload",
                "fasttrack",
                "fcp",
                "github"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/apps/devops-cicd-chatbot.md",
            "http_url": "/azure/architecture/example-scenario/apps/devops-cicd-chatbot",
            "word_count": 2300,
            "read_time": "9 min read",
            "Title": "Build a CI/CD pipeline for chatbots with ARM templates",
            "MetaDescription": "Use Azure Pipelines with ARM templates to set up a CI/CD pipeline to Azure App Service and Azure Bot Service for a chatbot app.",
            "category": [
                "devops",
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/example-scenario/apps/media/ci-cd-pipeline-deployment-arm-templates.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\apps\\media\\ci-cd-pipeline-deployment-arm-templates.png",
            "publish_date": "3/25/2020",
            "sample_code": true,
            "github_url": "https://github.com/mspnp/solution-architectures/tree/master/cicdbots",
            "name": "devops-cicd-chatbot",
            "popularity": 0,
            "topic": "DevOps"
        },
        {
            "tags": [
                "all-items",
                "azcat-ai",
                "data-flow",
                "example-code",
                "github",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/ai/real-time-recommendation.md",
            "http_url": "/azure/architecture/reference-architectures/ai/real-time-recommendation",
            "word_count": 1340,
            "read_time": "6 min read",
            "Title": "Build a Real-time Recommendation API on Azure",
            "MetaDescription": "Use machine learning to automate recommendations using Azure Databricks and Azure Data Science Virtual Machines (DSVM) to train a model on Azure.",
            "category": [
                "ai-machine-learning",
                "compute",
                "databases"
            ],
            "image": "/azure/architecture/reference-architectures/ai/_images/recommenders-architecture.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\ai\\_images\\recommenders-architecture.png",
            "publish_date": "12/12/2018",
            "Flow": {
                "FlowStep_A": "Track user behaviors. For example, a backend service might log when a user rates a movie or clicks a product or news article.",
                "FlowStep_B": "Load the data into Azure Databricks from an available [data source][data-source].",
                "FlowStep_C": "Prepare the data and split it into training and testing sets to train the model. ([This guide][guide] describes options for splitting data.)",
                "FlowStep_D": "Fit the [Spark Collaborative Filtering][als] model to the data.",
                "FlowStep_E": "Evaluate the quality of the model using rating and ranking metrics. ([This guide][eval-guide] provides details about the metrics you can evaluate your recommender on.)",
                "FlowStep_F": "Precompute the top 10 recommendations per user and store as a cache in Azure Cosmos DB.",
                "FlowStep_G": "Deploy an API service to AKS using the Azure Machine Learning APIs to containerize and deploy the API.",
                "FlowStep_H": "When the backend service gets a request from a user, call the recommendations API hosted in AKS to get the top 10 recommendations and display them to the user."
            },
            "sample_code": true,
            "github_url": "https://github.com/Microsoft/Recommenders/blob/master/examples/05_operationalize/als_movie_o16n.ipynb",
            "name": "real-time-recommendation",
            "popularity": 203,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "all-items",
                "azcat-ai",
                "data-flow",
                "example-code",
                "github",
                "reference-architecture",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/ai/conversational-bot.md",
            "http_url": "/azure/architecture/reference-architectures/ai/conversational-bot",
            "word_count": 3279,
            "read_time": "13 min read",
            "Title": "Build an enterprise-grade conversational bot",
            "MetaDescription": "How to build an enterprise-grade conversational bot (chatbot) using the Azure Bot Framework.",
            "category": [
                "ai-machine-learning",
                "featured"
            ],
            "image": "/azure/architecture/reference-architectures/ai/_images/conversational-bot-logical.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\ai\\_images\\conversational-bot-logical.png",
            "publish_date": "1/24/2019",
            "Flow": {},
            "sample_code": true,
            "github_url": "https://github.com/microsoft/botbuilder-dotnet",
            "visio_diagram": "https://arch-center.azureedge.net/conversational-bot.vsdx",
            "name": "conversational-bot",
            "popularity": 205,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "all-items",
                "data-flow",
                "fcp",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/cloud-native-apps.md",
            "http_url": "/azure/architecture/solution-ideas/articles/cloud-native-apps",
            "word_count": 553,
            "read_time": "3 min read",
            "Title": "Build cloud native applications",
            "MetaDescription": "Build cloud native applications with Azure Cosmos DB, Azure Database for PostgreSQL and Azure Cache for Redis",
            "category": [
                "databases",
                "web",
                "mobile"
            ],
            "image": "/azure/architecture/solution-ideas/media/cloud-native-apps.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\cloud-native-apps.png",
            "publish_date": "6/26/2020",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/aks/intro-kubernetes\">Azure Kubernetes Service</a> allows you to quickly deploy a production ready Kubernetes cluster in Azure.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/postgresql/overview\">Azure Database for PostgreSQL</a> is a fully managed relational database service based on the community edition of the open-source PostgreSQL database engine.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/azure-cache-for-redis/cache-overview\">Azure Cache for Redis</a> is a secure data cache and messaging broker that provides high throughput and low-latency access to data for applications.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/cosmos-db/introduction\">Azure Cosmos DB</a> is a fully managed NoSQL database service for building and modernizing scalable, high performance applications.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/notification-hubs/notification-hubs-push-notification-overview\">Azure Notification Hubs</a> sends push notifications from any backend to any mobile device.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/azure-functions/functions-overview\">Azure Functions</a> is a serverless compute service that lets you run event-triggered code without having to explicitly provision or manage infrastructure.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/databricks/scenarios/what-is-azure-databricks\">Azure Databricks</a> is an Apache Spark-based analytics service for big data analytics and AI</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/azure-monitor/app/app-insights-overview\">Azure Application Insights</a> is an extensible Application Performance Management service used to monitor live applications and continuously improve performance and usability.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-overview-what-is\">Azure Synapse Analytics</a> is an analytics service that brings together enterprise data warehousing and Big Data analytics within a unified experience.</p>",
                "<p><a href=\"https://learn.microsoft.com/power-bi/fundamentals/power-bi-overview\">Power BI</a> is a suite of business tools for self-service and enterprise business intelligence (BI). Here, it\u2019s used to analyze and visualize data.</p>"
            ],
            "Summary": "<p>Web and mobile applications are a key part of a successful digital transformation strategy. Organizations can build cloud-native applications using Azure managed databases, Azure Kubernetes Service, and analytics/ML for applications that are incredibly responsive to customer needs.</p>",
            "Flow": {
                "FlowStep_A": "Deploy and manage containerized applications easily with a continuous integration and delivery experience (CI/CD), and enterprise grade security and governance.",
                "FlowStep_B": "Focus on your app, not the database, with a fully managed database as a service for PostgreSQL. With built-in high availability and the rich feature set of Postgres, you can build design modern experiences free from legacy constraints.",
                "FlowStep_C": "Offload database demands by managing sessions state and asset caching with Azure Cache for Redis",
                "FlowStep_D": "Alert based on key events such as location or user activity using the serverless compute platform of Azure Functions.",
                "FlowStep_E": "Push timely notifications directly to your users on their preferred service or medium.",
                "FlowStep_F": "Derive deep insights by analyzing your data with Azure Synapse Analytics, with natively integrated Apache Spark for big data processing and machine learning.",
                "FlowStep_G": "Monitor your application\u2019s performance for degradation or anomalies, and auto-scale your application to changing performance requirements.",
                "FlowStep_H": "Track user interactions with you application at scale using Azure Cosmos DB. Easily scale to meet changing demand requirements with a fully managed NoSQL database.",
                "FlowStep_I": "Provide near real-time analytics and insight into user interaction by leveraging Azure Synapse Link for Azure Cosmos DB HTAP capabilities."
            },
            "name": "cloud-native-apps",
            "popularity": 0,
            "topic": "Databases"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-build-high-availability-into-your-bcdr-strategy-'",
                "acom-architecture",
                "all-items",
                "availability",
                "bcdr",
                "data-flow",
                "interactive-diagram",
                "solution-idea",
                "strategy"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/build-high-availability-into-your-bcdr-strategy.md",
            "http_url": "/azure/architecture/solution-ideas/articles/build-high-availability-into-your-bcdr-strategy",
            "word_count": 159,
            "read_time": "1 min read",
            "Title": "Build high availability into your BCDR strategy",
            "MetaDescription": "Virtual machines (VMs) are physically separated across zones, and a virtual network is created using load balancers at each site. These locations are close enough for high availability replication, so your applications stay running, despite any issues at the physical locations.",
            "category": [
                "management-and-governance",
                "networking",
                "hybrid"
            ],
            "image": "/azure/architecture/solution-ideas/media/build-high-availability-into-your-bcdr-strategy.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\build-high-availability-into-your-bcdr-strategy.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/virtual-machines\">Virtual Machines</a>: Provision Windows and Linux virtual machines in seconds</p>",
                "<p><a href=\"https://azure.microsoft.com/services/sql-database\">Azure SQL Database</a>: Managed, intelligent SQL in the cloud</p>",
                "<p><a href=\"https://azure.microsoft.com/services/load-balancer\">Load Balancer</a>: Deliver high availability and network performance to your applications</p>"
            ],
            "Summary": "<p>Virtual machines (VMs) are physically separated across zones, and a virtual network is created using load balancers at each site. These locations are close enough for high availability replication, so your applications stay running, despite any issues at the physical locations.</p>",
            "Flow": {
                "FlowStep_A": "Create zone-redundant Load Balancer.",
                "FlowStep_B": "Create front-end subnet.",
                "FlowStep_C": "Create DB subnet.",
                "FlowStep_D": "Create VMs in three Availability Zones.",
                "FlowStep_E": "Configure zone-redundant SQL DB.",
                "FlowStep_F": "Add VMs to the load balancer's back-end pool.",
                "FlowStep_G": "Deploy your application on VMs for redundancy and high availability."
            },
            "name": "build-high-availability-into-your-bcdr-strategy",
            "popularity": 158,
            "topic": "Management and Governance",
            "hybrid-topic": "Management"
        },
        {
            "tags": [
                "acom-architecture",
                "all-items",
                "fcp",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/webapps.md",
            "http_url": "/azure/architecture/solution-ideas/articles/webapps",
            "word_count": 470,
            "read_time": "2 min read",
            "Title": "Build web and mobile applications",
            "MetaDescription": "The reference architecture below is inspired by HSBC\u2019s digital payment platform, PayMe for Business.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/webapps.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\webapps.png",
            "publish_date": "6/24/2020",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/mysql/overview\">Azure Database for MySQL</a> is a fully managed relational database service based on the community edition of the open-source MySQL database engine.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/cosmos-db/\">Azure Cosmos DB</a> is a fully managed NoSQL database service for building and modernizing scalable, high performance applications.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/azure-cache-for-redis/\">Azure Cache for Redis</a> is a secure data cache and messaging broker that provides high throughput and low-latency access to data for applications.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/aks/\">Azure Kubernetes Service</a> is a highly available, secure, and fully managed Kubernetes service that makes it easy to deploy and manage containerized applications.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/event-hubs/\">Event Hubs</a> is a fully managed, real-time data ingestion service. Stream millions of events per second from any source to build dynamic data pipelines.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/azure-databricks/\">Azure Databricks</a> is an Apache Spark-based analytics service for big data analytics and AI</p>",
                "<p><a href=\"https://learn.microsoft.com/power-bi/fundamentals/power-bi-overview\">Power BI</a> is a suite of business tools for self-service and enterprise business intelligence (BI). Here, it\u2019s used to analyze and visualize data.</p>"
            ],
            "Summary": "<p>With Azure, it\u2019s easy to build web and mobile applications to help with digital payments, hotel or rental car bookings, e-commerce platforms, and more. A microservices-based architecture enables organizations to seamlessly scale on demand to cater to internet-scale users.</p>",
            "name": "webapps",
            "popularity": 0,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "all-items",
                "example-workload",
                "fcp"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/iot/builders-developers-operators.md",
            "http_url": "/azure/architecture/example-scenario/iot/builders-developers-operators",
            "word_count": 657,
            "read_time": "3 min read",
            "Title": "Builders, developers, and operators",
            "MetaDescription": "Learn about the device builder, application developer, and solution operator roles and how they interact in an IoT solution.",
            "category": [
                "iot"
            ],
            "image": "/azure/architecture/example-scenario/iot/media/device-builder.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\iot\\media\\device-builder.png",
            "publish_date": "8/10/2020",
            "name": "builders-developers-operators",
            "popularity": 0,
            "topic": "Internet of Things"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "database-team",
                "example-workload",
                "healthcare",
                "pricing-calculator",
                "pricing-guidance"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/apps/telehealth-system.yml",
            "http_url": "/azure/architecture/example-scenario/apps/telehealth-system",
            "word_count": 1668,
            "read_time": "7 min read",
            "Title": "Building a telehealth system on Azure",
            "MetaDescription": "A healthcare system connecting users, devices, and providers built using Kubernetes and PostgreSQL",
            "category": [
                "containers",
                "databases"
            ],
            "image": "/azure/architecture/example-scenario/apps/media/architecture-telehealth-system.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\apps\\media\\architecture-telehealth-system.png",
            "publish_date": "5/25/2019",
            "pricing_calculator": "https://www.azure.com/e/af6719a5700844aab6c8917b4908b8ab",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/postgresql/\">Azure Database for PostgreSQL</a> stores user (patient and health care professional) and device-related data. The service was chosen because it's stable, lightweight, and has no vendor lock-in.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/kubernetes-service/\">Azure Kubernetes Service</a> hosts the application business logic and provides ease of deployment and flexibility for customization. The service also abstracts the solution from the actual hardware used underneath.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cache/\">Azure Cache for Redis</a> hosts temporary data used for intra service data (shared data). The service can be recreated from the database in case the data expires from the cache</p>",
                "<p><a href=\"https://azure.microsoft.com/services/notification-hubs/\">Azure Notification Hub</a> notifies patient of incoming content: chat, video calls, device configuration settings.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/functions/\">Azure Functions</a> schedules tasks. For instance, broad communications to large set of users, coordination of analytics work in the backend (aggregations\u2026).</p>",
                "<p><a href=\"https://azure.microsoft.com/services/monitor/\">Azure Application Insights</a> centralizes signals/events from the system (logs, telemetry from logs from microservices, frontend, and devices) for troubleshooting purposes.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cdn/\">Azure Content Delivery Network (CDN)</a> is used for maintenance and updates (delivery of java scripts file) to the web portal and to deliver media files (videos, images) through the portal. All this content is stored in the Azure storage accounts in the background.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/traffic-manager/\">Azure Traffic Manager</a> load balances between geo locations.</p>"
            ],
            "Summary": "<p>This article explains how to build a <a href=\"https://en.wikipedia.org/wiki/Telehealth\">telehealth system</a> using Azure cloud services. The details are based on a real customer implementation that connects a professional healthcare organization to its remote patients. While there are other ways to build such a system, the solution described has been successful in enabling communication between patients and their remote care provider, as well as remotely tuning the medical devices that patients carry.</p>\n<p>There are about 700 million people who suffer from hearing disabilities. However, only 10% of them use hearing aid devices to improve their lives. In some geographies or situations, it is impossible for a patient to get direct assistance when needed. For example, consider patients who:</p>\n<ul>\n<li>Need help in a specific hearing situation (for example, while walking in the park, attending a party, or being at home), which cannot be reproduced in the hearing care professional's office.</li>\n<li>Have mobility issues or reside long distances from their hearing care professional.</li>\n<li>Live in an emerging country/region that has a limited number of hearing care professionals.</li>\n</ul>\n<p>To overcome these difficulties, it is important to have the ability to provide hearing care services remotely. In this case, the healthcare professional uses chat or video communication to engage with their remote patients. People who are hard of hearing use a smartphone to allow access to the hearing aid device during the remote session. The patient immediately experiences improved hearing as the hearing care professional deploys changes to the configuration of the hearing aid device in real time.</p>",
            "name": "telehealth-system",
            "popularity": 183,
            "topic": "Containers"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-scale-using-aks-with-aci-'",
                "acom-architecture",
                "all-items",
                "data-flow",
                "devops",
                "interactive-diagram",
                "kubernetes",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/scale-using-aks-with-aci.md",
            "http_url": "/azure/architecture/solution-ideas/articles/scale-using-aks-with-aci",
            "word_count": 117,
            "read_time": "1 min read",
            "Title": "Bursting from AKS with ACI",
            "MetaDescription": "Bursting from AKS with ACI",
            "category": [
                "containers",
                "devops"
            ],
            "image": "/azure/architecture/solution-ideas/media/scale-using-aks-with-aci.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\scale-using-aks-with-aci.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Use the AKS virtual node to provision pods inside ACI that start in seconds. This enables AKS to run with just enough capacity for your average workload. As you run out of capacity in your AKS cluster, scale out additional pods in ACI without any additional servers to manage.</p>",
            "Flow": {
                "FlowStep_A": "User registers container in Azure Container Registry",
                "FlowStep_B": "Container images are pulled from the Azure Container Registry",
                "FlowStep_C": "AKS virtual node, a Virtual Kubelet implementation, provisions pods inside ACI from AKS when traffic comes in spikes."
            },
            "name": "scale-using-aks-with-aci",
            "popularity": 120,
            "topic": "Containers"
        },
        {
            "tags": [
                "acom-architecture",
                "all-items",
                "data-flow",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/business-process-management.md",
            "http_url": "/azure/architecture/solution-ideas/articles/business-process-management",
            "word_count": 291,
            "read_time": "2 min read",
            "Title": "Business Process Management",
            "MetaDescription": "In industries where bidding competition is fierce, or when the diagnosis of a problem must be quick or in near real-time, companies can use knowledge mining to avoid costly mistakes",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/knowledge-mining-business-process-management.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\knowledge-mining-business-process-management.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>This architecture demonstrates how to use Knowledge Mining for business process management.</p>\n<p>When organizations task employees with the review and research of technical data, it can be tedious to read page after page of dense text. Knowledge mining helps employees quickly review these materials. In industries where bidding competition is fierce, or when the diagnosis of a problem must be quick or in near real-time, companies can use knowledge mining to avoid costly mistakes.</p>\n<p><img alt=\"Architecture Diagram\" src=\"https://learn.microsoft.com/azure/architecture/solution-ideas/media/knowledge-mining-business-process-management.png\" /></p>",
            "Flow": {
                "FlowStep_A": "This content is enriched by using optical character recognition, forms recognition, layout understanding, table extraction, key-value pair extraction",
                "FlowStep_B": "And finally, the user can automatically populate data from invoices into ELP systems or databases or compile enriched documents in the knowledge store and project them into tabular or object stores, then surface trends in an analytics dashboard, such as frequent issues, popular products, and much more"
            },
            "name": "business-process-management",
            "popularity": 0,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-cicd-for-azure-vms-'",
                "acom-architecture",
                "all-items",
                "ci-cd",
                "continuous-delivery",
                "continuous-deployment",
                "continuous-integration",
                "data-flow",
                "devops",
                "interactive-diagram",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/cicd-for-azure-vms.md",
            "http_url": "/azure/architecture/solution-ideas/articles/cicd-for-azure-vms",
            "word_count": 319,
            "read_time": "2 min read",
            "Title": "CI/CD for Azure VMs",
            "MetaDescription": "Azure is a world-class cloud for hosting virtual machines running Windows or Linux. Whether you use ASP.NET, Java, Node.js, or PHP to develop applications, you'll need a continuous integration and continuous deployment (CI/CD) pipeline to push changes to these virtual machines automatically.",
            "category": [
                "devops",
                "compute",
                "web"
            ],
            "image": "/azure/architecture/solution-ideas/media/cicd-for-azure-vms.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\cicd-for-azure-vms.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/virtual-machines\">Virtual Machines</a>: Provision Windows and Linux virtual machines in seconds</p>",
                "<p><a href=\"https://azure.microsoft.com/services/devtest-lab\">Azure DevTest Labs</a>: Quickly create environments using reusable templates and artifacts</p>",
                "<p><a href=\"https://azure.microsoft.com/services/monitor\">Application Insights</a>: Detect, triage, and diagnose issues in your web apps and services.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/devops\">Azure DevOps</a>: Build and deploy multi-platform apps to get the most from Azure services</p>"
            ],
            "Flow": {
                "FlowStep_A": "Change application source code",
                "FlowStep_B": "Commit Application Code and Azure Resource Manager (ARM) Template",
                "FlowStep_C": "Continuous integration triggers application build and unit tests",
                "FlowStep_D": "Continuous deployment trigger orchestrates deployment of application artifacts with environment-specific parameters",
                "FlowStep_E": "Deployment to QA environment",
                "FlowStep_F": "Deployment to staging environment",
                "FlowStep_G": "Deployment to production environment",
                "FlowStep_H": "Application Insights collects and analyses health, performance, and usage data",
                "FlowStep_I": "Review health, performance and usage information",
                "FlowStep_J": "Update backlog item"
            },
            "name": "cicd-for-azure-vms",
            "popularity": 201,
            "topic": "DevOps"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-azure-devops-continuous-integration-and-continuous-deployment-for-azure-web-apps-'",
                "acom-architecture",
                "all-items",
                "ci-cd",
                "continuous-delivery",
                "continuous-deployment",
                "continuous-integration",
                "data-flow",
                "devops",
                "interactive-diagram",
                "is-deployable",
                "pricing-calculator",
                "pricing-guidance",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/azure-devops-continuous-integration-and-continuous-deployment-for-azure-web-apps.md",
            "http_url": "/azure/architecture/solution-ideas/articles/azure-devops-continuous-integration-and-continuous-deployment-for-azure-web-apps",
            "word_count": 252,
            "read_time": "2 min read",
            "Title": "CI/CD for Azure Web Apps",
            "MetaDescription": "Azure Web Apps is a fast and simple way to create web apps using ASP.NET, Java, Node.js, or PHP. Deliver value faster to your customers with a continuous integration and continuous deployment (CI/CD) pipeline that pushes each of your changes automatically to Web Apps.",
            "category": [
                "devops",
                "web",
                "featured"
            ],
            "image": "/azure/architecture/solution-ideas/media/azure-devops-continuous-integration-and-continuous-deployment-for-azure-web-apps.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\azure-devops-continuous-integration-and-continuous-deployment-for-azure-web-apps.png",
            "publish_date": "12/16/2019",
            "pricing_calculator": "https://azure.com/e/b96a4a9dbf804edabc83d00b41ffb245",
            "pricing_guidance": "pricing-calculator",
            "components": [
                "<p>Application Insights: Detect, triage, and diagnose issues in your web apps and services.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/app-service/web\">Web Apps</a>: Quickly create and deploy mission critical Web apps at scale.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/devops\">Azure DevOps</a>: Services for teams to share code, track work, and ship software.</p>",
                "<p><a href=\"https://www.visualstudio.com/vs/azure\">Visual Studio</a>: A creative launch pad for viewing and editing code,  then debugging, building, and publishing apps for Android, iOS, Windows, the web, and the cloud.</p>"
            ],
            "Flow": {
                "FlowStep_A": "Change application source code.",
                "FlowStep_B": "Commit application code and Web Apps web.config file.",
                "FlowStep_C": "Continuous integration triggers application build and unit tests.",
                "FlowStep_D": "Continuous deployment trigger orchestrates deployment of application artifacts with environment-specific parameters.",
                "FlowStep_E": "Deployment to Web Apps.",
                "FlowStep_F": "Azure Application Insights collects and analyzes health, performance, and usage data.",
                "FlowStep_G": "Review health, performance, and usage information.",
                "FlowStep_H": "Update backlog item."
            },
            "name": "azure-devops-continuous-integration-and-continuous-deployment-for-azure-web-apps",
            "popularity": 210,
            "topic": "DevOps"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-cicd-for-containers-'",
                "acom-architecture",
                "all-items",
                "ci-cd",
                "continuous-delivery",
                "continuous-deployment",
                "continuous-integration",
                "data-flow",
                "devops",
                "interactive-diagram",
                "pricing-calculator",
                "pricing-guidance",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/cicd-for-containers.md",
            "http_url": "/azure/architecture/solution-ideas/articles/cicd-for-containers",
            "word_count": 257,
            "read_time": "2 min read",
            "Title": "CI/CD for Containers",
            "MetaDescription": "Containers make it easy for you to continuously build and deploy your applications. By orchestrating deployment of those containers using Kubernetes in Azure Kubernetes Service (AKS), you can achieve replicable, manageable clusters of containers.",
            "category": [
                "devops",
                "containers"
            ],
            "image": "/azure/architecture/solution-ideas/media/cicd-for-containers.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\cicd-for-containers.png",
            "publish_date": "12/16/2019",
            "pricing_calculator": "https://azure.com/e/91c84e39f4df46afaf6c6c433b2c7d78",
            "pricing_guidance": "pricing-calculator",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/container-registry\">Container Registry</a>: Store and manage container images across all types of Azure deployments</p>",
                "<p><a href=\"https://azure.microsoft.com/services/kubernetes-service\">Azure Kubernetes Service (AKS)</a>: Simplify the deployment, management, and operations of Kubernetes</p>",
                "<p>Application Insights: Detect, triage, and diagnose issues in your web apps and services</p>",
                "<p><a href=\"https://azure.microsoft.com/services/devops\">Azure DevOps</a>: Build and deploy multi-platform apps to get the most from Azure services</p>"
            ],
            "Flow": {
                "FlowStep_A": "Change application source code",
                "FlowStep_B": "Commit Application Code",
                "FlowStep_C": "Continuous integration triggers application build, container image build and unit tests",
                "FlowStep_D": "Container image pushed to Azure Container Registry",
                "FlowStep_E": "Continuous deployment trigger orchestrates deployment of application artifacts with environment-specific parameters",
                "FlowStep_F": "Deployment to Azure Kubernetes Service (AKS)",
                "FlowStep_G": "Container is launched using Container Image from Azure Container Registry",
                "FlowStep_H": "Application Insights collects and analyses health, performance, and usage data",
                "FlowStep_I": "Review health, performance and usage information",
                "FlowStep_J": "Update backlog item"
            },
            "name": "cicd-for-containers",
            "popularity": 192,
            "topic": "DevOps"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "azurecli-interactive",
                "data-flow",
                "devops",
                "example-code",
                "example-workload",
                "is-deployable",
                "microservices",
                "pricing-calculator",
                "pricing-guidance"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/apps/devops-with-aks.yml",
            "http_url": "/azure/architecture/example-scenario/apps/devops-with-aks",
            "word_count": 1610,
            "read_time": "7 min read",
            "Title": "CI/CD pipeline for container-based workloads",
            "MetaDescription": "Build a DevOps pipeline for a Node.js web app with Jenkins, Azure Container Registry, Azure Kubernetes Service, Azure Cosmos DB, and Grafana.",
            "category": [
                "containers",
                "devops",
                "featured",
                "compute"
            ],
            "image": "/azure/architecture/example-scenario/apps/media/architecture-devops-with-aks.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\apps\\media\\architecture-devops-with-aks.png",
            "publish_date": "7/05/2018",
            "deployable": "https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2Fmspnp%2Fsolution-architectures%2Fmaster%2Fapps%2Fdevops-with-aks%2Fazuredeploy.json",
            "pricing_calculator": "https://azure.com/e/841f0a75b1ea4802ba1ac8f7918a71e7",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "components": [
                "<p><a href=\"https://jenkins.io\">Jenkins</a> is an open-source automation server that can integrate with Azure services to enable continuous integration (CI) and continuous deployment (CD). In this scenario, Jenkins orchestrates the creation of new container images based on commits to source control, pushes those images to Azure Container Registry, then updates application instances in Azure Kubernetes Service.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-machines/linux/overview\">Azure Linux Virtual Machines</a> is the IaaS platform used to run the Jenkins and Grafana instances.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/container-registry/container-registry-intro\">Azure Container Registry</a> stores and manages container images that are used by the Azure Kubernetes Service cluster. Images are securely stored, and can be replicated to other regions by the Azure platform to speed up deployment times.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/aks/intro-kubernetes\">Azure Kubernetes Service</a> is a managed Kubernetes platform that lets you deploy and manage containerized applications without container orchestration expertise. As a hosted Kubernetes service, Azure handles critical tasks like health monitoring and maintenance for you.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/cosmos-db/introduction\">Azure Cosmos DB</a> is a globally distributed, multi-model database that allows you to choose from various database and consistency models to suit your needs. With Azure Cosmos DB, your data can be globally replicated, and there is no cluster management or replication components to deploy and configure.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/monitoring-and-diagnostics/monitoring-overview\">Azure Monitor</a> helps you track performance, maintain security, and identify trends. Metrics obtained by Monitor can be used by other resources and tools, such as Grafana.</p>",
                "<p><a href=\"https://grafana.com\">Grafana</a> is an open-source solution to query, visualize, alert, and understand metrics. A data source plugin for Azure Monitor allows Grafana to create visual dashboards to monitor the performance of your applications running in Azure Kubernetes Service and using Azure Cosmos DB.</p>"
            ],
            "Flow": {
                "FlowStep_A": "A developer makes changes to the Node.js web application source code.",
                "FlowStep_B": "The code change is committed to a source control repository, such as GitHub.",
                "FlowStep_C": "To start the continuous integration (CI) process, a GitHub webhook triggers a Jenkins project build.",
                "FlowStep_D": "The Jenkins build job uses a dynamic build agent in Azure Kubernetes Service to perform a container build process.",
                "FlowStep_E": "A container image is created from the code in source control, and is then pushed to an Azure Container Registry.",
                "FlowStep_F": "Through continuous deployment (CD), Jenkins deploys this updated container image to the Kubernetes cluster.",
                "FlowStep_G": "The Node.js web application uses Azure Cosmos DB as its back end. Both Azure Cosmos DB and Azure Kubernetes Service report metrics to Azure Monitor.",
                "FlowStep_H": "A Grafana instance provides visual dashboards of the application performance based on the data from Azure Monitor."
            },
            "code_languages": [
                "azurecli-interactive"
            ],
            "sample_code": true,
            "name": "devops-with-aks",
            "popularity": 196,
            "topic": "Containers"
        },
        {
            "tags": [
                "all-items",
                "fcp",
                "iot",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/cctv-iot-edge-for-covid-19-safe-environment-and-mask-detection.md",
            "http_url": "/azure/architecture/solution-ideas/articles/cctv-iot-edge-for-covid-19-safe-environment-and-mask-detection",
            "word_count": 706,
            "read_time": "3 min read",
            "Title": "COVID-19 Safe Solutions with IoT Edge",
            "MetaDescription": "Learn how to use CCTV, IoT Edge analytics and machine learning, and cloud services to monitor social distancing, mask/PPE use, and occupancy requirements.",
            "category": [
                "iot",
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/bosch-cctv-iot-edge-covid-19-safe-environment-mask-detection.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\bosch-cctv-iot-edge-covid-19-safe-environment-mask-detection.png",
            "publish_date": "6/06/2020",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/iot-edge/\">Azure IoT Edge</a> servers with onboard storage, computing, artificial intelligence (AI), and machine learning (ML) capabilities can quickly recognize and respond to sensor input.</p>",
                "<p>Bosch video analytics use <a href=\"https://azure.microsoft.com/services/cognitive-services/custom-vision-service/\">Custom Vision</a> skills and <a href=\"https://azure.microsoft.com/services/machine-learning/\">Azure Machine Learning</a> to continually improve monitoring, detection, and real-time alert triggering.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/digital-twins/\">Azure Digital Twins</a> IoT service creates comprehensive models of physical environments in a spatial intelligence graph. Rather than simply tracking individual devices, Digital Twins can virtually replicate the physical world by modeling the relationships between people, places, and devices.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/stream-analytics\">Azure Stream Analytics (ASA)</a> provides real-time serverless stream processing that can run the same queries in the cloud and on the edge. ASA on IoT Edge can filter or aggregate data that needs to be sent to the cloud for further processing or storage.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage/\">Azure Storage</a> provides flexible, scalable, secure <a href=\"https://azure.microsoft.com/services/storage/blobs/\">Blob storage</a> for unstructured data in the Azure cloud or on the IoT Edge. The current solution also uses <a href=\"https://azure.microsoft.com/services/cache/\">Redis</a> and <a href=\"https://www.mongodb.com/cloud/atlas/azure-mongodb\">mongoDB</a> data storage.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/service-bus/\">Azure Service Bus</a> messaging through <a href=\"https://azure.microsoft.com/services/iot-hub/\">Azure IoT Hub</a> connects devices to Azure cloud resources, and can use queries to filter data to be sent to the cloud.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/kubernetes-service/\">Azure Kubernetes Service (AKS)</a> is a managed service for developing, deploying, and managing containerized applications. In this solution, AKS manages an interactive visual dashboard app that tracks and analyzes safety violations.</p>",
                "<p>By integrating with the Azure cloud, the solution can use services like <a href=\"https://azure.microsoft.com/services/monitor/\">Azure Monitor</a>, <a href=\"https://azure.microsoft.com/services/security-center/\">Azure Security Center</a>, and <a href=\"https://azure.microsoft.com/services/active-directory/\">Azure Active Directory</a>.</p>",
                "<p>Integration with Microsoft <a href=\"https://support.office.com/article/manage-notifications-in-teams-1cc31834-5fe5-412b-8edb-43fecc78413d\">Teams</a> allows automated notifications of relevant stakeholders like HR and Security.</p>",
                "<p><a href=\"https://powerbi.microsoft.com\">Microsoft Power BI</a> visualizations enable well-informed and data-driven reporting and decision making.</p>"
            ],
            "name": "cctv-iot-edge-for-covid-19-safe-environment-and-mask-detection",
            "popularity": 0,
            "topic": "Internet of Things"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-campaign-optimization-with-sql-server-'",
                "acom-architecture",
                "ai-gallery",
                "all-items",
                "artificial-intelligence",
                "azure",
                "pricing-guidance",
                "solution-architectures",
                "solution-idea",
                "sql-server"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/campaign-optimization-with-sql-server.md",
            "http_url": "/azure/architecture/solution-ideas/articles/campaign-optimization-with-sql-server",
            "word_count": 1076,
            "read_time": "5 min read",
            "Title": "Campaign Optimization with SQL Server",
            "MetaDescription": "This solution demonstrates how to build and deploy a machine learning model with SQL Server 2016 with R Services to recommend actions to maximize the purchase rate of leads targeted by a campaign.",
            "category": [
                "databases",
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/campaign-optimization-with-sql-server.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\campaign-optimization-with-sql-server.png",
            "publish_date": "12/16/2019",
            "pricing_guidance": "pricing",
            "Summary": "<p>This solution demonstrates how to build and deploy a machine learning model with SQL Server 2016 with R Services to recommend actions to maximize the purchase rate of leads targeted by a campaign.</p>",
            "name": "campaign-optimization-with-sql-server",
            "popularity": 18,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "data-flow",
                "fcp",
                "solution-idea",
                "visio-diagram"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/appconfig-key-vault.md",
            "http_url": "/azure/architecture/solution-ideas/articles/appconfig-key-vault",
            "word_count": 463,
            "read_time": "3 min read",
            "Title": "Centralized app configuration and security",
            "MetaDescription": "Use Azure App Configuration and Azure Key Vault to create a centralized and secured configuration service for apps.",
            "category": [
                "security",
                "management-and-governance"
            ],
            "image": "/azure/architecture/solution-ideas/media/appconfig-development.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\appconfig-development.png",
            "publish_date": "5/13/2020",
            "Summary": "<p>Cloud-based applications often run on multiple virtual machines or containers in multiple regions, and use multiple external services. Creating a robust and scalable application in a distributed environment presents a significant challenge. <a href=\"https://learn.microsoft.com/azure/azure-app-configuration/overview\">Azure App Configuration</a> lets you manage and store all your app's configuration settings and feature flags, and secure access settings, in one place.</p>\n<p>App Configuration works seamlessly with <a href=\"https://azure.microsoft.com/services/key-vault/\">Azure Key Vault</a>, which stores passwords, keys, and secrets for secure access. This article presents best practices for using App Configuration and Key Vault in development and Azure environments.</p>",
            "Flow": {
                "FlowStep_A": "The application sends an authentication request during debugging in Visual Studio, or authenticates via the MSI in Azure.",
                "FlowStep_B": "Upon successful authentication, Azure AD returns an access token.",
                "FlowStep_C": "The App Configuration SDK sends a request with the access token to read the app's App Configuration KeyVault **secretURI** value for the app's key vault. ",
                "FlowStep_D": "Upon successful authorization, App Configuration sends the configuration value. ",
                "FlowStep_E": "Using the sign-in identity, the app sends a request to Azure Key Vault to retrieve the application secret for the **secretURI** that App Configuration sent.",
                "FlowStep_F": "Upon successful authorization, Key Vault returns the secret value."
            },
            "visio_diagram": "https://arch-center.azureedge.net/AppConfig_Development.vsdx",
            "name": "appconfig-key-vault",
            "popularity": 0,
            "topic": "Security"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "azurecli-interactive",
                "data-flow",
                "example-code",
                "example-workload",
                "github",
                "is-deployable",
                "pricing-calculator",
                "pricing-guidance"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/ai/commerce-chatbot.md",
            "http_url": "/azure/architecture/example-scenario/ai/commerce-chatbot",
            "word_count": 1384,
            "read_time": "6 min read",
            "Title": "Chatbot for hotel reservations",
            "MetaDescription": "Build a conversational chatbot for commerce applications with Azure Bot Service.",
            "category": [
                "ai-machine-learning",
                "web"
            ],
            "image": "/azure/architecture/example-scenario/ai/media/architecture-commerce-chatbot.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\ai\\media\\architecture-commerce-chatbot.png",
            "publish_date": "7/05/2018",
            "deployable": "https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2Fmspnp%2Fsolution-architectures%2Fmaster%2Fapps%2Fcommerce-chatbot.json",
            "pricing_calculator": "https://azure.com/e/dce05b6184904c50b38e1a8654f726b6",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/active-directory\">Azure Active Directory (Azure AD)</a> is Microsoft's multitenant cloud-based directory and identity management service. Azure AD supports a B2C connector allowing you to identify individuals using external IDs such as Google, Facebook, or a Microsoft Account.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/app-service\">App Service</a> enables you to build and host web applications in the programming language of your choice without managing infrastructure.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/bot-service\">Bot Service</a> provides tools to build, test, deploy, and manage intelligent bots.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/cognitive-services\">Cognitive Services</a> lets you use intelligent algorithms to see, hear, speak, understand, and interpret your user needs through natural methods of communication.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/sql-database\">SQL Database</a> is a fully managed relational cloud database service that provides SQL Server engine compatibility.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/application-insights/app-insights-overview\">Application Insights</a> is an extensible Application Performance Management (APM) service that lets you monitor the performance of applications, such as your chatbot.</p>"
            ],
            "Summary": "<p>This example scenario is applicable to businesses that need to integrate a conversational chatbot into applications. In this scenario, a C# chatbot is used for a hotel chain that allows customers to check availability and book accommodation through a web or mobile application.</p>\n<p>Potential uses include providing a way for customers to view hotel availability and book rooms, review a restaurant take-out menu and place a food order, or search for and order prints of photographs. Traditionally, businesses would need to hire and train customer service agents to respond to these customer requests, and customers would have to wait until a representative is available to provide assistance.</p>\n<p>By using Azure services such as the Bot Service and Language Understanding or Speech API services, companies can assist customers and process orders or reservations with automated, scalable bots.</p>",
            "Flow": {
                "FlowStep_A": "The customer accesses the chatbot with a mobile or web app.",
                "FlowStep_B": "Using Azure Active Directory (Azure AD) B2C (business-to-consumer), the user is authenticated.",
                "FlowStep_C": "Interacting with the Bot Service, the user requests information about hotel availability.",
                "FlowStep_D": "Cognitive Services processes the natural language request to understand the customer communication.",
                "FlowStep_E": "After the user is happy with the results, the bot adds or updates the customer's reservation in a SQL Database.",
                "FlowStep_F": "Application Insights gathers runtime telemetry throughout the process to help the DevOps team with bot performance and usage."
            },
            "sample_code": true,
            "github_url": "https://github.com/Microsoft/AzureBotServices-scenarios/tree/master/CSharp/Commerce/src",
            "code_languages": [
                "azurecli-interactive"
            ],
            "name": "commerce-chatbot",
            "popularity": 170,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "all-items",
                "fcp",
                "networking",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/hybrid-networking/vnet-peering.md",
            "http_url": "/azure/architecture/reference-architectures/hybrid-networking/vnet-peering",
            "word_count": 810,
            "read_time": "3 min read",
            "Title": "Choose between virtual network peering and VPN gateways",
            "MetaDescription": "Compares two ways to connect virtual networks in Azure.",
            "category": [
                "networking",
                "integration"
            ],
            "image": "/azure/architecture/_images/reference-architectures.svg",
            "publish_date": "12/13/2019",
            "Summary": "<p>This article compares two ways to connect virtual networks in Azure: virtual network peering and VPN gateways.</p>\n<p>A virtual network is a virtual, isolated portion of the Azure public network. By default, traffic cannot be routed between two virtual networks. However, it's possible to connect virtual networks, either within a single region or across two regions, so that traffic can be routed between them. </p>",
            "name": "vnet-peering",
            "popularity": 206,
            "topic": "Networking"
        },
        {
            "tags": [
                "all-items",
                "data-flow",
                "fcp",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/safe-buildings.md",
            "http_url": "/azure/architecture/solution-ideas/articles/safe-buildings",
            "word_count": 882,
            "read_time": "4 min read",
            "Title": "Cognizant Safe Buildings with IoT and Azure",
            "MetaDescription": "Deploy Cognizant Safe Buildings, IoT, and Azure services to protect buildings from COVID-19 outbreaks.",
            "category": [
                "iot"
            ],
            "image": "/azure/architecture/solution-ideas/media/safe-building-arch-design.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\safe-building-arch-design.png",
            "publish_date": "6/09/2020",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/iot-edge/\">Azure IoT Edge</a> allows you to deploy your cloud workloads to run on Internet of Things (IoT) edge devices via standard containers. Workloads like artificial intelligence, Azure and third-party services, or your own business logic.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/iot-hub/\">Azure IoT Hub</a> enables highly secure and reliable communication between your IoT application and the devices it manages.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/kubernetes-service/\">Azure Kubernetes Service</a> deploy and manage containerized applications more easily with a fully managed Kubernetes service.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/stream-analytics/\">Azure Stream Analytics</a> is an easy-to-use, real-time analytics service designed for mission-critical workloads.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/databricks/\">Azure Databricks</a> unlocks insights from all your data and build artificial intelligence (AI) solutions. Set up your Apache Spark environment in minutes, autoscale, and collaborate on shared projects in an interactive workspace.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage/data-lake-storage/\">Azure Data Lake Storage</a> - A highly scalable and cost-effective data lake solution for big data analytics.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cosmos-db/\">Azure Cosmos DB</a> -  A fully managed NoSQL database service for modern app development. Azure Cosmos DB has guaranteed single-digit millisecond response times. It also guarantees 99.999-percent availability backed by SLAs, automatic and instant scalability, and open-source APIs for MongoDB and Cassandra.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/postgresql/\">Azure Database for PostgreSQL</a> - Focus on application innovation, not database management, with fully managed and intelligent Azure Database for PostgreSQL.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/sql-database/\">Azure SQL Database</a> - The intelligent, scalable, relational database service built for the cloud. It\u2019s evergreen and always up to date, with AI-powered and automated features that optimize performance and durability for you.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cache/\">Azure Cache for Redis</a> - Fully managed, open source\u2013compatible in-memory data store to power fast, scalable applications.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/machine-learning/\">Azure Machine Learning</a> empowers developers and data scientists to build, train, and deploy machine learning models faster. Continuous retraining, updating, and improving data collection and analysis makes the models better over time.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/monitor/\">Azure Monitor</a> collects, analyzes, and acts on telemetry data from your Azure and on-premises environments.</p>",
                "<p><a href=\"https://powerbi.microsoft.com/\">Power BI</a> enables team members to discover insights hidden in your data.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/functions/\">Azure Functions</a> lets you build and debug locally without additional setup, deploy and operate at scale in the cloud, and integrate services using triggers and bindings.</p>",
                "<p>In addition, <strong>Safe Buildings</strong> has access to these other Azure services: <a href=\"https://azure.microsoft.com/services/active-directory/\">Azure Active Directory</a>, <a href=\"https://azure.microsoft.com/services/api-management/\">Azure API Management</a>, <a href=\"https://azure.microsoft.com/services/storage/blobs/\">Azure Blob storage</a>, <a href=\"https://azure.microsoft.com/services/container-registry/\">Azure Container Registry</a>, <a href=\"https://azure.microsoft.com/services/data-factory/\">Azure Data Factory</a>, <a href=\"https://azure.microsoft.com/services/event-hubs/\">Azure Event Hubs</a>, <a href=\"https://azure.microsoft.com/services/key-vault/\">Azure Key Vault</a>, <a href=\"https://azure.microsoft.com/services/logic-apps/\">Azure Logic App</a>, <a href=\"https://azure.microsoft.com/services/notification-hubs/\">Azure Notification Hubs</a>, <a href=\"https://azure.microsoft.com/services/virtual-machines/\">Azure VMs</a>, <a href=\"https://azure.microsoft.com/services/app-service/web/\">Azure Webapp Service</a>.</p>"
            ],
            "Summary": "<p>The world is cautiously reopening in a physical business environment where COVID-19 remains a factor. To help keep people healthy, <a href=\"https://www.cognizant.com/\">Cognizant</a> adapted their <a href=\"https://azuremarketplace.microsoft.com/en-us/marketplace/consulting-services/cognizant.one_facility\">OneFacility</a> solution to make workspaces safer for everyone who enters them. The <strong>Cognizant Safe Buildings</strong> solution provides a strategic approach to create safe buildings with sustainably healthy working environments.</p>\n<p>The solution monitors critical insights so you can act and respond to risks. It also builds confidence that you're focused on making sure people are safe. The measurements the solution reacts to are: human body temperature, effective physical distancing, hand sanitization compliance, and air quality tracking.</p>\n<p>Using <a href=\"https://azure.microsoft.com/services/iot-hub/\">Azure IoT Hub</a> and other Azure services, the <strong>Cognizant Safe Buildings</strong> solution brings together people, regulations, analytics, and technology to transform smart buildings into safe buildings. Through the use of different devices, the solution collects biometric and environmental data. When the system detects any deviation to health and safety protocol in a building, the solution activates. <strong>Safe Buildings</strong> layers safety controls to protect, monitor, and respond with real-time alerts.</p>",
            "Flow": {
                "FlowStep_A": "The server feeds the data to the Azure IoT Hub, Azure Data Factory, and Azure Blob storage.",
                "FlowStep_B": "The Azure IoT Hub sends data through an Azure Kubernetes Service (AKS).",
                "FlowStep_C": "AKS routes the data so Azure Stream Analytics and Azure Databricks can analyze and enrich it.",
                "FlowStep_D": "**Safe Buildings** sends the processed data to various data stores:",
                "FlowStep_E": "From there, different services and APIs consume the data:"
            },
            "name": "safe-buildings",
            "popularity": 0,
            "topic": "Internet of Things"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-commerce-chatbot-'",
                "acom-architecture",
                "all-items",
                "bot-service",
                "chatbot",
                "data-flow",
                "interactive-diagram",
                "luis",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/commerce-chatbot.md",
            "http_url": "/azure/architecture/solution-ideas/articles/commerce-chatbot",
            "word_count": 167,
            "read_time": "1 min read",
            "Title": "Commerce Chatbot",
            "MetaDescription": "The Azure Bot Service with Language Understanding enables developers to create conversational interfaces for banking, travel, and entertainment commerce scenarios. For example, a hotel concierge can use a bot to enhance traditional e-mail and phone call interactions. The bot validates a customer via Azure Active Directory and uses Azure Cognitive Services to contextually process customer service requests using text and voice. Add the Speech recognition service to support voice commands.",
            "category": [
                "ai-machine-learning",
                "web"
            ],
            "image": "/azure/architecture/solution-ideas/media/commerce-chatbot-customer-service.svg",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\commerce-chatbot-customer-service.svg",
            "publish_date": "12/16/2019",
            "Summary": "<p>The Azure Bot Service with Language Understanding enables developers to create conversational interfaces for banking, travel, and entertainment commerce scenarios. For example, a hotel concierge can use a bot to enhance traditional e-mail and phone call interactions. The bot validates a customer via Azure Active Directory and uses Azure Cognitive Services to contextually process customer service requests using text and voice. Add the Speech recognition service to support voice commands.</p>",
            "Flow": {
                "FlowStep_A": "Customer uses your mobile app",
                "FlowStep_B": "Using Azure AD B2C, the user authenticates",
                "FlowStep_C": "Using the custom Application Bot, user requests information",
                "FlowStep_D": "Cognitive Services helps process the natural language request",
                "FlowStep_E": "Response is reviewed by customer who can refine the question using natural conversation",
                "FlowStep_F": "Once the user is happy with the results, the Application Bot updates the customer's reservation"
            },
            "name": "commerce-chatbot",
            "popularity": 59,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "data-flow",
                "example-code",
                "example-workload",
                "fcp",
                "github",
                "powershell"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/forensics/index.md",
            "http_url": "/azure/architecture/example-scenario/forensics",
            "word_count": 1794,
            "read_time": "8 min read",
            "Title": "Computer forensics Chain of Custody in Azure",
            "MetaDescription": "Create an infrastructure and workflow to ensure a valid digital evidence Chain of Custody (CoC) for computer forensics in Azure.",
            "category": [
                "security"
            ],
            "image": "/azure/architecture/example-scenario/forensics/media/chain-of-custody.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\forensics\\media\\chain-of-custody.png",
            "publish_date": "4/27/2020",
            "alternative_choices": "alternatives",
            "Summary": "<p>Digital forensics is a science that addresses the recovery and investigation of digital data to support criminal investigations or civil proceedings. Computer forensics is a branch of digital forensics that captures and analyzes data from computers, virtual machines (VMs), and digital storage media.</p>\n<p>Companies must guarantee that digital evidence they provide in response to legal requests demonstrates a valid <em>Chain of Custody</em> (CoC) throughout the evidence acquisition, preservation, and access process. To ensure a valid CoC, digital evidence storage must demonstrate adequate access control, data protection and integrity, monitoring and alerting, and logging and auditing.</p>",
            "Flow": {
                "FlowStep_A": "Sign in to the SOC subscription in the Azure portal, and select their Azure Automation account.",
                "FlowStep_B": "Edit the Copy-VmDigitalEvidence runbook to supply the following information:",
                "FlowStep_C": "Access the Hybrid Runbook Worker VM, which has a managed identity or service principal for the Azure tenant, and run the Copy-VmDigitalEvidence runbook.",
                "FlowStep_D": "The Activity Logs register the runbook execution, and store the related data in Log Analytics for further analysis.",
                "FlowStep_E": "Signs in to the Azure SOC subscription.",
                "FlowStep_F": "Signs in to the target VM and creates the OS disk snapshot",
                "FlowStep_G": "Copies the snapshot to the immutable SOC Blob Storage account and to the temporary SOC Azure file share",
                "FlowStep_H": "Calculates the SHA-256 hash value of snapshot on the file share",
                "FlowStep_I": "Accesses the target VM's key vault and copies the VM's BEK, and KEK if applicable, to the SOC key vault. A secret named with the thumbprint of the runbook execution contains the encryption key and all the tags to identify the disk and volume.",
                "FlowStep_J": "Stores the calculated SHA-256 hash value into the SOC key vault.",
                "FlowStep_K": "Removes the temporary copy of the snapshot from the SOC Azure file share.",
                "FlowStep_L": "Repeats the disk snapshots, snapshot and key copying, and hash generation and copying for each data disk attached to the VM.",
                "FlowStep_M": "Removes all the source snapshots generated during the process."
            },
            "sample_code": true,
            "github_url": "https://github.com/mspnp/solution-architectures/blob/master/forensics/Copy-VmDigitalEvidence.ps1",
            "code_languages": [
                "powershell"
            ],
            "name": "forensics",
            "popularity": 0,
            "topic": "Security"
        },
        {
            "tags": [
                "acom-architecture",
                "all-items",
                "data-flow",
                "example-code",
                "github",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/condition-monitoring.md",
            "http_url": "/azure/architecture/solution-ideas/articles/condition-monitoring",
            "word_count": 1285,
            "read_time": "6 min read",
            "Title": "Condition Monitoring for Industrial IoT",
            "MetaDescription": "This example demonstrates how manufacturers can connect their assets to the cloud using OPC UA and the Industrial Components.",
            "category": [
                "iot",
                "analytics",
                "containers"
            ],
            "image": "/azure/architecture/solution-ideas/media/condition-monitoring.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\condition-monitoring.png",
            "publish_date": "8/05/2020",
            "Summary": "<p>This example scenario demonstrates how end manufacturers can connect their assets to the cloud using OPC UA (Open Platform Communication Unified Architecture) and the Industrial Components. They can monitor their equipment's key parameters to discover anomalies before they become critical issues. OPC UA is a platform-independent and service-oriented interoperability standard for a secure and reliable data exchange. OPC UA is used by various industrial systems and devices such as industry PCs, PLCs, and sensors. It's a standard that is driven by the OPC Foundation.</p>",
            "Flow": {
                "FlowStep_A": "Industrial devices that can natively communicate OPC UA can directly connect to IoT Edge. IoT Edge is the compute power that sits on your on-premises network. It\u2019s the runtime environment of the Industrial Modules (OPC Publisher, OPC Twin, and Discovery Module). Modules are containers that run Azure services, 3rd party services, or your own code. The OPC Publisher module connects to OPC UA servers and publishes OPC UA telemetry data to Azure IoT Hub. OPC Twin creates a digital twin of an OPC UA server in the cloud and provides OPC UA browse/read/write/method call capabilities via a cloud-based REST (Representational State Transfer) interface. The Discovery module provides discovery services on the edge, which include OPC UA server discovery.",
                "FlowStep_B": "Industrial devices that can\u2019t communicate through OPC UA need a 3rd party PLC adapter to connect to IoT Edge. Adapters are obtainable as modules in the [Azure Marketplace](https://azuremarketplace.microsoft.com/marketplace/).",
                "FlowStep_C": "The 3rd party PLC adapters enable a connectivity between the devices and IoT Edge.",
                "FlowStep_D": "For analytical capabilities closer to where the data originates, there are modules like Machine Learning on Edge or Functions obtainable from the Azure Marketplace, allowing low latency and operation in disconnected state.",
                "FlowStep_E": "Azure IoT Hub connects the devices virtually to the cloud for further data processing. It enables a security-enhanced bidirectional communication between IoT applications and devices.",
                "FlowStep_F": "The Industrial Services are made up of several microservices exposing a REST API. All Industrial Services are deployed to an Azure Kubernetes Service cluster. They implement business logic and functionality for discovery, registration, remote control, and post-processing telemetry of industrial devices. The REST APIs can be used in any programming language and framework that can call an HTTP endpoint.",
                "FlowStep_G": "Azure Event Hubs transforms and stores the data. It provides a distributed stream processing platform with low latency and seamless integration.",
                "FlowStep_H": "_Alternative 1:_ Store and analyze the data using Azure Time Series Insights (TSI). The telemetry processor in the Industrial IoT platform forwards contextualized samples to TSI and other consumers.",
                "FlowStep_I": "The Time Series Insights Explorer is a web application you can use to visualize the telemetry.",
                "FlowStep_J": "_Alternative 2:_ After the Industrial Services process the data, Azure Data Lake stores and further analyzes the data. Azure Data Lake is a massively scalable data lake with enterprise-grade security and auditing, which allows batch, stream and interactive analytic programs to run with simplicity. Azure Data Lake solves many of the productivity and scalability challenges that prevent you from maximizing the value of your data assets.",
                "FlowStep_K": "Explore your data with visual reports and collaborate, publish and share them with others. Power BI integrates with other tools, including Microsoft Excel, so you can get up to speed quickly and work seamlessly with your existing solutions.",
                "FlowStep_L": "_Alternative 3:_ Azure Stream Analytics is a real time analytics service. It\u2019s easily extensible with custom code and built-in machine learning capabilities for more advanced scenarios.",
                "FlowStep_M": "Azure Functions is a serverless compute service, which allows you to run small pieces of code (called \"functions\") without worrying about application infrastructure. With Azure Functions, the cloud infrastructure provides all the up-to-date servers you need to keep your application running at scale.",
                "FlowStep_N": "Azure Notification Hubs allow you to send notifications to a wide range of mobile platforms and can allow notification of operators and administrators on certain events or alerts which require immediate attention."
            },
            "sample_code": true,
            "github_url": "https://github.com/Azure/Industrial-IoT/blob/master/docs/modules/discovery.md",
            "name": "condition-monitoring",
            "popularity": 0,
            "topic": "Internet of Things"
        },
        {
            "tags": [
                "all-items",
                "networking",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/hybrid-networking/index.yml",
            "http_url": "/azure/architecture/reference-architectures/hybrid-networking",
            "word_count": 519,
            "read_time": "2 min read",
            "Title": "Connect an on-premises network to Azure",
            "MetaDescription": "Compare reference architectures for connecting an on-premises network to Azure.",
            "category": [
                "hybrid",
                "networking"
            ],
            "image": "/azure/architecture/_images/reference-architectures.svg",
            "publish_date": "7/02/2018",
            "name": "hybrid-networking",
            "popularity": 241,
            "topic": "Networking",
            "hybrid-topic": "Networking"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "is-deployable",
                "networking",
                "powershell",
                "reference-architecture",
                "seodec18",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/hybrid-networking/expressroute-vpn-failover.yml",
            "http_url": "/azure/architecture/reference-architectures/hybrid-networking/expressroute-vpn-failover",
            "word_count": 1060,
            "read_time": "5 min read",
            "Title": "Connect an on-premises network to Azure using ExpressRoute",
            "MetaDescription": "Implement a highly available and secure site-to-site network architecture that spans an Azure virtual network and an on-premises network connected using ExpressRoute with VPN gateway failover.",
            "category": [
                "hybrid",
                "networking"
            ],
            "image": "/azure/architecture/reference-architectures/hybrid-networking/images/expressroute-vpn-failover.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\hybrid-networking\\images\\expressroute-vpn-failover.png",
            "publish_date": "10/22/2017",
            "deployable": "https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2Fmspnp%2Freference-architectures%2Fmaster%2Fhybrid-networking%2Fexpressroute-vpn-failover%2Fazuredeploy.json",
            "visio_diagram": "https://arch-center.azureedge.net/hybrid-network-architectures.vsdx",
            "code_languages": [
                "powershell"
            ],
            "sample_code": true,
            "name": "expressroute-vpn-failover",
            "popularity": 212,
            "topic": "Networking",
            "hybrid-topic": "Networking"
        },
        {
            "tags": [
                "all-items",
                "fcp",
                "is-deployable",
                "reference-architecture",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "hybrid/azure-network-adapter.md",
            "http_url": "/azure/architecture/hybrid/azure-network-adapter",
            "word_count": 3054,
            "read_time": "12 min read",
            "Title": "Connect standalone servers by using Azure Network Adapter",
            "MetaDescription": "Connect standalone servers on-premises and in other cloud providers networks to Azure networks",
            "category": [
                "hybrid",
                "networking"
            ],
            "image": "/azure/architecture/hybrid/images/azure-network-adapter.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\hybrid\\images\\azure-network-adapter.png",
            "publish_date": "7/23/2020",
            "deployable": "https://portal.azure.com/#create/Microsoft.VirtualNetwork-ARM",
            "Summary": "<p>This reference architecture shows how to connect an on-premises standalone server to Microsoft Azure virtual networks by using the Azure Network Adapter that you deploy through Windows Admin Center (WAC). Azure Network Adapter creates a secured virtual connection over the internet, thereby extending your on-premises network into Azure.</p>\n<p><img alt=\"Use Azure VPN to connect a standalone server to an Azure virtual network by deploying an Azure Network Adapter using Windows Admin Center. You then can manage the Azure virtual machines (VMs) from the standalone server by using the VMs private IP address.\" src=\"https://learn.microsoft.com/azure/architecture/hybrid/images/azure-network-adapter.png\" /></p>\n<p><img alt=\"Deploy an Azure Network Adapter using Windows Admin Center to connect a standalone server via Azure VPN to a corporate network's Azure virtual network, a branch office, or another cloud provider's network. You then can use the standalone server to manage the Azure VMs via their private IP addresses, from any locations.\" src=\"https://learn.microsoft.com/azure/architecture/hybrid/images/azure-network-adapter-large.png\" /></p>\n<p><em>Download a <a href=\"https://arch-center.azureedge.net/azure-network-adapter.vsdx\">Visio file</a> of these architectures.</em></p>",
            "visio_diagram": "https://arch-center.azureedge.net/azure-network-adapter.vsdx",
            "name": "azure-network-adapter",
            "popularity": 0,
            "topic": "Networking",
            "hybrid-topic": "Networking"
        },
        {
            "tags": [
                "all-items",
                "fcp",
                "iot",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/contactless-interfaces.md",
            "http_url": "/azure/architecture/solution-ideas/articles/contactless-interfaces",
            "word_count": 554,
            "read_time": "3 min read",
            "Title": "Contactless IoT interfaces with Azure intelligent edge",
            "MetaDescription": "Create solutions with touch-free interfaces & other intelligent & perceptive IoT devices backed by the storage, compute, AI, & ML capabilities of Azure cloud.",
            "category": [
                "iot",
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/avanade-contactless-interface-iot-edge.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\avanade-contactless-interface-iot-edge.png",
            "publish_date": "6/06/2020",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/iot-edge/\">Azure IoT Edge</a> service deploys cloud workloads to run on IoT Edge devices via standard containers. Modules can run AI, other Azure and third-party services, or your own business logic. IoT Edge intelligent devices can respond quickly and offline, and limit costs by preprocessing and sending only necessary data to the cloud.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/iot-hub/\">Azure IoT Hub</a> provides a cloud-hosted backend to connect virtually any IoT device with Azure cloud services. IoT Hub enables highly secure and reliable bi-directional communication, management, and provisioning for IoT Edge devices.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage/\">Azure Storage</a> provides flexible, scalable, secure storage in the Azure cloud. The current solution uses <a href=\"https://azure.microsoft.com/pricing/details/storage/blobs/\">block blobs</a> to store unstructured data, <a href=\"https://azure.microsoft.com/pricing/details/storage/page-blobs/\">page blobs</a> to read and write random small data segments, and <a href=\"https://azure.microsoft.com/pricing/details/storage/files/\">file storage</a> for file shares.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cognitive-services/\">Azure Cognitive Services</a> are a family of AI services and cognitive APIs that help build intelligent apps. For example, voice control can use the <a href=\"https://azure.microsoft.com/services/cognitive-services/speech-to-text/\">Speech to Text</a> and <a href=\"https://azure.microsoft.com/services/cognitive-services/speaker-recognition/\">Speaker Recognition</a> services. Extending the solution to image or facial recognition could use <a href=\"https://azure.microsoft.com/services/cognitive-services/computer-vision/\">Computer Vision</a>, <a href=\"https://azure.microsoft.com/services/cognitive-services/custom-vision-service/\">Custom Vision</a>, and <a href=\"https://azure.microsoft.com/services/cognitive-services/face/\">Facial Recognition</a>.</p>",
                "<p><a href=\"https://wikipedia.org/wiki/Machine_learning\">Machine Learning (ML)</a> uses algorithms to improve machine predictions or decisions automatically through experience. Machine learning algorithms build and continually <em>train</em> mathematical <em>models</em>. <a href=\"https://azure.microsoft.com/services/machine-learning/\">Azure Machine Learning</a> lets you build, train, deploy, track, and manage ML models at cloud scale.</p>"
            ],
            "Summary": "<p>Contactless business is the new normal. The world has become more aware of, and endangered by, surfaces that many people touch every day. Contactless interfaces reduce or eliminate physical touchpoints like traffic light buttons, touch screens, door handles, and elevator controls by creating touch-free experiences that are both safe and pleasing for users.</p>\n<p><a href=\"https://www.avanade.com\">Avanade</a> and the Microsoft COVID-19 task force partnered to develop contactless interfaces using the <a href=\"https://azure.microsoft.com/overview/future-of-cloud/\">Azure intelligent edge</a> platform. This solution combines intelligent and perceptive Internet of Things (IoT) edge devices with the storage, computing, artificial intelligence (AI), and machine learning (ML) capabilities of the Azure cloud.</p>\n<p>IoT Edge devices can quickly recognize and respond to speech, image, gesture, or multi-modal input by using onboard processing. Azure IoT Hub in the cloud controls the devices and connects them to Azure resources. Azure Cognitive Services and Machine Learning continually retrain and update models to improve interface accuracy and performance.</p>",
            "name": "contactless-interfaces",
            "popularity": 0,
            "topic": "Internet of Things"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-container-cicd-using-jenkins-and-kubernetes-on-azure-container-service-'",
                "acom-architecture",
                "all-items",
                "ci-cd",
                "continuous-delivery",
                "continuous-deployment",
                "continuous-integration",
                "data-flow",
                "devops",
                "interactive-diagram",
                "is-deployable",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/container-cicd-using-jenkins-and-kubernetes-on-azure-container-service.md",
            "http_url": "/azure/architecture/solution-ideas/articles/container-cicd-using-jenkins-and-kubernetes-on-azure-container-service",
            "word_count": 288,
            "read_time": "2 min read",
            "Title": "Container CI/CD using Jenkins and Kubernetes on Azure Kubernetes Service (AKS)",
            "MetaDescription": "Containers make it easy for you to continuously build and deploy applications. By orchestrating the deployment of those containers using Azure Kubernetes Service (AKS), you can achieve replicable, manageable clusters of containers.",
            "category": [
                "devops",
                "containers"
            ],
            "image": "/azure/architecture/solution-ideas/media/container-cicd-using-jenkins-and-kubernetes-on-azure-container-service.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\container-cicd-using-jenkins-and-kubernetes-on-azure-container-service.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/kubernetes-service\">Azure Kubernetes Service (AKS)</a>: Simplify the deployment, management, and operations of Kubernetes.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/container-registry\">Container Registry</a>: Store and manage container images across all types of Azure deployments.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cosmos-db\">Azure Cosmos DB</a>: Globally distributed, multi-model database for any scale.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/monitor\">Azure Monitor</a>: Highly granular and real-time monitoring data for any Azure resource.</p>",
                "<p><a href=\"https://azure.microsoft.com/products/visual-studio\">Visual Studio Code</a>: Build and deploy multi-platform apps to get the most from Azure services.</p>"
            ],
            "Flow": {
                "FlowStep_A": "Change application source code.",
                "FlowStep_B": "Commit code to GitHub.",
                "FlowStep_C": "Continuous Integration Trigger to Jenkins.",
                "FlowStep_D": "Jenkins triggers a build job using Azure Kubernetes Service (AKS) for a dynamic build agent.",
                "FlowStep_E": "Jenkins builds and pushes Docker container to Azure Container Registry.",
                "FlowStep_F": "Jenkins deploys your new containerized app to Kubernetes on Azure.",
                "FlowStep_G": "Container Service (AKS), backed by Azure Cosmos DB.",
                "FlowStep_H": "Grafana displays visualization of infrastructure and application metrics via Azure Monitor.",
                "FlowStep_I": "Monitor application and make improvements."
            },
            "name": "container-cicd-using-jenkins-and-kubernetes-on-azure-container-service",
            "popularity": 166,
            "topic": "DevOps"
        },
        {
            "tags": [
                "acom-architecture",
                "all-items",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/content-research.md",
            "http_url": "/azure/architecture/solution-ideas/articles/content-research",
            "word_count": 280,
            "read_time": "2 min read",
            "Title": "Content Research",
            "MetaDescription": "Knowledge mining with a search index makes it easy for customers and employees to locate what they are looking for faster.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/knowledge-mining-content-research.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\knowledge-mining-content-research.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>This architecture describes how knowledge mining can be used for content research.</p>\n<p>When organizations task employees to review and research of technical data, it can be tedious to read page after page of dense text. Knowledge mining helps employees quickly review these dense materials. In industries where bidding competition is fierce, or when the diagnosis of a problem must be quick or in near real-time, companies can use knowledge mining to avoid costly mistakes.</p>\n<p><img alt=\"Architecture Diagram\" src=\"https://learn.microsoft.com/azure/architecture/solution-ideas/media/knowledge-mining-content-research.png\" /></p>",
            "name": "content-research",
            "popularity": 0,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "acom-architecture",
                "all-items",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/contract-management.md",
            "http_url": "/azure/architecture/solution-ideas/articles/contract-management",
            "word_count": 242,
            "read_time": "2 min read",
            "Title": "Contract Management",
            "MetaDescription": "Knowledge mining can help organizations to scour thousands of pages of sources to create an accurate bid.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/knowledge-mining-contract-management.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\knowledge-mining-contract-management.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Many companies create products for multiple sectors, hence the business opportunities with different vendors and buyers increases exponentially. Knowledge mining can help organizations to scour thousands of pages of sources to create an accurate bid. Minor details in the bidding process can make the difference between a healthy profit or lost opportunity on a project.</p>\n<p><img alt=\"Architecture Diagram\" src=\"https://learn.microsoft.com/azure/architecture/solution-ideas/media/knowledge-mining-contract-management.png\" /></p>",
            "name": "contract-management",
            "popularity": 0,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-iot-devices-'",
                "acom-architecture",
                "all-items",
                "bot-service",
                "data-flow",
                "iot",
                "luis",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/iot-controlling-devices-with-voice-assistant.md",
            "http_url": "/azure/architecture/solution-ideas/articles/iot-controlling-devices-with-voice-assistant",
            "word_count": 346,
            "read_time": "2 min read",
            "Title": "Controlling IoT devices using a Voice Assistant",
            "MetaDescription": "Create seamless conversational interfaces with all of your internet-accessible devices-from your connected television or fridge to devices in a connected power plant. By combining Azure Speech Service, Language Understanding Service (LUIS) and Azure Bot Framework, developers can create natural, human-like conversational interfaces to control smart devices.",
            "category": [
                "iot"
            ],
            "image": "/azure/architecture/solution-ideas/media/controlling-iot-devices-using-voice.svg",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\controlling-iot-devices-using-voice.svg",
            "publish_date": "3/23/2020",
            "Summary": "<p>Create seamless conversational interfaces with all of your internet-accessible devices-from your connected television or fridge to devices in a connected power plant. By combining <a href=\"https://learn.microsoft.com/azure/cognitive-services/speech-service/overview\">Azure Speech Service</a>, <a href=\"https://learn.microsoft.com/azure/cognitive-services/luis/\">Language Understanding Service</a> (LUIS) and <a href=\"https://learn.microsoft.com/azure/bot-service/?view=azure-bot-service-4.0\">Azure Bot Framework</a>, developers can create natural, human-like conversational interfaces to control smart devices using <a href=\"https://azure.microsoft.com/services/iot-hub/\">Azure IoT Hub</a>.</p>",
            "Flow": {
                "FlowStep_A": "Using voice, the user asks the voice assistant app to turn on the exterior house lights.",
                "FlowStep_B": "Using the Speech SDK, the app connects to Direct Line Speech. If keywords are confirmed by Keyword Verification, the speech is transcribed to text and sent to the Bot Service.",
                "FlowStep_C": "The Bot Service connects to Language Understanding service (LUIS). LUIS allows an application to understand what a person wants in their own words. The intent of the user's request (example: TurnOnLight) is returned to the Bot Service.",
                "FlowStep_D": "The request is relayed to the device.",
                "FlowStep_E": "The Bot returns the results of the command to the user by generating a response that includes the text to speak.",
                "FlowStep_F": "The response is turned into audio using the Text-to-speech service and passed back to the voice assistant app by Direct Line Speech.",
                "FlowStep_G": "Application Insights gathers runtime telemetry to help development with bot performance and usage",
                "FlowStep_H": "Azure App Service hosts the Bot Service application."
            },
            "name": "iot-controlling-devices-with-voice-assistant",
            "popularity": 0,
            "topic": "Internet of Things"
        },
        {
            "tags": [
                "all-items",
                "bash",
                "example-code",
                "github",
                "identity",
                "reference-architecture",
                "seodec18",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/identity/adds-forest.yml",
            "http_url": "/azure/architecture/reference-architectures/identity/adds-forest",
            "word_count": 1514,
            "read_time": "6 min read",
            "Title": "Create an AD DS resource forest in Azure",
            "MetaDescription": "How to create a trusted Active Directory domain in Azure.",
            "category": [
                "identity",
                "hybrid"
            ],
            "image": "/azure/architecture/reference-architectures/identity/images/adds-forest.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\identity\\images\\adds-forest.png",
            "publish_date": "5/02/2018",
            "sample_code": true,
            "github_url": "https://github.com/mspnp/identity-reference-architectures",
            "visio_diagram": "https://arch-center.azureedge.net/identity-architectures.vsdx",
            "code_languages": [
                "bash"
            ],
            "name": "adds-forest",
            "popularity": 193,
            "topic": "Identity",
            "hybrid-topic": "Identity"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-cross-cloud-scaling-'",
                "acom-architecture",
                "all-items",
                "cloud-scalability",
                "cross-cloud",
                "cross-cloud-architecture",
                "data-flow",
                "hybrid-infrastructure",
                "interactive-diagram",
                "scalability",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/cross-cloud-scaling.md",
            "http_url": "/azure/architecture/solution-ideas/articles/cross-cloud-scaling",
            "word_count": 179,
            "read_time": "1 min read",
            "Title": "Cross Cloud Scaling Architecture",
            "MetaDescription": "Learn how to improve cross cloud scalability with solution architecture that includes Azure Stack. A step-by-step flowchart details instructions for implementation.",
            "category": [
                "hybrid",
                "web"
            ],
            "image": "/azure/architecture/solution-ideas/media/cross-cloud-scaling.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\cross-cloud-scaling.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/traffic-manager\">Traffic Manager</a>: Route incoming traffic for high performance and availability</p>",
                "<p><a href=\"https://azure.microsoft.com/services/functions\">Azure Functions</a>: Process events with serverless code</p>",
                "<p><a href=\"https://azure.microsoft.com/overview/azure-stack\">Azure Stack</a>: Build and run innovative hybrid applications across cloud boundaries</p>"
            ],
            "Summary": "<p>Modern software is increasingly connected and distributed. The consistency of Azure Stack with Azure infrastructure and platform services enable you to scale resources cross cloud to meet increased load as needed, and decrease resources as demand drops. Optimize cost and maximize resource efficiency while remaining compliant with cross cloud architecture.</p>",
            "Flow": {
                "FlowStep_A": "A large number of users attempt to access a web app.",
                "FlowStep_B": "Traffic manager returns the Azure Stack DNS name.",
                "FlowStep_C": "Users access the Azure Stack web app.",
                "FlowStep_D": "Once a threshold is reached, a function starts the Azure Web App and enables the Azure Traffic Manager route.",
                "FlowStep_E": "Traffic is routed to Azure, which can automatically scale App Service."
            },
            "name": "cross-cloud-scaling",
            "popularity": 185,
            "topic": "Web",
            "hybrid-topic": "Apps"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-cross-platform-chat-'",
                "acom-architecture",
                "all-items",
                "chat",
                "data-flow",
                "interactive-diagram",
                "signalr-service",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/cross-platform-chat.md",
            "http_url": "/azure/architecture/solution-ideas/articles/cross-platform-chat",
            "word_count": 63,
            "read_time": "1 min read",
            "Title": "Cross-platform Chat",
            "MetaDescription": "Accelerate development of reliable, high-performing chat applications",
            "category": [
                "hybrid",
                "web"
            ],
            "image": "/azure/architecture/solution-ideas/media/cross-platform-chat.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\cross-platform-chat.png",
            "publish_date": "12/16/2019",
            "Flow": {
                "FlowStep_A": "Web chat app connects to SignalR Service and receives token",
                "FlowStep_B": "User logs into app with multi-factor authentication; if passed, SignalR endpoint and bearer token returned"
            },
            "name": "cross-platform-chat",
            "popularity": 89,
            "topic": "Web",
            "hybrid-topic": "Apps"
        },
        {
            "tags": [
                "all-items",
                "data-flow",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/custom-business-processes.md",
            "http_url": "/azure/architecture/solution-ideas/articles/custom-business-processes",
            "word_count": 395,
            "read_time": "2 min read",
            "Title": "Custom Business Processes",
            "MetaDescription": "This example demonstrates how you can deploy portals that automate manual or paper-based processes and surface rich user experience. Leverage Azure API management and Azure Functions to connect custom APIs which tap into your legacy systems.",
            "category": [
                "mobile",
                "apim",
                "functions"
            ],
            "image": "/azure/architecture/solution-ideas/media/custom-business-processes.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\custom-business-processes.png",
            "publish_date": "8/24/2020",
            "Summary": "",
            "Flow": {
                "FlowStep_A": "The airline system assigns flights to Teams channel which are also displayed in Power Apps.",
                "FlowStep_B": "Custom API Coordinator hosted in Azure API Management receives notifications and handles incoming messages from the airline system.",
                "FlowStep_C": "When a user selects a flight to monitor or the system assigns the user to a flight, Graph API call is queued for coordinator to process.",
                "FlowStep_D": "Azure Functions run the Graph API calls which are processed in Azure Storage.",
                "FlowStep_E": "Notifications from airline system are managed by a custom bot messaging service leveraging Azure Bot Service.",
                "FlowStep_F": "Custom bots sends flight updates to users in Teams.",
                "FlowStep_G": "Power BI generates reports from the Azure Data Lake, based on Teams activity."
            },
            "name": "custom-business-processes",
            "popularity": 0,
            "topic": "Mobile"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-custom-mobile-workforce-app-'",
                "acom-architecture",
                "all-items",
                "data-flow",
                "interactive-diagram",
                "mobile-workforce-app",
                "mobile-workforce-management-app",
                "mobile-workforce-management-solution",
                "solution-idea",
                "workforce-management-app"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/custom-mobile-workforce-app.md",
            "http_url": "/azure/architecture/solution-ideas/articles/custom-mobile-workforce-app",
            "word_count": 429,
            "read_time": "2 min read",
            "Title": "Custom Mobile Workforce App",
            "MetaDescription": "Learn how the custom mobile workforce management app architecture is built and implemented with a step-by-step diagram that illustrates the integration of Active Directory, SAP, and Azure App Service.",
            "category": [
                "mobile",
                "identity",
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/custom-mobile-workforce-app.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\custom-mobile-workforce-app.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>This mobile workforce app architecture uses Active Directory to secure corporate data from an SAP back end system, delivered to devices via Azure App Service API Management.</p>\n<p>A Xamarin.Forms client app, with support for iOS, Android, and Windows, works offline and enables field engineers to view and edit the jobs assigned to them.</p>\n<p>The app is built with Visual Studio (PC or Mac) and Xamarin, sharing C# code across Android, iOS, and Windows without compromising user experience. Visual Studio App Center is used to automate builds and tests and distribute to beta testers and app stores, while also providing usage monitoring and analytics in conjunction with App Insights.</p>\n<p>The links to the right provide documentation on deploying and managing the Azure products listed in the solution architecture above.</p>\n<p><a href=\"https://azure.microsoft.com/services/visual-studio-team-services\">Visual Studio Team Services</a></p>\n<p><a href=\"https://www.visualstudio.com/vs\">Visual Studio</a></p>\n<p><a href=\"https://www.visualstudio.com/xamarin\">Visual Studio Tools for Xamarin</a></p>\n<p><a href=\"https://azure.microsoft.com/services/application-insights\">Application Insights</a></p>\n<p><a href=\"https://www.visualstudio.com/app-center\">Visual Studio App Center</a></p>\n<p><a href=\"https://azure.microsoft.com/services/app-service/mobile\">App Service Mobile Apps</a></p>",
            "Flow": {
                "FlowStep_A": "Create the app using Visual Studio and Xamarin.",
                "FlowStep_B": "Add the Azure App Service Mobile Apps back end service to the app solution.",
                "FlowStep_C": "Implement authentication through Azure Active Directory.",
                "FlowStep_D": "Connect to business data in external systems like SAP using Azure API Management.",
                "FlowStep_E": "Implement offline sync to make the mobile app functional without a network connection.",
                "FlowStep_F": "Build and test the app through Visual Studio App Center and publish it.",
                "FlowStep_G": "Use Application Insights to monitor the App Service.",
                "FlowStep_H": "Deploy the app to devices using App Center."
            },
            "name": "custom-mobile-workforce-app",
            "popularity": 116,
            "topic": "Mobile"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-customer-churn-prediction-'",
                "acom-architecture",
                "ai-gallery",
                "all-items",
                "artificial-intelligence",
                "azure",
                "example-code",
                "github",
                "solution-architectures",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/customer-churn-prediction.md",
            "http_url": "/azure/architecture/solution-ideas/articles/customer-churn-prediction",
            "word_count": 304,
            "read_time": "2 min read",
            "Title": "Customer Churn Prediction",
            "MetaDescription": "Customer Churn Prediction uses Cortana Intelligence Suite components to predict churn probability and helps find patterns in existing data associated with the predicted churn rate.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/customer-churn-prediction.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\customer-churn-prediction.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Customer Churn Prediction uses Cortana Intelligence Suite components to predict churn probability and helps find patterns in existing data associated with the predicted churn rate.</p>",
            "sample_code": true,
            "github_url": "https://github.com/Azure/cortana-intelligence-churn-prediction-solution",
            "name": "customer-churn-prediction",
            "popularity": 94,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "acom-architecture",
                "all-items",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/customer-feedback-and-analytics.md",
            "http_url": "/azure/architecture/solution-ideas/articles/customer-feedback-and-analytics",
            "word_count": 281,
            "read_time": "2 min read",
            "Title": "Customer Feedback and Analytics",
            "MetaDescription": "Knowledge mining can help customer support teams quickly find the right answers for customer questions or assess customer sentiment at scale.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/knowledge-mining-customer-feedback-and-analytics.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\knowledge-mining-customer-feedback-and-analytics.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>For many companies, customer support is costly and inefficient. Knowledge mining can help customer support teams quickly find the right answers for customer questions or assess customer sentiment at scale.</p>\n<p>Every company is looking to enhance the customer experience. Knowledge mining can aggregate and analyze data to discover trends about what customers are saying and use that information to improve products and services</p>\n<p><img alt=\"Architecture Diagram\" src=\"https://learn.microsoft.com/azure/architecture/solution-ideas/media/knowledge-mining-customer-feedback-and-analytics.png\" /></p>",
            "name": "customer-feedback-and-analytics",
            "popularity": 0,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-data-streaming-scenario-'",
                "acom-architecture",
                "all-items",
                "data",
                "data-flow",
                "data-streaming-scenario",
                "interactive-diagram",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/data-streaming-scenario.md",
            "http_url": "/azure/architecture/solution-ideas/articles/data-streaming-scenario",
            "word_count": 174,
            "read_time": "1 min read",
            "Title": "Data Streaming scenario",
            "MetaDescription": "Data Streaming scenario",
            "category": [
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/data-streaming-scenario.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\data-streaming-scenario.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Use AKS to easily ingest &amp; process a real-time data stream with millions of data points collected via sensors. Perform fast analysis and computations to develop insights into complex scenarios quickly.</p>",
            "Flow": {
                "FlowStep_A": "Sensor data is generated and streamed to Azure API Management.",
                "FlowStep_B": "AKS cluster runs microservice that are deployed as containers behind a service mesh. Containers are built using a DevOps process and stored in Azure Container Registry.",
                "FlowStep_C": "Ingest service stores data in an Azure Cosmos DB instance",
                "FlowStep_D": "Asynchronously, the Analysis service receives the data and streams it to Apache Kafka and Azure HDInsight.",
                "FlowStep_E": "Data scientists can analyze the large big data for use in machine learning models using Splunk.",
                "FlowStep_F": "Data is processed by the processing service which stores the result in Azure Database for PostgreSQL and caches the data in an Azure Cache for Redis."
            },
            "name": "data-streaming-scenario",
            "popularity": 117,
            "topic": "Databases"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-data-cache-with-redis-cache-'",
                "acom-architecture",
                "all-items",
                "data",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/data-cache-with-redis-cache.md",
            "http_url": "/azure/architecture/solution-ideas/articles/data-cache-with-redis-cache",
            "word_count": 60,
            "read_time": "1 min read",
            "Title": "Data cache",
            "MetaDescription": "data cache, data cache with azure cache for redis, azure database, cosmos db",
            "category": [
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/data-cache-with-redis-cache.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\data-cache-with-redis-cache.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Azure Cache for Redis perfectly complements Azure database services such as Azure Cosmos DB. It provides a cost-effective solution to scale read and write throughput of your data tier. Store and share database query results, session states, static contents, and more using a common cache-aside pattern.</p>",
            "name": "data-cache-with-redis-cache",
            "popularity": 68,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "data-analytics",
                "data-flow",
                "data-warehouse",
                "example-workload",
                "pricing-calculator",
                "pricing-guidance"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/data/data-warehouse.md",
            "http_url": "/azure/architecture/example-scenario/data/data-warehouse",
            "word_count": 1210,
            "read_time": "5 min read",
            "Title": "Data warehousing and analytics",
            "MetaDescription": "This example demonstrates a data pipeline that integrates large amounts of data from multiple sources into a unified analytics platform in Azure.",
            "category": [
                "analytics",
                "databases"
            ],
            "image": "/azure/architecture/example-scenario/data/media/architecture-data-warehouse.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\data\\media\\architecture-data-warehouse.png",
            "publish_date": "11/20/2019",
            "pricing_calculator": "https://azure.com/e/b798fb70c53e4dd19fdeacea4db78276",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "Summary": "<p>This example scenario demonstrates a data pipeline that integrates large amounts of data from multiple sources into a unified analytics platform in Azure. This specific scenario is based on a sales and marketing solution, but the design patterns are relevant for many industries requiring advanced analytics of large datasets such as e-commerce, retail, and healthcare.</p>\n<p>This example demonstrates a sales and marketing company that creates incentive programs. These programs reward customers, suppliers, salespeople, and employees. Data is fundamental to these programs, and the company wants to improve the insights gained through data analytics using Azure.</p>\n<p>The company needs a modern approach to analysis data, so that decisions are made using the right data at the right time. The company's goals include:</p>\n<ul>\n<li>Combining different kinds of data sources into a cloud-scale platform.</li>\n<li>Transforming source data into a common taxonomy and structure, to make the data consistent and easily compared.</li>\n<li>Loading data using a highly parallelized approach that can support thousands of incentive programs, without the high costs of deploying and maintaining on-premises infrastructure.</li>\n<li>Greatly reducing the time needed to gather and transform data, so you can focus on analyzing the data.</li>\n</ul>",
            "Flow": {
                "FlowStep_A": "For each data source, any updates are exported periodically into a staging area in Azure Blob storage.",
                "FlowStep_B": "Data Factory incrementally loads the data from Blob storage into staging tables in Azure Synapse Analytics. The data is cleansed and transformed during this process. PolyBase can parallelize the process for large datasets.",
                "FlowStep_C": "After loading a new batch of data into the warehouse, a previously created Analysis Services tabular model is refreshed. This semantic model simplifies the analysis of business data and relationships.",
                "FlowStep_D": "Business analysts use Microsoft Power BI to analyze warehoused data via the Analysis Services semantic model."
            },
            "name": "data-warehouse",
            "popularity": 200,
            "topic": "Analytics"
        },
        {
            "tags": [
                "all-items",
                "cse",
                "example-code",
                "example-workload",
                "fcp",
                "github"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/data-warehouse/dataops-mdw.md",
            "http_url": "/azure/architecture/example-scenario/data-warehouse/dataops-mdw",
            "word_count": 1504,
            "read_time": "6 min read",
            "Title": "DataOps for the modern data warehouse",
            "MetaDescription": "How to apply DevOps principles to data pipelines built according to the modern data  (MDW) architectural pattern on Microsoft Azure",
            "category": [
                "databases"
            ],
            "image": "/azure/architecture/example-scenario/data-warehouse/media/street-parking-availability.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\data-warehouse\\media\\street-parking-availability.png",
            "publish_date": "7/14/2020",
            "Summary": "<p>A modern data warehouse (MDW) lets you easily bring all of your data together at any scale. It doesn't matter if it's  structured, unstructured, or semi-structured data. You can gain insights to an MDW through analytical dashboards, operational reports, or advanced analytics for all your users.</p>\n<p>Setting up an MDW environment for both development (dev) and production (prod) environments is complex. Automating the process is key. It helps increase productivity while minimizing the risk of errors.</p>\n<p>This article describes how a fictional city planning office could use this solution. The solution provides an end-to-end data pipeline that follows the MDW architectural pattern, along with corresponding DevOps and DataOps processes, to assess parking use and make more informed business decisions.</p>",
            "sample_code": true,
            "github_url": "https://github.com/Azure-Samples/modern-data-warehouse-dataops/tree/master/e2e_samples/parking_sensors#how-to-use-the-sample",
            "name": "dataops-mdw",
            "popularity": 0,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "blockchain",
                "csa-team",
                "data-flow",
                "example-code",
                "example-workload",
                "finance",
                "github",
                "pricing-calculator",
                "pricing-guidance"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/apps/decentralized-trust.md",
            "http_url": "/azure/architecture/example-scenario/apps/decentralized-trust",
            "word_count": 1240,
            "read_time": "5 min read",
            "Title": "Decentralized trust between banks",
            "MetaDescription": "Establish a trusted environment for communication and information sharing without resorting to a centralized database.",
            "category": [
                "blockchain"
            ],
            "image": "/azure/architecture/example-scenario/apps/media/architecture-decentralized-trust.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\apps\\media\\architecture-decentralized-trust.png",
            "publish_date": "9/09/2018",
            "pricing_calculator": "https://azure.com/e/4e429d721eb54adc9a1558fae3e67990",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "components": [
                "<p>Virtual machines within virtual machine scale sets provides the on-demand compute facility to host the validator processes for the blockchain</p>",
                "<p>Key Vault is used as the secure storage facility for the private keys of each validator</p>",
                "<p>Load Balancer spreads the RPC, peering, and Governance DApp requests</p>",
                "<p>Storage hosting persistent network information and coordinating leasing</p>",
                "<p>Operations Management Suite (a bundling of a few Azure services) provides insight into available nodes, transactions per minute and consortium members</p>"
            ],
            "Summary": "<p>This example scenario is useful for banks or any other institutions that want to establish a trusted environment for information sharing without resorting to a centralized database. For the purpose of this example, we will describe the scenario in the context of maintaining credit score information between banks, but the architecture can be applied to any scenario where a consortium of organizations want to share validated information with one another without resorting to the use of a central system ran by one single party.</p>\n<p>Traditionally, banks within a financial system rely on centralized sources such as credit bureaus for information on an individual's credit score and history. A centralized approach presents a concentration of operational risk and sometimes an unnecessary third party.</p>\n<p>With DLTs (distributed ledger technology), a consortium of banks can establish a decentralized system that can be more efficient, less susceptible to attack, and serve as a new platform where innovative structures can be implemented to solve traditional challenges with privacy, speed, and cost.</p>\n<p>This example will show you how Azure services such as virtual machine scale sets, Virtual Network, Key Vault, Storage, Load Balancer, and Monitor can be quickly provisioned for the deployment of an efficient private Ethereum PoA blockchain where member banks can establish their own nodes.</p>",
            "Flow": {
                "FlowStep_A": "Bank A creates/updates an individual's credit record by sending a transaction to the blockchain network via JSON-RPC.",
                "FlowStep_B": "Data flows from Bank A's private application server to the Azure load balancer and subsequently to a validating node VM on the virtual machine scale set.",
                "FlowStep_C": "The Ethereum PoA network creates a block at a preset time (2 seconds for this scenario).",
                "FlowStep_D": "The transaction is bundled into the created block and validated across the blockchain network.",
                "FlowStep_E": "Bank B can read the credit record created by bank A by communicating with its own node similarly via JSON-RPC."
            },
            "sample_code": true,
            "github_url": "https://github.com/vitoc/creditscoreblockchain",
            "name": "decentralized-trust",
            "popularity": 184,
            "topic": "Blockchain"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-defect-prevention-with-predictive-maintenance-'",
                "acom-architecture",
                "all-items",
                "anomaly-detection",
                "manufacturing-control",
                "manufacturing-quality-control",
                "quality-control-process",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/defect-prevention-with-predictive-maintenance.md",
            "http_url": "/azure/architecture/solution-ideas/articles/defect-prevention-with-predictive-maintenance",
            "word_count": 220,
            "read_time": "2 min read",
            "Title": "Defect prevention with predictive maintenance",
            "MetaDescription": "Learn how to use Azure Machine Learning to predict failures before they happen with real-time assembly line data.",
            "category": [
                "ai-machine-learning",
                "analytics"
            ],
            "image": "/azure/architecture/solution-ideas/media/defect-prevention-with-predictive-maintenance.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\defect-prevention-with-predictive-maintenance.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/stream-analytics\">Azure Stream Analytics</a>: Stream Analytics provides near real-time analytics on the input stream from the Azure Event Hub. Input data is filtered and passed to a Machine Learning endpoint, finally sending the results to the Power BI dashboard.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/event-hubs\">Event Hubs</a> ingests raw assembly-line data and passes it on to Stream Analytics.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/machine-learning-studio\">Machine Learning Studio</a>: Machine Learning predicts potential failures based on real-time assembly-line data from Stream Analytics.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/synapse-analytics\">Azure Synapse Analytics</a>: Synapse Analytics stores assembly-line data along with failure predictions.</p>",
                "<p><a href=\"https://powerbi.microsoft.com\">Power BI</a> visualizes real-time assembly-line data from Stream Analytics and the predicted failures and alerts from Data Warehouse.</p>"
            ],
            "Summary": "<p>Learn how to use Azure Machine Learning to predict failures before they happen with real-time assembly line data.</p>\n<p>This solution is built on the Azure managed services: <a href=\"https://azure.microsoft.com/services/stream-analytics\">Azure Stream Analytics</a>, <a href=\"https://azure.microsoft.com/services/event-hubs\">Event Hubs</a>, <a href=\"https://azure.microsoft.com/services/machine-learning-studio\">Machine Learning Studio</a>, <a href=\"https://azure.microsoft.com/services/synapse-analytics\">Azure Synapse Analytics</a> and <a href=\"https://powerbi.microsoft.com\">Power BI</a>. These services run in a high-availability environment, patched and supported, allowing you to focus on your solution instead of the environment they run in.</p>",
            "name": "defect-prevention-with-predictive-maintenance",
            "popularity": 93,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "all-items",
                "fcp",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/erp-customer-service.md",
            "http_url": "/azure/architecture/solution-ideas/articles/erp-customer-service",
            "word_count": 507,
            "read_time": "3 min read",
            "Title": "Deliver highly scalable customer service and ERP applications",
            "MetaDescription": "Deliver highly scalable customer service and ERP applications with Azure SQL and Azure Cosmos DB",
            "category": [
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/erp-customer-service.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\erp-customer-service.png",
            "publish_date": "6/26/2020",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/storage/blobs/data-lake-storage-introduction\">Azure Data Lake Storage Gen 2</a> provides massively scalable and secure data lake storage for high-performance analytics workloads.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-overview-what-is\">Azure Synapse Analytics</a> is an analytics service that brings together enterprise data warehousing and Big Data analytics within a unified experience.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/azure-sql/database/service-tier-hyperscale\">Azure SQL Database Hyperscale</a> is a storage tier in Azure SQL Database that leverages Azure architecture to scale out storage and compute resources.  Hyperscale supports up to 100TB of storage and provides nearly instantaneous backups and fast database restores in minutes \u2013 regardless of the size of data operation.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/cosmos-db/introduction\">Azure Cosmos DB</a> is a fully managed NoSQL database service for building and modernizing scalable, high performance applications.</p>",
                "<p><a href=\"https://learn.microsoft.com/power-bi/fundamentals/power-bi-overview\">Power BI</a> is a suite of business tools for self-service and enterprise business intelligence (BI). Here, it\u2019s used to analyze and visualize data.</p>"
            ],
            "Summary": "<p>Today\u2019s organizations are generating ever-increasing amounts of structured and unstructured data. With Azure managed databases and Azure Synapse Analytics, they can deliver insights to their employees via ERP applications and Power BI, as well as superior customer service through web and mobile applications, scaling without limits as data volumes and application users increase.</p>",
            "name": "erp-customer-service",
            "popularity": 0,
            "topic": "Databases"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-demand-forecasting-'",
                "acom-architecture",
                "ai-gallery",
                "all-items",
                "artificial-intelligence",
                "azure",
                "data-flow",
                "pricing-guidance",
                "solution-architectures",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/demand-forecasting.md",
            "http_url": "/azure/architecture/solution-ideas/articles/demand-forecasting",
            "word_count": 566,
            "read_time": "3 min read",
            "Title": "Demand Forecasting",
            "MetaDescription": "Accurately forecasting spikes in demand for products and services can give a company a competitive advantage. This solution focuses on-demand forecasting within the energy sector.",
            "category": [
                "analytics",
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/demand-forecasting.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\demand-forecasting.png",
            "publish_date": "12/16/2019",
            "pricing_guidance": "pricing-info",
            "Summary": "<p>Accurately forecasting spikes in demand for products and services can give a company a competitive advantage. This solution focuses on-demand forecasting within the energy sector.</p>",
            "Flow": {
                "FlowStep_A": "The sample data is streamed by newly deployed Azure Web Jobs.",
                "FlowStep_B": "This synthetic data feeds into the Azure Event Hubs and Azure SQL service as data points or events, that will be used in the rest of the solution flow.",
                "FlowStep_C": "Azure Stream Analytics analyze the data to provide near real-time analytics on the input stream from the event hub and directly publish to PowerBI for visualization.",
                "FlowStep_D": "Azure Machine Learning is used to make forecast on the energy demand of particular region given the inputs received.",
                "FlowStep_E": "Azure SQL Database is used to store the prediction results received from Azure Machine Learning. These results are then consumed in the Power BI dashboard.",
                "FlowStep_F": "Azure Data Factory handles orchestration, and scheduling of the hourly model retraining.",
                "FlowStep_G": "Finally, Power BI is used for results visualization, so that users can monitor the energy consumption from a region in real time and use the forecast demand to optimize the power generation or distribution process."
            },
            "name": "demand-forecasting",
            "popularity": 110,
            "topic": "Analytics"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-demand-forecasting-price-optimization-marketing-'",
                "acom-architecture",
                "all-items",
                "demand-forecasting",
                "price-optimization",
                "pricing-guidance",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/demand-forecasting-price-optimization-marketing.md",
            "http_url": "/azure/architecture/solution-ideas/articles/demand-forecasting-price-optimization-marketing",
            "word_count": 279,
            "read_time": "2 min read",
            "Title": "Demand Forecasting + Price Optimization",
            "MetaDescription": "Predict future customer demand and optimize pricing to maximize profitability using big-data and advanced-analytics services from Microsoft Azure.",
            "category": [
                "analytics",
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/demand-forecasting-price-optimization-marketing.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\demand-forecasting-price-optimization-marketing.png",
            "publish_date": "12/16/2019",
            "pricing_guidance": "pricing-is-pivotal-for-many-industries,-but-it-can-be-one-of-the-most-challenging-tasks.-companies-often-struggle-to-accurately-forecast-the-fiscal-impact-of-potential-tactics,-fully-consider-core-business-constraints,-and-fairly-validate-pricing-decisions-once-they've-been-made.-as-product-offerings-expand-and-complicate-the-calculations-behind-real-time-pricing-decisions,-the-process-grows-even-more-difficult.",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/storage/data-lake-storage\">Azure Data Lake Storage</a>: Data Lake Store stores the weekly raw sales data, which is read by Spark on HDInsight.</p>",
                "<p>Spark on <a href=\"https://azure.microsoft.com/services/hdinsight\">HDInsight</a> ingests the data and executes data preprocessing, forecasting modeling, and price-optimization algorithms.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/data-factory\">Data Factory</a> handles orchestration and scheduling of the model retraining.</p>",
                "<p><a href=\"https://powerbi.microsoft.com\">Power BI</a> visualizes sales results, the predicted future demand, and the recommended optimal prices for a variety of products sold in different stores.</p>"
            ],
            "name": "demand-forecasting-price-optimization-marketing",
            "popularity": 61,
            "topic": "Analytics"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-demand-forecasting-for-shipping-and-distribution-'",
                "acom-architecture",
                "ai-gallery",
                "all-items",
                "artificial-intelligence",
                "azure",
                "example-code",
                "github",
                "pricing-guidance",
                "solution-architectures",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/demand-forecasting-for-shipping-and-distribution.md",
            "http_url": "/azure/architecture/solution-ideas/articles/demand-forecasting-for-shipping-and-distribution",
            "word_count": 1083,
            "read_time": "5 min read",
            "Title": "Demand Forecasting for Shipping and Distribution",
            "MetaDescription": "Use historical demand data to forecast future periods across various customers, products and destinations.",
            "category": [
                "analytics",
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/demand-forecasting-for-shipping-and-distribution.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\demand-forecasting-for-shipping-and-distribution.png",
            "publish_date": "12/16/2019",
            "pricing_guidance": "pricing-info",
            "Summary": "<p>The Demand Forecasting for Shipping and Distribution Solution uses historical demand data to forecast demand in future periods across various customers, products and destinations. For instance, a shipping or delivery company wants to predict the quantities of the different products its customers want delivered at different locations at future times. A company can use these forecasts as input to an allocation tool that optimizes operations, such as delivery vehicles routing, or to plan capacity in the longer term.</p>\n<p><a >View on GitHub</a></p>",
            "sample_code": true,
            "github_url": "https://github.com/Azure/cortana-intelligence-shipping-and-distribution-forecasting/blob/master/Technical%20Deployment%20Guide/Technical-Solution-Guide.md",
            "name": "demand-forecasting-for-shipping-and-distribution",
            "popularity": 33,
            "topic": "Analytics"
        },
        {
            "tags": [
                "all-items",
                "bash",
                "example-code",
                "github",
                "identity",
                "reference-architecture",
                "seodec18",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/identity/adds-extend-domain.yml",
            "http_url": "/azure/architecture/reference-architectures/identity/adds-extend-domain",
            "word_count": 2071,
            "read_time": "8 min read",
            "Title": "Deploy AD DS in an Azure virtual network",
            "MetaDescription": "Use this reference architecture to extend an on-premises Active Directory domain to Azure to provide distributed authentication services.",
            "category": [
                "identity"
            ],
            "image": "/azure/architecture/reference-architectures/identity/images/adds-extend-domain.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\identity\\images\\adds-extend-domain.png",
            "publish_date": "5/02/2018",
            "sample_code": true,
            "github_url": "https://github.com/mspnp/identity-reference-architectures",
            "visio_diagram": "https://arch-center.azureedge.net/identity-architectures.vsdx",
            "code_languages": [
                "bash"
            ],
            "name": "adds-extend-domain",
            "popularity": 231,
            "topic": "Identity"
        },
        {
            "tags": [
                "all-items",
                "fcp",
                "reference-architecture",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "hybrid/deploy-ai-ml-azure-stack-edge.md",
            "http_url": "/azure/architecture/hybrid/deploy-ai-ml-azure-stack-edge",
            "word_count": 1325,
            "read_time": "5 min read",
            "Title": "Deploy AI and machine learning at the edge by using Azure Stack Edge",
            "MetaDescription": "Run intelligence workloads directly on IoT devices by using Azure Stack Edge",
            "category": [
                "hybrid",
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/hybrid/images/deploy-ai-ml-azure-stack-edge.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\hybrid\\images\\deploy-ai-ml-azure-stack-edge.png",
            "publish_date": "7/16/2020",
            "Summary": "<p>This reference architecture illustrates how to use Microsoft Azure Stack Edge to extend the ability to perform rapid machine learning inferencing from the cloud to on-premises or edge scenarios.</p>\n<p><img alt=\"The diagram illustrates Azure Stack Edge sending data to Azure Machine Learning to train a model that is deployed to Azure Stack Edge and Azure Container Registry to make inferences against sampled data.\" src=\"https://learn.microsoft.com/azure/architecture/hybrid/images/deploy-ai-ml-azure-stack-edge.png\" /></p>\n<p><em>Download a <a href=\"https://arch-center.azureedge.net/deploy-ai-ml-azure-stack-edge.vsdx\">Visio file</a> of this architecture.</em></p>\n<p>Typical uses for this architecture include:</p>\n<ul>\n<li>Performing local, rapid machine learning inference against data as it\u2019s ingested by organizations with a significant on-premises hardware footprint .</li>\n<li>Creating long-term research solutions where existing on-premises data is cleaned and used to generate a model. The model is then used both on-premises and in the cloud; it's retrained regularly as new data arrives.</li>\n<li>Building software applications that need to make inferences about users, both at a physical location and online.</li>\n</ul>",
            "visio_diagram": "https://arch-center.azureedge.net/deploy-ai-ml-azure-stack-edge.vsdx",
            "name": "deploy-ai-ml-azure-stack-edge",
            "popularity": 0,
            "topic": "AI + Machine Learning",
            "hybrid-topic": "Apps"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "github",
                "networking",
                "reference-architecture",
                "seodec18"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/dmz/nva-ha.yml",
            "http_url": "/azure/architecture/reference-architectures/dmz/nva-ha",
            "word_count": 1607,
            "read_time": "7 min read",
            "Title": "Deploy highly available NVAs",
            "MetaDescription": "Learn how to deploy network virtual appliances for high availability in Azure. This article includes example architectures for ingress, egress, and both.",
            "category": [
                "networking",
                "management-and-governance"
            ],
            "image": "/azure/architecture/reference-architectures/dmz/images/nva-ha/pip-udr-without-snat.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\dmz\\images\\nva-ha\\pip-udr-without-snat.png",
            "publish_date": "12/08/2018",
            "Summary": "<p>This article shows how to deploy a set of network virtual appliances (NVAs) for high availability in Azure. An NVA is typically used to control the flow of network traffic from a perimeter network, also known as a DMZ, to other networks or subnets. To learn about implementing a DMZ in Azure, see <a href=\"https://learn.microsoft.com/azure/best-practices-network-security\">Microsoft cloud services and network security</a>. The article includes example architectures for ingress only, egress only, and both ingress and egress.</p>\n<p><strong>Prerequisites:</strong> This article assumes a basic understanding of Azure networking, <a href=\"https://learn.microsoft.com/azure/load-balancer/load-balancer-overview\">Azure load balancers</a>, and <a href=\"https://learn.microsoft.com/azure/virtual-network/virtual-networks-udr-overview\">user-defined routes</a> (UDRs).</p>",
            "sample_code": true,
            "github_url": "https://github.com/mspnp/samples/tree/master/solutions/ha-nva",
            "name": "nva-ha",
            "popularity": 221,
            "topic": "Networking"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-collaborative-design-review-powered-by-mixed-reality-'",
                "acom-architecture",
                "all-items",
                "azure-active-directory",
                "azure-spatial-anchors",
                "blob-storage",
                "cosmos-db",
                "data-flow",
                "interactive-diagram",
                "microsoft-hololens",
                "solution-idea",
                "web-service"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/collaborative-design-review-powered-by-mixed-reality.md",
            "http_url": "/azure/architecture/solution-ideas/articles/collaborative-design-review-powered-by-mixed-reality",
            "word_count": 370,
            "read_time": "2 min read",
            "Title": "Design Review Powered by Mixed Reality",
            "MetaDescription": "Too often, product designers waste time and money with inefficient design review-2D images lose essential detail and context, and physical prototypes are extremely expensive. With this mixed reality scenario, clients, designers, and on-site engineers can easily share and review designs as 3D holograms in the context of their environment, accelerating design decisions and reducing time to market.",
            "category": [
                "mixed-reality"
            ],
            "image": "/azure/architecture/solution-ideas/media/collaborative-design-review-powered-by-mixed-reality.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\collaborative-design-review-powered-by-mixed-reality.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/active-directory\">Azure Active Directory</a>: Synchronize on-premises directories and enable single sign-on</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage/blobs\">Blob Storage</a>: REST-based object storage for unstructured data</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cosmos-db\">Azure Cosmos DB</a>: Globally distributed, multi-model database for any scale</p>"
            ],
            "Summary": "<p>Businesses and teams across industries have to spend time and money on design reviews. 2D images lose essential detail and context, and physical prototypes are extremely expensive. With this mixed reality scenario, clients, designers, and onsite engineers can easily share and review designs as 3D holograms in the context of their environment, accelerating design decisions and reducing time to market.</p>",
            "Flow": {
                "FlowStep_A": "Users of the client application authenticate using their Azure Active Directory credentials from HoloLens or a mobile device.",
                "FlowStep_B": "Device 1 creates an anchor using Azure Spatial Anchors and gets back an anchor ID.",
                "FlowStep_C": "Device 1 sends the anchor ID to the app's web service to create a collaboration session. It also specifies which hologram is to be displayed via its ID in Azure Blob storage.",
                "FlowStep_D": "Session information, including a 6-digit code to join the session, is stored in Azure Cosmos DB. That code is returned to the client, allowing the user of that device to invite others to join.",
                "FlowStep_E": "Device 2 connects to the app's web service and enters the code to join the session (displayed on Device 1).",
                "FlowStep_F": "The web service retrieves the anchor ID for the session and the ID of the hologram associated to that session from Azure Cosmos DB.",
                "FlowStep_G": "The web service retrieves a SAS key to access the hologram associated to the session from Blob storage. It then returns the anchor ID and SAS key to Device 2.",
                "FlowStep_H": "Device 2 queries Azure Spatial Anchors to get coordinates for the anchor ID retrieved in step 6.",
                "FlowStep_I": "Device 2 fetches the hologram from Blob storage using the SAS key obtained from the app service.",
                "FlowStep_J": "Device 1 and Device 2 exchange state information over a peer-to-peer networking channel (or through a service relay of your choice)."
            },
            "name": "collaborative-design-review-powered-by-mixed-reality",
            "popularity": 130,
            "topic": "Mixed Reality"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "app-development",
                "data-flow",
                "devops",
                "example-workload",
                "fasttrack",
                "pricing-calculator",
                "pricing-guidance",
                "seodec18"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/apps/devops-dotnet-baseline.yml",
            "http_url": "/azure/architecture/example-scenario/apps/devops-dotnet-baseline",
            "word_count": 1127,
            "read_time": "5 min read",
            "Title": "Design a CI/CD pipeline using Azure DevOps",
            "MetaDescription": "This architecture and design guidance example is a continuous integration and deployment pipeline for a two-tier .NET web application to the Azure App Service.",
            "category": [
                "developer-tools",
                "devops",
                "web",
                "featured"
            ],
            "image": "/azure/architecture/example-scenario/apps/media/architecture-devops-dotnet-webapp.svg",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\apps\\media\\architecture-devops-dotnet-webapp.svg",
            "publish_date": "12/06/2018",
            "pricing_calculator": "https://azure.com/e/498aa024454445a8a352e75724f900b1",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/devops\">Azure DevOps</a> is a service for managing your development lifecycle end-to-end&mdash;from planning and project management, to code management, and continuing to build and release.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/app-service/app-service-web-overview\">Azure Web Apps</a> is a PaaS service for hosting web applications, REST APIs, and mobile back ends. While this article focuses on .NET, there are several additional development platform options supported.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/application-insights\">Application Insights</a> is a first-party, extensible Application Performance Management (APM) service for web developers on multiple platforms.</p>"
            ],
            "Flow": {
                "FlowStep_A": "A developer changes application source code.",
                "FlowStep_B": "Application code including the web.config file is committed to the source code repository in Azure Repos.",
                "FlowStep_C": "Continuous integration triggers application build and unit tests using Azure Test Plans.",
                "FlowStep_D": "Continuous deployment within Azure Pipelines triggers an automated deployment of application artifacts *with environment-specific configuration values*.",
                "FlowStep_E": "The artifacts are deployed to Azure App Service.",
                "FlowStep_F": "Azure Application Insights collects and analyzes health, performance, and usage data.",
                "FlowStep_G": "Developers monitor and manage health, performance, and usage information.",
                "FlowStep_H": "Backlog information is used to prioritize new features and bug fixes using Azure Boards."
            },
            "name": "devops-dotnet-webapp",
            "popularity": 224,
            "topic": "Developer Tools"
        },
        {
            "tags": [
                "all-items",
                "fcp",
                "reference-architecture",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "hybrid/hybrid-dns-infra.md",
            "http_url": "/azure/architecture/hybrid/hybrid-dns-infra",
            "word_count": 2022,
            "read_time": "8 min read",
            "Title": "Design a hybrid Domain Name System solution with Azure",
            "MetaDescription": "Hybrid Domain Name System (DNS) solution to resolve names for workloads that are hosted on-premises and in Microsoft Azure",
            "category": [
                "hybrid",
                "networking"
            ],
            "image": "/azure/architecture/hybrid/images/hybrid-dns-infra.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\hybrid\\images\\hybrid-dns-infra.png",
            "publish_date": "7/23/2020",
            "Summary": "<p>This reference architecture illustrates how to design a hybrid Domain Name System (DNS) solution to resolve names for workloads that are hosted on-premises and in Microsoft Azure. This architecture works for users and other systems that are connecting from on-premises and the public internet.</p>\n<p><img alt=\"Hybrid Domain Name System (DNS)\" src=\"https://learn.microsoft.com/azure/architecture/hybrid/images/hybrid-dns-infra.png\" /></p>\n<p><em>Download a <a href=\"https://arch-center.azureedge.net/hybrid-dns-infra.vsdx\">Visio file</a> of this architecture.</em></p>",
            "visio_diagram": "https://arch-center.azureedge.net/hybrid-dns-infra.vsdx",
            "name": "hybrid-dns-infra",
            "popularity": 0,
            "topic": "Networking",
            "hybrid-topic": "Networking"
        },
        {
            "tags": [
                "acom-architecture",
                "all-items",
                "data-flow",
                "example-code",
                "github",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/devops-in-a-hybrid-environment.md",
            "http_url": "/azure/architecture/solution-ideas/articles/devops-in-a-hybrid-environment",
            "word_count": 482,
            "read_time": "3 min read",
            "Title": "DevOps in a hybrid environment",
            "MetaDescription": "The tools provided in Azure allow for the implementation of a DevOps strategy that capably manages both cloud and on-premises environments in tandem.",
            "category": [
                "devops",
                "hybrid"
            ],
            "image": "/azure/architecture/solution-ideas/media/devops-in-a-hybrid-environment.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\devops-in-a-hybrid-environment.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/devops/boards/github/connect-to-github?view=azure-devops\">Azure Boards</a>: Use Azure Board to plan work and track its progress, using Agile tools such as Kanban boards.</p>",
                "<p>Source code is hosted on <a href=\"https://github.com/enterprise\">GitHub Enterprise</a>, where developers can collaborate within your organization and the open source communities. GitHub Enterprise offers advanced security features to identify vulnerabilities in the code you write and in open source dependencies.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/devops/pipelines/?view=azure-devops&preserve-view=true\">Azure Pipelines</a>  runs Continuous Integration and Continuous Delivery jobs for your application, as well as the creation of your infrastructure with the integration with Terraform.</p>",
                "<p>You can use <a href=\"https://learn.microsoft.com/azure/key-vault/basic-concepts\">Azure Key Vault</a> to store certificates, connection strings, tokens, and other secrets. These are read by your application at run-time, so they're abstracted away from your developers</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/terraform/terraform-install-configure\">Terraform</a> is a third-party product developed by HashiCorp that allows infrastructure automation on Azure, on-premises, and other environments</p>",
                "<p>Using <a href=\"https://learn.microsoft.com/azure/azure-monitor/overview\">Azure Monitor</a> lets you get insights on the availability and performance of your application and infrastructure.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/active-directory/fundamentals/active-directory-whatis\">Azure AD</a> provides identity and access management services for your application, both on-premises and on the cloud. Azure AD can synchronize with an on-premises Active Directory to seamlessly allow your users to authenticate everywhere.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/app-service/overview\">Azure Web Apps</a> is a managed platform for hosting web-based applications in the cloud.</p>"
            ],
            "Summary": "<p>In many scenarios, the adoption of the Azure cloud as a business solution involves the migration of an on-premises environment. It is usually not practical to deprecate the on-premises environment quickly, and in many cases the on-premises environment will need to persist alongside the cloud environment for a significant amount of time. The tools provided in Azure allow for the implementation of a DevOps strategy that capably manages both cloud and on-premises environments in tandem.</p>\n<p><img alt=\"Architecture\" src=\"https://learn.microsoft.com/azure/architecture/solution-ideas/media/devops-in-a-hybrid-environment.png\" />\n<em>Download an <a href=\"https://learn.microsoft.com/azure/architecture/solution-ideas/media/devops-in-a-hybrid-environment.svg\">SVG</a> of this architecture.</em></p>",
            "Flow": {
                "FlowStep_A": "GitHub Enterprise is used as the code repository for the application",
                "FlowStep_B": "Pull Requests trigger CI builds and automated testing in Azure Pipelines",
                "FlowStep_C": "Continuous monitoring with Azure Monitor extends to release pipelines to gate or rollback releases based on monitoring data",
                "FlowStep_D": "A release on Azure Pipelines integrates the Terraform tool, managing both cloud and on-premises infrastructure as code, provisioning resources such as Azure Web Apps, VMs, and databases in both locations",
                "FlowStep_E": "Azure Pipelines define both Continuous Delivery (CD) to a development environment in the cloud, and release deployments to an on-premises production environment.",
                "FlowStep_F": "Azure Key Vault is used to securely inject secrets and credentials into a deployment, abstracting secrets away from developers",
                "FlowStep_G": "Azure Monitor can be configured to log analytics from both the cloud and on-premises environments. Application Insights as a part of Azure Monitor can be connected to both cloud and on-premises applications for monitoring",
                "FlowStep_H": "Azure AD in the cloud can be used to provide identity services for the application, both running on Azure and on-premises."
            },
            "sample_code": true,
            "github_url": "https://github.com/enterprise",
            "name": "devops-in-a-hybrid-environment",
            "popularity": 0,
            "topic": "DevOps",
            "hybrid-topic": "Apps"
        },
        {
            "tags": [
                "acom-architecture",
                "all-items",
                "data-flow",
                "azure-guide"
            ],
            "type": "azure-guide",
            "file_url": "guide/devsecops/devsecops-on-aks.yml",
            "http_url": "/azure/architecture/guide/devsecops/devsecops-on-aks",
            "word_count": 778,
            "read_time": "4 min read",
            "Title": "DevSecOps on AKS",
            "MetaDescription": "DevSecOps involves utilizing security best practices from the beginning of development, shifting the focus on security away from auditing at the end and towards development in the beginning",
            "category": [
                "devops",
                "hybrid"
            ],
            "image": "/azure/architecture/guide/devsecops/media/devsecops-azure-aks.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\guide\\devsecops\\media\\devsecops-azure-aks.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/active-directory/fundamentals/active-directory-whatis\">Azure Active Directory</a> provides identity and access management services for your organization, allowing control over access to the resources inside Azure, GitHub Enterprise, and Azure DevOps.</p>",
                "<p>Source code is hosted on <a href=\"https://help.github.com/en/github\">GitHub Enterprise</a>, where developers can collaborate within your organization and the open-source communities. GitHub Enterprise offers advanced security features to identify vulnerabilities in the code you write and in open-source dependencies</p>",
                "<p>Use <a href=\"https://learn.microsoft.com/azure/devops/boards/github/connect-to-github?view=azure-devops\">Azure Boards</a> to plan work and track its progress, using Agile tools such as Kanban boards.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/devops/pipelines/get-started/pipelines-get-started?view=azure-devops\">Azure Pipelines</a> is a service that provides Continuous Integration and Continuous Delivery jobs, to build and release your application automatically.</p>",
                "<p>Host your Docker container images on <a href=\"https://learn.microsoft.com/azure/container-registry/container-registry-concepts\">Azure Container Registry</a>. This service includes container image scanning with the integration with Azure Security Center.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/aks/intro-kubernetes\">Azure Kubernetes Service</a> offers a Kubernetes cluster that is fully managed by Azure, to ensure availability and security of your infrastructure.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/terraform/terraform-create-k8s-cluster-with-tf-and-aks\">Terraform</a> is a third-party product developed by HashiCorp that allows infrastructure automation on Azure, as well as on other environments.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/governance/policy/overview\">Azure Policy</a> lets you create, assign, and manage policies. These policies enforce different rules and effects over your resources, so those resources stay compliant with your corporate standards and service level agreements. It integrates with Azure Kubernetes Service too.</p>",
                "<p>You can use <a href=\"https://learn.microsoft.com/azure/key-vault/key-vault-overview\">Azure Key Vault</a> to store certificates, connection strings, tokens, and other secrets. This sensitive information is read by your application at run-time, so it's abstracted away from your developers.</p>",
                "<p>Azure <a href=\"https://learn.microsoft.com/azure/cosmos-db/introduction\">Azure Cosmos DB</a> is a globally distributed, multi-model database service, that is fully managed and compatible with multiple APIs, including MongoDB, Cassandra, SQL.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/application-gateway/ingress-controller-overview\">Azure Application Gateway</a> is a Layer-7 load balancer with support for advanced routing rules and a Web Application Firewall (WAF).</p>",
                "<p>Using <a href=\"https://learn.microsoft.com/azure/azure-monitor/overview\">Azure Monitor</a> lets you get insights on the availability and performance of your application and infrastructure. It also gives you access to signals to monitor your solution's health and spot abnormal activity early.</p>",
                "<p>Using <a href=\"https://learn.microsoft.com/azure/active-directory-b2c/overview\">Azure AD B2C</a> you can provide identity services to consumers (end-users) of your application, even if they're not part of your organization.</p>"
            ],
            "Summary": "<p>Security is a prime concern for businesses that store any sort of custom or client data. The solution that is covering the management and interface of this data should be developed with security in mind. DevSecOps involves utilizing security best practices from the beginning of development, shifting the focus on security away from auditing at the end and towards development in the beginning using a shift-left strategy.</p>\n<p><img alt=\"Architecture Diagram\" src=\"https://learn.microsoft.com/azure/architecture/guide/devsecops/media/devsecops-azure-aks.png\" />\n<em>Download an <a href=\"https://learn.microsoft.com/azure/architecture/guide/devsecops/media/devsecops-azure-aks.svg\">SVG</a> of this architecture.</em></p>",
            "Flow": {
                "FlowStep_A": "Azure Active Directory (AD) can be configured as the identity provider for GitHub. Multi-factor authentication can be enabled for extra security.",
                "FlowStep_B": "Developers commit to GitHub Enterprise, driven by work items and bugs tracked with Azure Boards.",
                "FlowStep_C": "GitHub Enterprise can integrate automatic security and dependency scanning through GitHub Advanced Security and GitHub Open Source Security.",
                "FlowStep_D": "Pull Requests trigger CI builds and automated testing in Azure Pipelines.",
                "FlowStep_E": "The CI build in Azure Pipelines generates a Docker container image that is stored to Azure Container Registry, which is to be used at release time by Azure Kubernetes Service.",
                "FlowStep_F": "Upon uploading to the Azure Container Registry, Azure Security Center will scan the image for Azure-native vulnerabilities and for security recommendations for the pushed image.",
                "FlowStep_G": "A release on Azure Pipelines integrates the Terraform tool, managing both the cloud infrastructure as code, provisioning resources such as Azure Kubernetes Service, Application Gateway, and Azure Cosmos DB.",
                "FlowStep_H": "Azure Pipelines enable Continuous Delivery (CD) to Azure Kubernetes Service, by accessing the Container Registry through a secure service connection.",
                "FlowStep_I": "Azure Policy can be applied to Azure Pipelines to enforce post-deployment gateways, and can be applied directly to the AKS engine for policy enforcement.",
                "FlowStep_J": "Azure Key Vault is used to securely inject secrets and credentials into an application at runtime, abstracting sensitive information away from developers.",
                "FlowStep_K": "End users can authenticate with Azure AD B2C, required to use MFA for extra security, and be routed through an Application Gateway that can load balance and protect core services.",
                "FlowStep_L": "Continuous monitoring with Azure Monitor extends to release pipelines to gate or rollback releases based on monitoring data. Azure Monitor also ingests security logs and can alert on suspicious activity.",
                "FlowStep_M": "As addition and final part of a DevSecOps flow, Azure Security Center will be able to do active threat monitoring on the Azure Kubernetes Service, on both Node level (VM threats) and internals."
            },
            "name": "devsecops-on-aks",
            "popularity": 0,
            "topic": "DevOps",
            "hybrid-topic": "Apps"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "fcp",
                "github",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/devsecops-in-github.md",
            "http_url": "/azure/architecture/solution-ideas/articles/devsecops-in-github",
            "word_count": 2089,
            "read_time": "8 min read",
            "Title": "DevSecOps in GitHub",
            "MetaDescription": "Learn how GitHub tools make security practices an integral part of DevOps while maintaining efficiency. See how to use these tools within an Azure framework.",
            "category": [
                "devops",
                "security"
            ],
            "image": "/azure/architecture/solution-ideas/media/devsecops-in-github-data-flow.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\devsecops-in-github-data-flow.png",
            "publish_date": "9/01/2020",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/active-directory/fundamentals/active-directory-whatis\">Azure AD</a> is a multi-tenant, cloud-based identity service that controls access to Azure and other cloud apps like <a href=\"https://www.microsoft.com/microsoft-365/what-is-microsoft-365\">Microsoft 365</a> and GitHub.</p>",
                "<p><a href=\"https://docs.github.com/en/github\">GitHub</a> provides a code-hosting platform that developers can use for collaborating on both open-source and <a href=\"https://resources.github.com/whitepapers/introduction-to-innersource/\">inner-source</a> projects.</p>",
                "<p><a href=\"https://docs.github.com/en/github/developing-online-with-codespaces/about-codespaces\">Codespaces</a> is an online development environment. Hosted by GitHub and powered by <a href=\"https://code.visualstudio.com/\">Visual Studio Code</a>, this tool provides a complete development solution in the cloud.</p>",
                "<p><a href=\"https://github.com/features/security\">GitHub Security</a> works to eliminate threats in a number of ways. Agents and services identify vulnerabilities in repositories and in dependent packages. They also upgrade dependencies to up-to-date, secure versions.</p>",
                "<p><a href=\"https://docs.github.com/en/actions/getting-started-with-github-actions/about-github-actions\">GitHub Actions</a> are custom workflows that provide continuous integration (CI) and continuous deployment (CD) capabilities directly in repositories. Computers called <em>runners</em> host these CI/CD jobs.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/app-service/\">App Service</a> provides a framework for building, deploying, and scaling web apps. This platform offers built-in infrastructure maintenance, security patching, and scaling.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/governance/policy/overview\">Azure Policy</a> helps teams manage and prevent IT issues through policy definitions that can enforce rules for cloud resources. For instance, if your project is about to deploy a virtual machine with an unrecognized SKU, Azure Policy alerts you to the problem and stops the deployment.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/security-center/security-center-intro\">Azure Security Center</a> provides unified security management and advanced threat protection across hybrid cloud workloads.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/azure-monitor/overview\">Azure Monitor</a> collects and analyzes app telemetry, such as performance metrics and activity logs. When this service identifies irregular conditions, it alerts apps and personnel.</p>"
            ],
            "Summary": "<p>Starting with the first steps of development, DevSecOps adheres to security best practices. By using a <a href=\"https://devops.com/devops-shift-left-avoid-failure/\">shift-left</a> strategy, DevSecOps redirects the security focus. Instead of pointing toward auditing at the end, it shifts to development in the beginning. Besides producing robust code, this <a href=\"https://whatis.techtarget.com/definition/fail-fast\">fail fast</a> approach helps to resolve problems early on, when they're easy to fix.</p>\n<p>With many security capabilities, GitHub offers tools that support every part of a DevSecOps workflow:</p>\n<ul>\n<li>Browser-based IDEs with built-in security extensions.</li>\n<li>Agents that continuously monitor security advisories and replace vulnerable and out-of-date dependencies.</li>\n<li>Search capabilities that scan source code for vulnerabilities.</li>\n<li>Action-based workflows that automate every step of development, testing, and deployment.</li>\n<li>Spaces that provide a way to privately discuss and resolve security threats and then publish the information.</li>\n</ul>\n<p>Combined with the monitoring and evaluation power of Azure, these features provide a superb service for building secure cloud solutions.</p>",
            "sample_code": true,
            "github_url": "https://github.com/features/security",
            "name": "devsecops-in-github",
            "popularity": 0,
            "topic": "DevOps"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-dev-test-image-factory-'",
                "acom-architecture",
                "all-items",
                "azure-devtest-image-factory",
                "create-custom-image",
                "data-flow",
                "devops",
                "image-management-solutions",
                "interactive-diagram",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/dev-test-image-factory.md",
            "http_url": "/azure/architecture/solution-ideas/articles/dev-test-image-factory",
            "word_count": 244,
            "read_time": "2 min read",
            "Title": "DevTest Image Factory",
            "MetaDescription": "Create, maintain, and distribute custom images with the DevTest Image Factory, an automated image development and management solution from Azure DevTest Labs.",
            "category": [
                "devops",
                "compute",
                "management-and-governance"
            ],
            "image": "/azure/architecture/solution-ideas/media/dev-test-image-factory.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\dev-test-image-factory.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/lab-services\">Azure Lab Services</a>: Set up labs for classrooms, trials, development and testing, and other scenarios</p>",
                "<p><a href=\"https://azure.microsoft.com/services/virtual-machines\">Virtual Machines</a>: Provision Windows and Linux virtual machines in seconds</p>",
                "<p><a href=\"https://azure.microsoft.com/services/devops\">Azure DevOps</a>: Services for teams to share code, track work, and ship software</p>"
            ],
            "Summary": "<p>The image factory provides a great way for organizations to create, maintain, and distribute custom images with Azure DevTest Labs. Whether you have globally distributed teams that need to work with a common set of custom images, need to centrally manage the configuration of images to ensure they meet regulatory compliance and security requirements, or complex software setup and configuration requirements, the image factory provides an automated solution to manage it</p>",
            "Flow": {
                "FlowStep_A": "With config as code, define the images to push and select which labs will receive the image.",
                "FlowStep_B": "IT admin checks into source code control of choice (such as Visual Studio Team Services or GitHub + Jenkins).",
                "FlowStep_C": "Orchestrator triggers \"golden image\" creation based on configuration in source code control that goes to the image factory.",
                "FlowStep_D": "Image factory lab receives commands to create virtual machines (VMs) and custom images.",
                "FlowStep_E": "Specified images copied from image factory lab to team labs.",
                "FlowStep_F": "Team lab users claim VMs or create VMs with the latest images."
            },
            "name": "dev-test-image-factory",
            "popularity": 43,
            "topic": "DevOps"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "fcp",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/dev-test-iaas.md",
            "http_url": "/azure/architecture/solution-ideas/articles/dev-test-iaas",
            "word_count": 1068,
            "read_time": "5 min read",
            "Title": "DevTest and DevOps for IaaS solutions",
            "MetaDescription": "Learn how to configure a DevTest and DevOps infrastructure for development, testing, and deploying IaaS-based software.",
            "category": [
                "devops",
                "management-and-governance"
            ],
            "image": "/azure/architecture/solution-ideas/media/dev-test-iaas.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\dev-test-iaas.png",
            "publish_date": "9/17/2020",
            "alternative_choices": "alternatives",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/devtest-lab/\">Azure DevTest Labs</a> provides labs that have all the necessary tools and software to create environments. Developers can efficiently self-manage resources without waiting for approvals. With DevTest Labs, teams can control costs and regulate resources per lab, granting developers permission and flexibility to operate their sandboxes within cost constraints.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-machines/windows/image-builder-overview\">Azure VM Image Builder</a> service provides baseline VM images that developers can customize. The service facilitates the creation and patching of images and can be called as an Azure Pipelines task.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-machines/windows/shared-image-galleries\">Shared Image Gallery</a> acts as a VM image repository for IaaS solutions. VM Image Builder can build directly into a Shared Image Gallery, facilitating an Azure Pipelines CI/CD process of versioning the VM-based application.</p>",
                "<p><a href=\"https://docs.github.com/github/creating-cloning-and-archiving-repositories/about-repositories\">GitHub</a> is a code hosting platform for version control and collaboration. A GitHub repository contains all project files and their revision history. Developers can work together to contribute, discuss, and manage code in the repository.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/devops/pipelines/\">Azure Pipelines</a> deploys the VM application images. Pipelines can also deploy the VM resources themselves, through <a href=\"https://learn.microsoft.com/azure/azure-resource-manager/templates/overview\">Azure Resource Manager (ARM) templates</a>. This <a href=\"https://learn.microsoft.com/azure/devops/learn/what-is-infrastructure-as-code\">infrastructure-as-code</a> can be source controlled and configured for CI/CD, ensuring that the infrastructure remains up to date.</p>",
                "<p><a >DevSecOps on AKS</a>.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/devops/boards/\">Azure Boards</a> is a service for managing work for software projects. Azure Boards brings a rich set of capabilities, including native support for Scrum and Kanban methodologies, customizable dashboards, and integrated reporting.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/active-directory/fundamentals/active-directory-whatis\">Azure Active Directory (Azure AD)</a> enterprise identity platform provides single sign-on and multifactor authentication to govern user access to resources. In this scenario, a separate Azure AD per subscription creates a distinct separation of concerns between Azure users.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/azure-policy/\">Azure Policy</a> governs resources to meet organizational standards and compliance. In a DevTest role, Azure Policy can regulate and limit the number and costs of VMs in the subscription. Auditing can provide insights and track the usage of the DevTest VMs.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/devtest-labs/security-baseline\">Azure Monitor</a> can work across subscriptions to monitor VMs in both Production and DevTest environments. Azure Monitor can collect log data from VM operating systems as well as crash dump files, and aggregate them for viewing in <a href=\"https://learn.microsoft.com/azure/security-center/security-center-enable-data-collection\">Azure Security Center</a>.</p>"
            ],
            "Summary": "<p><em>Infrastructure as a service (IaaS)</em> is a form of cloud computing that provides virtualized computing resources. <em>Development testing (DevTest)</em> is a software development approach that integrates testing early in the development phase. In this solution, configuring DevTest operations for an IaaS application reduces the cost and overhead of development and test environments, while facilitating faster development through automated virtual machine (VM) and VM image integration and deployment.</p>\n<p><em>DevOps</em> is a set of practices that combine software development and IT operations to shorten the development cycle and provide high-quality continuous deployments (CD). Using <a href=\"https://azure.microsoft.com/services/devops/\">Azure DevOps</a> with DevTest environments lends power and focus to the IaaS development process.</p>",
            "name": "dev-test-iaas",
            "popularity": 126,
            "topic": "DevOps"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "example-code",
                "fcp",
                "github",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/dev-test-paas.md",
            "http_url": "/azure/architecture/solution-ideas/articles/dev-test-paas",
            "word_count": 1352,
            "read_time": "6 min read",
            "Title": "DevTest and DevOps for PaaS solutions",
            "MetaDescription": "Learn how to configure a DevTest and DevOps infrastructure for development, testing, and deploying PaaS-based software.",
            "category": [
                "devops",
                "management-and-governance"
            ],
            "image": "/azure/architecture/solution-ideas/media/dev-test-paas.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\dev-test-paas.png",
            "publish_date": "9/17/2020",
            "alternative_choices": "alternatives",
            "Summary": "<p>In <em>platform as a service (PaaS)</em> cloud computing, a service provider delivers a platform for clients to develop, run, and manage applications without having to build and maintain infrastructure. Solution development based on Azure Platform resources and services removes the overhead of managing virtual machines, virtual networks, disks, and related configurations.</p>\n<p><em>Development testing (DevTest)</em> is a software development approach that integrates testing early in the development phase. <em>DevOps</em> is a set of practices that combine software development and IT operations, to shorten the development cycle and provide continuous delivery with high quality.</p>\n<p>This solution architecture combines reduced overhead and a DevOps toolchain to support rapid DevTest iteration cycles and a fast development environment with PaaS resources.</p>",
            "sample_code": true,
            "github_url": "https://github.com/features/packages",
            "name": "dev-test-paas",
            "popularity": 151,
            "topic": "DevOps"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "example-code",
                "fcp",
                "github",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/dev-test-microservice.md",
            "http_url": "/azure/architecture/solution-ideas/articles/dev-test-microservice",
            "word_count": 1216,
            "read_time": "5 min read",
            "Title": "DevTest and DevOps for microservice solutions",
            "MetaDescription": "Learn how to configure a DevTest and DevOps infrastructure for development, testing, and deploying microservice-based software.",
            "category": [
                "devops",
                "management-and-governance"
            ],
            "image": "/azure/architecture/solution-ideas/media/dev-test-microservice.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\dev-test-microservice.png",
            "publish_date": "9/17/2020",
            "alternative_choices": "alternatives",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/devtest-lab/\">Azure DevTest Labs</a> provides labs that have all the necessary tools and software to create environments. Developers can efficiently self-manage resources without waiting for approvals. With DevTest Labs, teams can control costs and regulate resources per lab, granting developers permission and flexibility to operate their sandboxes within cost constraints.</p>",
                "<p><a href=\"https://docs.github.com/github/creating-cloning-and-archiving-repositories/about-repositories\">GitHub</a> is a code hosting platform for version control and collaboration. A GitHub source-control <a href=\"https://docs.github.com/github/creating-cloning-and-archiving-repositories/about-repositories\">repository</a> contains all project files and their revision history. Developers can work together to contribute, discuss, and manage code in the repository.</p>",
                "<p><a href=\"https://github.com/features/actions\">GitHub Actions</a> provides a suite of build and release workflows, covering CI, automated testing, and container deployments.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/devops/boards/\">Azure Boards</a> is a service for managing work for software projects. Azure Boards brings a rich set of capabilities including native support for Scrum and Kanban methodologies, customizable dashboards, and integrated reporting.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/devops/pipelines/\">Azure Pipelines</a> is a fully featured CI/CD service that can automatically deploy updated Container Registry images to Kubernetes clusters.</p>",
                "<p><a >DevSecOps in GitHub</a>.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/container-registry/\">Azure Container Registry</a> supports building, storing, and managing container images and artifacts in private registries for all types of container deployments.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/aks/intro-kubernetes\">Azure Kubernetes Service</a> makes it simple to deploy managed Kubernetes clusters by offloading much of the complexity, responsibility, and operational overhead to Azure.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/active-directory/fundamentals/active-directory-whatis\">Azure Active Directory (Azure AD)</a> enterprise identity platform provides single sign-on and multifactor authentication to govern user access. A single Azure AD can manage identity for all environments across subscriptions. <a href=\"https://learn.microsoft.com/azure/role-based-access-control/overview\">Role-based access control (RBAC)</a> restricts access to protected resources, preventing unauthorized or inadvertent modification of production resources.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/cosmos-db/optimize-dev-test\">Azure Cosmos DB</a> is a fully managed, widely distributed database-as-a-service that supports high availability, multi-region applications, and both SQL and NoSQL APIs. Azure Cosmos DB includes DevTest features like a local emulator that integrates with Azure DevOps, and low-cost tiers for managing costs in DevTest sandboxes.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/devtest-labs/security-baseline\">Azure Monitor</a> can monitor both Production and DevTest environments. Azure Monitor collects log data from VM operating systems and crash dump files, and aggregates them for viewing in <a href=\"https://learn.microsoft.com/azure/security-center/security-center-enable-data-collection\">Azure Security Center</a>.</p>"
            ],
            "Summary": "<p>Microservice architectures design applications as collections of loosely coupled services. In a microservices architecture, services are fine-grained and protocols are lightweight. Microservices offer benefits such as clear separation of concerns and decoupling of dependencies.</p>\n<p>Microservices introduce complexities in the development cycle compared to traditional monolithic applications. Traditionally, development occurs in a local or virtual replica of the application stack, which configures and runs compute and storage components locally in isolation. In a microservice model, developers need to test their services against the existing architecture, catch integration issues early to save on build and deployment time, and keep integrated builds clean over the lifecycle of the application.</p>\n<p><em>Development testing (DevTest)</em> is a software development approach that integrates testing early in the development phase to speed development. <em>DevOps</em> is a set of practices that combine software development and IT operations to shorten the development cycle and provide high-quality continuous delivery. <a href=\"https://kubernetes.io/\">Kubernetes</a> is an open-source container orchestration system for automating application deployments.</p>\n<p>This solution architecture models a development and deployment environment that uses DevOps in DevTest for rapid iterative development of an <a href=\"https://azure.microsoft.com/services/kubernetes-service/\">Azure Kubernetes Service (AKS)</a> microservice application. </p>",
            "sample_code": true,
            "github_url": "https://github.com/marketplace/azure-boards",
            "name": "dev-test-microservice",
            "popularity": 118,
            "topic": "DevOps"
        },
        {
            "tags": [
                "all-items",
                "data-flow",
                "example-workload",
                "fasttrack",
                "is-deployable",
                "pricing-calculator",
                "pricing-guidance",
                "sap"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/apps/sap-dev-test.yml",
            "http_url": "/azure/architecture/example-scenario/apps/sap-dev-test",
            "word_count": 716,
            "read_time": "4 min read",
            "Title": "Development and test environments for SAP workloads on Azure",
            "MetaDescription": "Learn how to establish a dev/test environment for SAP NetWeaver on Azure. This architecture is designed for non-production environments.",
            "category": [
                "databases"
            ],
            "image": "/azure/architecture/example-scenario/apps/media/architecture-sap-dev-test.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\apps\\media\\architecture-sap-dev-test.png",
            "publish_date": "7/11/2018",
            "deployable": "https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2Fmspnp%2Fsolution-architectures%2Fmaster%2Fapps%2Fsap-2tier%2Fazuredeploy.json",
            "pricing_calculator": "https://azure.com/e/9d26b9612da9466bb7a800eab56e71d1",
            "pricing_guidance": "pricing",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-network/virtual-networks-overview\">Virtual networks</a> are the basis of network communication within Azure.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-machines/windows/overview\">Azure Virtual Machines</a> provide on-demand, high-scale, secure, virtualized infrastructure using Windows or Linux servers.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/expressroute/expressroute-introduction\">ExpressRoute</a> extends your on-premises networks into the Microsoft cloud over a private connection facilitated by a connectivity provider.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-network/security-overview\">Network security groups</a> limit network traffic to specific resources in a virtual network. A network security group contains a list of security rules that allow or deny inbound or outbound network traffic based on source or destination IP address, port, and protocol.</p>"
            ],
            "Summary": "<p>This example shows how to establish a dev/test environment for SAP NetWeaver in a Windows or Linux environment on Azure. The database used is AnyDB, the SAP term for any supported DBMS (that isn't SAP HANA). Because this architecture is designed for non-production environments, it's deployed with only one virtual machine (VM), and the virtual machine size can be changed to accommodate your organization's needs.</p>\n<p>For production use cases review the SAP reference architectures available below:</p>\n<ul>\n<li><a >SAP NetWeaver for AnyDB</a></li>\n<li><a >SAP S/4HANA</a></li>\n<li><a >SAP on Azure large instances</a></li>\n</ul>",
            "Flow": {
                "FlowStep_A": "Customers use the SAP user interface or other client tools (Excel, a web browser, or other web application) to access the Azure-based SAP system.",
                "FlowStep_B": "Connectivity is provided through the use of an established ExpressRoute. The ExpressRoute connection is terminated in Azure at the ExpressRoute gateway. Network traffic routes through the ExpressRoute gateway to the gateway subnet, and from the gateway subnet to the application-tier spoke subnet (see the [hub-spoke network topology][hub-spoke]) and via a Network Security Gateway to the SAP application virtual machine.",
                "FlowStep_C": "The identity management servers provide authentication services.",
                "FlowStep_D": "The jump box provides local management capabilities."
            },
            "name": "sap-dev-test",
            "popularity": 119,
            "topic": "Databases"
        },
        {
            "tags": [
                "acom-architecture",
                "all-items",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/digital-asset-management.md",
            "http_url": "/azure/architecture/solution-ideas/articles/digital-asset-management",
            "word_count": 225,
            "read_time": "2 min read",
            "Title": "Digital Asset Management",
            "MetaDescription": "Knowledge mining through a search index makes it easy for end customers and employees to locate what they are looking for faster.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/knowledge-mining-digital-asset-management.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\knowledge-mining-digital-asset-management.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>This architecture describes digital asset management for knowledge mining.</p>\n<p>Given the amount of unstructured data created daily, many companies are struggling to make use of or find information within their files. Knowledge mining through a search index makes it easy for end customers and employees to locate what they are looking for faster.</p>\n<p><img alt=\"Architecture Diagram\" src=\"https://learn.microsoft.com/azure/architecture/solution-ideas/media/knowledge-mining-digital-asset-management.png\" /></p>",
            "name": "digital-asset-management",
            "popularity": 0,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-digital-marketing-using-azure-database-for-postgresql-'",
                "acom-architecture",
                "all-items",
                "azure",
                "postgresql",
                "solution-idea",
                "solutions",
                "use-cases",
                "web-apps"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/digital-marketing-using-azure-database-for-postgresql.md",
            "http_url": "/azure/architecture/solution-ideas/articles/digital-marketing-using-azure-database-for-postgresql",
            "word_count": 41,
            "read_time": "1 min read",
            "Title": "Digital Campaign Management",
            "MetaDescription": "Use Azure Database for PostgreSQL to engage with customers around the world with rich, personalized digital marketing experiences.",
            "category": [
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/digital-marketing-using-azure-database-for-postgresql.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\digital-marketing-using-azure-database-for-postgresql.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Engage with customers around the world with rich, personalized digital marketing experiences. Quickly build and launch digital campaigns that automatically scale based on customer demand.</p>",
            "name": "digital-marketing-using-azure-database-for-postgresql",
            "popularity": 63,
            "topic": "Databases"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-digital-marketing-using-azure-database-for-mysql-'",
                "acom-architecture",
                "all-items",
                "azure",
                "mysql",
                "solution-idea",
                "solutions",
                "use-cases",
                "web-apps"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/digital-marketing-using-azure-database-for-mysql.md",
            "http_url": "/azure/architecture/solution-ideas/articles/digital-marketing-using-azure-database-for-mysql",
            "word_count": 45,
            "read_time": "1 min read",
            "Title": "Digital Marketing using Azure Database for MySQL",
            "MetaDescription": "Use Azure Database for MySQL to engage with customers around the world with rich, personalized digital marketing experiences.",
            "category": [
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/digital-marketing-using-azure-database-for-mysql.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\digital-marketing-using-azure-database-for-mysql.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Engage with customers around the world with rich, personalized digital marketing experiences. Quickly build and launch digital campaigns that automatically scale based on customer demand.</p>",
            "name": "digital-marketing-using-azure-database-for-mysql",
            "popularity": 45,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "cat-team",
                "example-code",
                "example-workload",
                "github",
                "hpc",
                "linux",
                "pricing-calculator",
                "pricing-guidance"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/infrastructure/image-modeling.yml",
            "http_url": "/azure/architecture/example-scenario/infrastructure/image-modeling",
            "word_count": 1573,
            "read_time": "7 min read",
            "Title": "Digital image-based modeling on Azure",
            "MetaDescription": "Accelerate digital image-based modeling on Azure using Avere and Agisoft PhotoScan",
            "category": [
                "compute",
                "storage"
            ],
            "image": "/azure/architecture/example-scenario/infrastructure/media/architecture-image-modeling.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\infrastructure\\media\\architecture-image-modeling.png",
            "publish_date": "1/11/2019",
            "pricing_calculator": "https://azure.com/e/42362ddfd2e245a28a8e78bc609c80f3",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "components": [
                "<p><a href=\"http://www.agisoft.com/\">Agisoft PhotoScan</a>: The PhotoScan Scheduler runs on a Windows 2016 Server VM, and the processing nodes use five VMs with GPUs that run CentOS Linux 7.5.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/avere-vfxt/avere-vfxt-overview\">Avere vFXT</a> is a file caching solution that uses object storage and traditional network-attached storage (NAS) to optimize storage of large datasets. It includes:</p>",
                "<p>Avere Controller. This VM executes the script that installs the Avere vFXT cluster and runs Ubuntu 18.04 LTS. The VM can be used later to add or remove cluster nodes and to destroy the cluster as well.</p>",
                "<p>vFXT cluster. At least three VMs are used, one for each of the Avere vFXT nodes based on Avere OS 5.0.2.1. These VMs form the vFXT cluster, which is attached to Azure Blob storage.</p>",
                "<p><a href=\"https://learn.microsoft.com/windows/desktop/ad/active-directory-domain-services\">Microsoft Active Directory domain controllers</a> allow the host access to domain resources and provide DNS name resolution. Avere vFXT adds a number of A records &mdash; for example, each A record in a vFXT cluster points to the IP address of each Avere vFXT node. In this setup, all VMs use the round-robin pattern to access vFXT exports.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-machines/\">Other VMs</a> serve as jump boxes used by the administrator to access the scheduler and processing nodes. The Windows jumpbox is mandatory to allow the administrator to access the head node via remote desktop protocol. The second jumpbox is optional and runs Linux for administration of the worker nodes.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-network/manage-network-security-group\">Network security groups</a>  limit access to the public IP address (PIP) and allow ports 3389 and 22 for access to the VMs attached to the Jumpbox subnet.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-network/virtual-network-peering-overview\">Virtual network peering</a> connects a PhotoScan virtual network to an Avere virtual network.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/storage/blobs/storage-blobs-introduction\">Azure Blob storage</a> works with Avere vFXT as the core filer to store the committed data being processed. Avere vFXT identifies the active data stored in Azure Blob and tiers it into solid-state drives (SSD) used for caching in its compute nodes while a PhotoScan job is running. If changes are made, the data is asynchronously committed back to the core filer.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/key-vault/key-vault-overview\">Azure Key Vault</a> is used to store the administrator passwords and PhotoScan activation code.</p>"
            ],
            "sample_code": true,
            "github_url": "https://github.com/paulomarquesc/beegfs-template",
            "name": "image-modeling",
            "popularity": 145,
            "topic": "Compute"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "fcp",
                "reference-architecture",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "hybrid/azure-stack-vm-dr.md",
            "http_url": "/azure/architecture/hybrid/azure-stack-vm-dr",
            "word_count": 7577,
            "read_time": "29 min read",
            "Title": "Disaster Recovery for Azure Stack Hub virtual machines",
            "MetaDescription": "Optimized approach to disaster recovery of virtual machine (VM)-based user workloads hosted on Azure Stack Hub",
            "category": [
                "hybrid",
                "management-and-governance"
            ],
            "image": "/azure/architecture/hybrid/images/azure-stack-vm-dr.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\hybrid\\images\\azure-stack-vm-dr.png",
            "publish_date": "8/06/2020",
            "alternative_choices": "alternatively,-you-have-the-option-to-use-workload-specific-replication-mechanisms-to-provide-site-level-resiliency.-this-is-a-commonly-used-option-when-implementing-disaster-recovery-for-ad-ds-domain-controllers,-sql-server,-or-exchange,-all-of-which-natively-support-replication.-though-this-requires-provisioning-azure-vms-hosting-these-workloads-in-the-disaster-recovery-environment,-which-increases-the-cost,-it-offers-the-following-benefits:",
            "Summary": "<p>This document describes the architecture and design considerations of a solution that delivers an optimized approach to disaster recovery of virtual machine (VM)-based user workloads hosted on Azure Stack Hub.</p>\n<p><img alt=\"The diagram illustrates the architecture of an Azure Stack Hub disaster recovery solution based on Azure Site Recovery. The solution consists of a configuration server and process server components runing on an Azure Stack Hub VM. These components are capable of protecting both Windows Server VMs running such workloads as SQL Server or Sharepoint Server, as well as CentOS and Ubuntu Linux VMs. The Azure components of the solution include an geo-redundant Azure Recovery Services vault handling orchestration tasks and an Azure Storage account serving as the destination of the replication traffic originating from the Azure Stack Hub VMs.\" src=\"https://learn.microsoft.com/azure/architecture/hybrid/images/azure-stack-vm-dr.png\" /></p>\n<p><em>Download a <a href=\"https://arch-center.azureedge.net/azure-stack-vm-dr.vsdx\">Visio file</a> of this architecture.</em></p>\n<p>Azure Stack Hub includes self-healing functionality, providing auto-remediation in a range of scenarios involving localized failures of its components. However, large-scale failures, including outages affecting server racks or site-level disasters, require additional considerations. These considerations should be part of the business continuity and disaster recovery strategy for VM-based user workloads. This strategy must also account for recovery of the Azure Stack infrastructure, which is separate from workload recovery.</p>\n<p>Traditional, on-premises workload recovery solutions are complex to configure, expensive and labor-intensive to maintain, and challenging to automate, especially when using another on-premises location as the failover site. Microsoft recommends an alternative solution that relies on a combination of the cloud and on-premises components to deliver resilient, performance-based, highly automated, and straightforward ways to manage, secure, and achieve a cost-efficient disaster recovery strategy. The core element of this solution is the Microsoft Azure Recovery Services offering, with the failover site residing in Azure.</p>\n<p>Azure Site Recovery with Azure as the failover site eliminates all of these drawbacks. You can use its capabilities to protect both physical and virtual servers, including those running on either Microsoft Hyper-V or VMware ESXi virtualization platforms. You also have the option to leverage the same capabilities to facilitate recovery of workloads running on Azure Stack Hub VMs.</p>",
            "visio_diagram": "https://arch-center.azureedge.net/azure-stack-vm-dr.vsdx",
            "name": "azure-stack-vm-dr",
            "popularity": 0,
            "topic": "Management and Governance",
            "hybrid-topic": "Management"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-cloud-scale-analytics-with-discovery-hub-'",
                "acom-architecture",
                "all-items",
                "azure-discovery-hub",
                "cloud-scale-analytics",
                "data-flow",
                "data-warehouse-analytics",
                "interactive-diagram",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/cloud-scale-analytics-with-discovery-hub.md",
            "http_url": "/azure/architecture/solution-ideas/articles/cloud-scale-analytics-with-discovery-hub",
            "word_count": 279,
            "read_time": "2 min read",
            "Title": "Discovery Hub with Cloud Scale Analytics",
            "MetaDescription": "Build a modern data estate that is ready for cloud scale analytics with a step-by-step flowchart from Microsoft Azure.",
            "category": [
                "analytics",
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/cloud-scale-analytics-with-discovery-hub.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\cloud-scale-analytics-with-discovery-hub.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/storage/data-lake-storage\">Azure Data Lake Storage</a>: Massively scalable, secure data lake functionality built on Azure Blob Storage</p>",
                "<p><a href=\"https://azure.microsoft.com/services/databricks\">Azure Databricks</a>: Fast, easy, and collaborative Apache Spark-based analytics platform</p>",
                "<p><a href=\"https://azure.microsoft.com/services/synapse-analytics\">Azure Synapse Analytics</a>: Limitless analytics service with unmatched time to insight (formerly SQL Data Warehouse)</p>",
                "<p><a href=\"https://azure.microsoft.com/services/analysis-services\">Azure Analysis Services</a>: Enterprise-grade analytics engine as a service</p>",
                "<p><a href=\"https://azure.microsoft.com/services/power-bi-embedded\">Power BI Embedded</a>: Embed fully interactive, stunning data visualizations in your applications</p>"
            ],
            "Summary": "<p>Use Discovery Hub to define a data estate using a graphical user interface, with definitions stored in a metadata repository. Code for building the data estate is generated automatically while remaining fully customizable. The resulting modern data warehouse is ready to support cloud scale analytics and AI.</p>",
            "Flow": {
                "FlowStep_A": "Combine all your structured and semi-structured data in Azure Data Lake Storage using Discovery Hub's data engineering pipeline with hundreds of native data connectors.",
                "FlowStep_B": "Clean and transform data using the powerful analytics and computational ability of Azure Databricks.",
                "FlowStep_C": "Move cleansed and transformed data to Azure Synapse Analytics, creating one hub for all your data. Take advantage of native connectors between Azure Databricks (PolyBase) and Azure Synapse Analytics to access and move data at scale.",
                "FlowStep_D": "Build operational reports and analytical dashboards on top of SQL Database to derive insights from the data and use Azure Analysis Services to serve the data.",
                "FlowStep_E": "Run ad-hoc queries directly on data within Azure Databricks."
            },
            "name": "cloud-scale-analytics-with-discovery-hub",
            "popularity": 156,
            "topic": "Analytics"
        },
        {
            "tags": [
                "all-items",
                "azcat-ai",
                "example-code",
                "github",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/ai/training-deep-learning.md",
            "http_url": "/azure/architecture/reference-architectures/ai/training-deep-learning",
            "word_count": 1756,
            "read_time": "7 min read",
            "Title": "Distributed training of deep learning models on Azure",
            "MetaDescription": "This reference architecture shows how to conduct distributed training of deep learning models across clusters of GPU-enabled VMs using Azure Machine Learning.",
            "category": [
                "ai-machine-learning",
                "compute",
                "media"
            ],
            "image": "/azure/architecture/reference-architectures/ai/_images/distributed_dl_architecture.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\ai\\_images\\distributed_dl_architecture.png",
            "publish_date": "6/05/2019",
            "Summary": "<p>This reference architecture shows how to conduct distributed training of deep learning models across clusters of GPU-enabled VMs. The scenario is image classification, but the solution can be generalized for other deep learning scenarios such as segmentation and object detection.</p>\n<p>A reference implementation for this architecture is available on <a href=\"https://github.com/microsoft/DistributedDeepLearning\">GitHub</a>.</p>\n<p><img alt=\"Architecture for distributed deep learning\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/ai/_images/distributed_dl_architecture.png\" /></p>\n<p><strong>Scenario</strong>: Classifying images is a widely applied technique in computer vision, often tackled by training a convolutional neural network (CNN). For particularly large models with large datasets, the training process can take weeks or months on a single GPU. In some situations, the models are so large that it's not possible to fit reasonable batch sizes onto the GPU. Using distributed training in these situations can shorten the training time.</p>\n<p>In this specific scenario, a <a href=\"https://arxiv.org/abs/1512.03385\">ResNet50 CNN model</a> is trained using <a href=\"https://github.com/uber/horovod\">Horovod</a> on the <a href=\"http://www.image-net.org\">Imagenet dataset</a> and on synthetic data. The reference implementation shows how to accomplish this task using TensorFlow.</p>\n<p>There are several ways to train a deep learning model in a distributed fashion, including data-parallel and model-parallel approaches based on synchronous or asynchronous updates. Currently the most common scenario is data parallel with synchronous updates. This approach is the easiest to implement and is sufficient for most use cases.</p>\n<p>In data-parallel distributed training with synchronous updates, the model is replicated across <em>n</em> hardware devices. A mini-batch of training samples is divided into <em>n</em> micro-batches. Each device performs the forward and backward passes for a micro-batch. When a device finishes the process, it shares the updates with the other devices. These values are used to calculate the updated weights of the entire mini-batch, and the weights are synchronized across the models. This scenario is covered in the <a href=\"https://github.com/microsoft/DistributedDeepLearning\">GitHub</a> repository.</p>\n<p><img alt=\"Data parallel distributed training\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/ai/_images/distributed_dl_flow.png\" /></p>\n<p>This architecture can also be used for model-parallel and asynchronous updates. In model-parallel distributed training, the model is divided across <em>n</em> hardware devices, with each device holding a part of the model. In the simplest implementation, each device may hold a layer of the network, and information is passed between devices during the forward and backwards pass. Larger neural networks can be trained this way, but at the cost of performance, since devices are constantly waiting for each other to complete either the forward or backwards pass. Some advanced techniques try to partially alleviate this issue by using synthetic gradients.</p>\n<p>The steps for training are:</p>\n<ol>\n<li>\n<p>Create scripts that will run on the cluster and train your model, then transfer them to file storage.</p>\n</li>\n<li>\n<p>Write the data to Premium Blob Storage.</p>\n</li>\n<li>\n<p>Create an Azure Machine Learning workspace. This will also create an Azure Container Registry to host your Docker Images.</p>\n</li>\n<li>\n<p>Create an Azure Machine Learning GPU Cluster.</p>\n</li>\n<li>\n<p>Submit jobs. For each job with unique dependencies, a new Docker image is built and pushed to your container registry. During execution, the appropriate Docker image runs and executes your script.</p>\n</li>\n<li>\n<p>All the results and logs will be written to Blob storage.</p>\n</li>\n</ol>",
            "sample_code": true,
            "github_url": "https://github.com/msalvaris/BatchAIHorovodBenchmark",
            "name": "training-deep-learning",
            "popularity": 161,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "acom-architecture",
                "all-items",
                "data-flow",
                "fcp",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/business-central.md",
            "http_url": "/azure/architecture/solution-ideas/articles/business-central",
            "word_count": 1023,
            "read_time": "5 min read",
            "Title": "Dynamics Business Central as a Service on Azure",
            "MetaDescription": "This example shows how to establish the production environment for Business Central in partner private Azure environment.",
            "category": [
                "compute"
            ],
            "image": "/azure/architecture/solution-ideas/media/business-central-as-a-service.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\business-central-as-a-service.png",
            "publish_date": "6/25/2020",
            "Summary": "",
            "Flow": {
                "FlowStep_A": "Customers login using web browser, device (phone or tablet) or through API to access the Dynamics 365 Business Central.",
                "FlowStep_B": "Virtual Machine as a middle-tier, provides Web Server Components and plays roles as a [NST Server](/dynamics365/business-central/dev-itpro/administration/configure-server-instance), connecting customers with databases. One Virtual Machine can be used for multiple customers and the partner just needs to provide different Business Central Server Instance with different ports numbers for each of customers. Using this model, support will be much easier as the partner needs to support only one server at a minimum. With Azure Load balancer, this system will scale applications and create highly available services.",
                "FlowStep_C": "The application and business data reside in separate databases, both using Azure SQL for its databases. App database will be in one single database (S0 will be enough to run application database). The partner maintains the application centrally without affecting the various tenants that use the application. Tenant databases will be placed in an Azure Elastic Database Pool (for starters, S4 pool with 200 DTU\u2019s will be enough). Each tenant database contains the business data for one or more specific companies from one client and does not contain all of the application metadata. If customers require more power, it is easy to change service tier on Azure SQL and Elastic Database Pool.",
                "FlowStep_D": "To provide better sustainability, all resources will be in one resource Group. All external services (Azure Machine Learning, Power Apps, Power Automate and Power BI) will communicate directly with the NST Server through exposed API\u2019s and OData web services."
            },
            "name": "business-central",
            "popularity": 0,
            "topic": "Compute"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "data-flow",
                "ecommerce",
                "example-code",
                "example-workload",
                "fasttrack",
                "github",
                "pricing-calculator",
                "pricing-guidance",
                "web-apps"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/apps/ecommerce-scenario.yml",
            "http_url": "/azure/architecture/example-scenario/apps/ecommerce-scenario",
            "word_count": 1468,
            "read_time": "6 min read",
            "Title": "E-commerce front end",
            "MetaDescription": "This example scenario implements an e-commerce front end using Azure platform as a service tools, which allow you to handle increases in transactions.",
            "category": [
                "web"
            ],
            "image": "/azure/architecture/example-scenario/apps/media/architecture-ecommerce-scenario.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\apps\\media\\architecture-ecommerce-scenario.png",
            "publish_date": "7/13/2018",
            "pricing_calculator": "https://azure.com/e/90fbb6a661a04888a57322985f9b34ac",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "components": [
                "<p><a href=\"https://www.microsoft.com/azure/cdn/cdn-overview\">Azure CDN</a> delivers static, cached content from locations close to users to reduce latency.</p>",
                "<p><a href=\"https://www.microsoft.com/azure/traffic-manager/traffic-manager-overview\">Azure Traffic Manager</a> controls the distribution of user traffic for service endpoints in different Azure regions.</p>",
                "<p><a href=\"https://www.microsoft.com/azure/app-service/app-service-web-overview\">App Services - Web Apps</a> hosts web applications allowing autoscale and high availability without having to manage infrastructure.</p>",
                "<p><a href=\"https://www.microsoft.com/azure/active-directory-b2c/active-directory-b2c-overview\">Azure Active Directory - B2C</a> is an identity management service that enables customization and control over how customers sign up, sign in, and manage their profiles in an application.</p>",
                "<p><a href=\"https://www.microsoft.com/azure/storage/queues/storage-queues-introduction\">Storage Queues</a> stores large numbers of queue messages that can be accessed by an application.</p>",
                "<p><a href=\"https://www.microsoft.com/azure/azure-functions/functions-overview\">Functions</a> are serverless compute options that allow applications to run on-demand without having to manage infrastructure.</p>",
                "<p><a href=\"https://www.microsoft.com/azure/cognitive-services/welcome\">Cognitive Services - Sentiment Analysis</a> uses machine learning APIs and enables developers to easily add intelligent features \u2013 such as emotion and video detection; facial, speech, and vision recognition; and speech and language understanding \u2013 into applications.</p>",
                "<p><a href=\"https://www.microsoft.com/azure/search/search-what-is-azure-search\">Azure Search</a> is a search-as-a-service cloud solution that provides a rich search experience over private, heterogeneous content in web, mobile, and enterprise applications.</p>",
                "<p><a href=\"https://www.microsoft.com/azure/storage/blobs/storage-blobs-introduction\">Storage Blobs</a> are optimized to store large amounts of unstructured data, such as text or binary data.</p>",
                "<p><a href=\"https://www.microsoft.com/azure/redis-cache/cache-overview\">Azure Cache for Redis</a> improves the performance and scalability of systems that rely heavily on back-end data stores by temporarily copying frequently accessed data to fast storage located close to the application.</p>",
                "<p><a href=\"https://www.microsoft.com/azure/sql-database/sql-database-technical-overview\">SQL Database</a> is a general-purpose relational database managed service in Microsoft Azure that supports structures such as relational data, JSON, spatial, and XML.</p>",
                "<p><a href=\"https://www.microsoft.com/azure/application-insights/app-insights-overview\">Application Insights</a> is designed to help you continuously improve performance and usability by automatically detecting performance anomalies through built-in analytics tools to help understand what users do with an app.</p>"
            ],
            "Flow": {
                "FlowStep_A": "Azure Traffic Manager routes a user's request to the e-commerce site hosted in Azure App Service.",
                "FlowStep_B": "Azure CDN serves static images and content to the user.",
                "FlowStep_C": "User signs in to the application through an Azure Active Directory B2C tenant.",
                "FlowStep_D": "User searches for concerts using Azure Search.",
                "FlowStep_E": "Web site pulls concert details from Azure SQL Database.",
                "FlowStep_F": "Web site refers to purchased ticket images in Blob Storage.",
                "FlowStep_G": "Database query results are cached in Azure Cache for Redis to improve performance.",
                "FlowStep_H": "User submits ticket orders and concert reviews, which are placed in the queue.",
                "FlowStep_I": "Azure Functions processes order payment and concert reviews.",
                "FlowStep_J": "Cognitive Services provides an analysis of the concert review to determine the sentiment (positive or negative).",
                "FlowStep_K": "Application Insights provides performance metrics for monitoring the health of the web application."
            },
            "sample_code": true,
            "github_url": "https://github.com/Azure/fta-customerfacingapps/tree/master/ecommerce/articles",
            "name": "ecommerce-scenario",
            "popularity": 186,
            "topic": "Web"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-ecommerce-website-running-in-secured-ase-'",
                "acom-architecture",
                "all-items",
                "app-service-environment",
                "data-flow",
                "e-commerce-security-solutions",
                "e-commerce-site-security",
                "interactive-diagram",
                "security-for-ecommerce-websites",
                "solution-idea",
                "web-apps"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/ecommerce-website-running-in-secured-ase.md",
            "http_url": "/azure/architecture/solution-ideas/articles/ecommerce-website-running-in-secured-ase",
            "word_count": 360,
            "read_time": "2 min read",
            "Title": "E-commerce website running in secured App Service Environment",
            "MetaDescription": "Secure your e-commerce website's sensitive user and payment data using the Microsoft Azure App Service Environment.",
            "category": [
                "web"
            ],
            "image": "/azure/architecture/solution-ideas/media/ecommerce-website-running-in-secured-ase.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\ecommerce-website-running-in-secured-ase.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/app-service\">App Service</a>: Quickly create powerful cloud apps for web and mobile</p>",
                "<p><a href=\"https://azure.microsoft.com/services/app-service/web\">Web Apps</a>: An App Service Web App runs in a single region, accessible to web and mobile browsers</p>",
                "<p><a href=\"https://azure.microsoft.com/services/sql-database\">Azure SQL Database</a>: Managed, intelligent SQL in the cloud</p>",
                "<p><a href=\"https://azure.microsoft.com/services/app-service/api\">API Apps</a>: Publish APIs to external, partner, and employee developers securely and at scale.</p>",
                "<p>Application Insights: Detect, triage, and diagnose issues in your web apps and services</p>",
                "<p><a href=\"https://azure.microsoft.com/services/application-gateway\">Application Gateway</a>: Build secure, scalable, and highly available web front ends in Azure</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cache\">Azure Cache for Redis</a>: Power applications with high-throughput, low-latency data access</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cdn\">Content Delivery Network</a>: Ensure secure, reliable content delivery with broad global reach</p>",
                "<p><a href=\"https://azure.microsoft.com/services/active-directory\">Azure Active Directory</a>: Synchronize on-premises directories and enable single sign-on</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage/blobs\">Blob Storage</a>: Azure Blob storage is a Massively scalable object storage for any type of unstructured data-images, videos, audio, documents, and more-easily and cost-effectively.</p>"
            ],
            "Flow": {
                "FlowStep_A": "Customer accesses the public website in browser.",
                "FlowStep_B": "Browser pulls static resources and product images from Azure Content Delivery Network.",
                "FlowStep_C": "Content Delivery Network pulls product images from blob storage.",
                "FlowStep_D": "Customer searches for products.",
                "FlowStep_E": "Public website pulls product catalog from product database.",
                "FlowStep_F": "Page output is cached in the Azure Cache for Redis.",
                "FlowStep_G": "Customer creates new orders.",
                "FlowStep_H": "Public website invokes orders web service.",
                "FlowStep_I": "Orders web service saves/loads orders from Azure SQL Database.",
                "FlowStep_J": "Employee accesses the admin website in browser.",
                "FlowStep_K": "Employee authenticates against Azure Active Directory (Azure AD).",
                "FlowStep_L": "Employee searches orders.",
                "FlowStep_M": "Admin website invokes orders web service."
            },
            "name": "ecommerce-website-running-in-secured-ase",
            "popularity": 147,
            "topic": "Web"
        },
        {
            "tags": [
                "acom-architecture",
                "all-items",
                "data-flow",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/aks-demand-spikes.md",
            "http_url": "/azure/architecture/solution-ideas/articles/aks-demand-spikes",
            "word_count": 336,
            "read_time": "2 min read",
            "Title": "Elastic demand handling with AKS",
            "MetaDescription": "Achieve fast and reliable service quality during seasonal and other high-traffic demand periods",
            "category": [
                "containers",
                "web"
            ],
            "image": "/azure/architecture/solution-ideas/media/aks-demand-spikes.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\aks-demand-spikes.png",
            "publish_date": "4/17/2020",
            "Summary": "<p>This example shows how to achieve fast and reliable service quality during seasonal and other high-traffic demand periods. This approach can be used to manage:</p>\n<ul>\n<li>Elastic scaling handles traffic and sales bursts without managing infrastructures</li>\n<li>Low-latency data access from anywhere in the world for fast, robust user experiences</li>\n<li>High availability across multiple data centers</li>\n</ul>",
            "Flow": {
                "FlowStep_A": "Azure Traffic Manager routes incoming requests to Azure API management Gateway",
                "FlowStep_B": "API Gateway ensures requests meet security and other policies, and then routes them to service running in Azure Kubernetes Service",
                "FlowStep_C": "Services use Azure Cosmos DB, Azure CDN, and Azure Functions to achieve low-latency data access data as needed from anywhere in the world",
                "FlowStep_D": "When demand spikes past current capacity, AKS uses virtual nodes to dynamically scale up the service"
            },
            "name": "aks-demand-spikes",
            "popularity": 0,
            "topic": "Containers"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-energy-supply-optimization-'",
                "acom-architecture",
                "ai-gallery",
                "all-items",
                "artificial-intelligence",
                "azure",
                "data-flow",
                "example-code",
                "github",
                "solution-architectures",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/energy-supply-optimization.md",
            "http_url": "/azure/architecture/solution-ideas/articles/energy-supply-optimization",
            "word_count": 577,
            "read_time": "3 min read",
            "Title": "Energy Supply Optimization",
            "MetaDescription": "This solution provides an Azure-based smart solution, applying external open-source tools, to determine the optimal energy unit commitments from various energy resources for an energy grid.",
            "category": [
                "ai-machine-learning",
                "integration"
            ],
            "image": "/azure/architecture/solution-ideas/media/energy-supply-optimization.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\energy-supply-optimization.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>In an energy grid, energy consumers are engaged with various types of energy supplying, trading, and storage components such as substations, batteries, windfarms and solar panels, micro-turbines, as well as demand response bids, to meet their respective demands and minimize the cost of energy commitment. To do so, the grid operator must determine how much energy each type of the resources should commit over a time frame, given the prices of soliciting different types of resources and the capacities and the physical characteristics of them.</p>\n<p>This solution is built upon Cortana Intelligence Suite and external open-source tools, and it computes the optimal energy unit commitments from various types of energy resources. This solution demonstrates the ability of Cortana Intelligence Suite to accommodating external tools, to solve parallelized numerical optimization problems over an Azure Batch of Azure Virtual Machines.</p>",
            "Flow": {
                "FlowStep_A": "The sample data is streamed by newly deployed Azure Web Jobs. The web job uses resource-related data from Azure SQL to generate the simulated data.",
                "FlowStep_B": "The data simulator feeds this simulated data into the Azure Storage and writes message in Storage Queue, that will be used in the rest of the solution flow.",
                "FlowStep_C": "Another Web Job monitors the storage queue and initiate an Azure Batch job once message in the queue is available.",
                "FlowStep_D": "The Azure Batch service together with Data Science Virtual Machines is used to optimize the energy supply from a particular resource type given the inputs received.",
                "FlowStep_E": "Azure SQL Database is used to store the optimization results received from the Azure Batch service. These results are then consumed in the Power BI dashboard."
            },
            "sample_code": true,
            "github_url": "https://github.com/Azure/cortana-intelligence-energy-supply-optimization",
            "name": "energy-supply-optimization",
            "popularity": 15,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-enterprise-productivity-chatbot-'",
                "acom-architecture",
                "all-items",
                "bot-service",
                "data-flow",
                "interactive-diagram",
                "luis",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/enterprise-productivity-chatbot.md",
            "http_url": "/azure/architecture/solution-ideas/articles/enterprise-productivity-chatbot",
            "word_count": 137,
            "read_time": "1 min read",
            "Title": "Enterprise Productivity Chatbot",
            "MetaDescription": "Azure Bot Service can be easily combined with Language Understanding to build powerful enterprise productivity bots, allowing organizations to streamline common work activities by integrating external systems, such as Microsoft 365 calendar, customer cases stored in Dynamics CRM and much more.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/enterprise-productivity-chatbot.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\enterprise-productivity-chatbot.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Azure Bot Service can be easily combined with Language Understanding to build powerful enterprise productivity bots, allowing organizations to streamline common work activities by integrating external systems, such as Microsoft 365 calendar, customer cases stored in Dynamics CRM and much more.</p>",
            "Flow": {
                "FlowStep_A": "Employee access Enterprise Productivity Bot",
                "FlowStep_B": "Azure Active Directory validates the employee's identity",
                "FlowStep_C": "The Bot is able to query the employee's Microsoft 365 calendar via the Azure Graph",
                "FlowStep_D": "Using data gathered from the calendar, the Bot access case information in Dynamics CRM",
                "FlowStep_E": "Information is returned to the employee who can filter down the data without leaving the Bot"
            },
            "name": "enterprise-productivity-chatbot",
            "popularity": 55,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "github",
                "pricing-guidance",
                "reference-architecture",
                "seodec18"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/data/enterprise-bi-synapse.md",
            "http_url": "/azure/architecture/reference-architectures/data/enterprise-bi-synapse",
            "word_count": 3089,
            "read_time": "12 min read",
            "Title": "Enterprise business intelligence",
            "MetaDescription": "See an extract, load, and transform pipeline that moves data from an on-premises SQL Server database into Azure Synapse and transforms the data for analysis.",
            "category": [
                "integration",
                "analytics",
                "databases"
            ],
            "image": "/azure/architecture/reference-architectures/data/images/enterprise-bi-synapse.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\data\\images\\enterprise-bi-synapse.png",
            "publish_date": "11/20/2019",
            "pricing_guidance": "pricing-for-azure-analysis-services-depends-on-the-tier.-the-reference-implementation-of-this-architecture-uses-the-**developer**-tier,-which-is-recommended-for-evaluation,-development,-and-test-scenarios.-other-tiers-include,-the-**basic**-tier,-which-is-recommended-for-small-production-environment;-the-**standard**-tier-for-mission-critical-production-applications.-for-more-information,-see-[the-right-tier-when-you-need-it](-azure-analysis-services-analysis-services-overview#the-right-tier-when-you-need-it).",
            "Summary": "<p>This reference architecture implements an <a extract-load-and-transform-elt\">extract, load, and transform (ELT)</a> pipeline that moves data from an on-premises SQL Server database into Azure Synapse and transforms the data for analysis.</p>\n<p><img alt=\"GitHub logo\" src=\"https://learn.microsoft.com/azure/architecture/_images/github.png\" /> A reference implementation for this architecture is available on <a href=\"https://github.com/mspnp/azure-sqldw-enterprise-bi\">GitHub</a>.</p>\n<p><img alt=\"Architecture diagram for Enterprise BI in Azure with Azure Synapse\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/data/images/enterprise-bi-synapse.png\" /></p>\n<p><strong>Scenario</strong>: An organization has a large OLTP data set stored in a SQL Server database on premises. The organization wants to use Azure Synapse to perform analysis using Power BI.</p>\n<p>This reference architecture is designed for one-time or on-demand jobs. If you need to move data on a continuing basis (hourly or daily), we recommend using Azure Data Factory to define an automated workflow. For a reference architecture that uses Data Factory, see <a >Automated enterprise BI with Azure Synapse and Azure Data Factory</a>.</p>",
            "sample_code": true,
            "github_url": "https://github.com/mspnp/template-building-blocks/wiki",
            "name": "enterprise-bi-synapse",
            "popularity": 230,
            "topic": "Integration"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "fcp",
                "github",
                "solution-idea",
                "visio-diagram"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/enterprise-chatbot-disaster-recovery.md",
            "http_url": "/azure/architecture/solution-ideas/articles/enterprise-chatbot-disaster-recovery",
            "word_count": 566,
            "read_time": "3 min read",
            "Title": "Enterprise chatbot disaster recovery",
            "MetaDescription": "Learn how to set up disaster recovery and high availability for Azure services in an enterprise-grade conversational bot.",
            "category": [
                "ai-machine-learning",
                "management-and-governance"
            ],
            "image": "/azure/architecture/solution-ideas/media/chatbot-with-failover-two-regions.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\chatbot-with-failover-two-regions.png",
            "publish_date": "6/22/2020",
            "Summary": "<p>To set up disaster recovery for an enterprise-grade <em>conversational bot (chatbot)</em>, first review the service level agreement (SLA) that cover the <em>Recovery Point Objective (RPO)</em> and <em>Recovery Time Objective (RTO)</em> for the chatbot. Implement the disaster recovery patterns in this article to build highly available and disaster resistant chatbot solutions to meet the SLA.</p>\n<p>For a description of the core components of a typical enterprise-grade chatbot solution in Azure, see <a >Enterprise-grade conversational bot</a>.</p>",
            "sample_code": true,
            "github_url": "https://github.com/pchoudhari/QnAMakerBackupRestore",
            "visio_diagram": "https://arch-center.azureedge.net/Bot_DR.vsdx",
            "name": "enterprise-chatbot-disaster-recovery",
            "popularity": 0,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "all-items",
                "azurecli",
                "example-code",
                "github",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/enterprise-integration/ase-standard-deployment.md",
            "http_url": "/azure/architecture/reference-architectures/enterprise-integration/ase-standard-deployment",
            "word_count": 4396,
            "read_time": "18 min read",
            "Title": "Enterprise deployment using App Services Environment",
            "MetaDescription": "Recommended architecture for deploying an enterprise application using App Services Environment.",
            "category": [
                "management-and-governance",
                "featured"
            ],
            "image": "/azure/architecture/reference-architectures/enterprise-integration/_images/standard-ase-deployment.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\enterprise-integration\\_images\\standard-ase-deployment.png",
            "publish_date": "5/08/2020",
            "Summary": "<p><a href=\"https://learn.microsoft.com/azure/app-service/overview\">Azure App Service</a> is a PaaS service used to host a variety of apps on Azure: web apps, API apps, functions, and mobile apps. <a href=\"https://learn.microsoft.com/azure/app-service/environment/intro\">App Service Environment or ASE</a> allows enterprises to deploy their App Service apps in a subnet in their own Azure Virtual Network, providing an isolated, highly scalable, and dedicated environment for their cloud workloads.</p>\n<p>This reference architecture demonstrates a common enterprise workload using ASE, and best practices to tighten security of this workload.</p>\n<p><img alt=\"GitHub logo\" src=\"https://learn.microsoft.com/azure/architecture/_images/github.png\" /> A reference implementation for this architecture is available on <a href=\"https://github.com/mspnp/app-service-environments-ILB-deployments\">GitHub</a>.</p>\n<p><img alt=\"Reference architecture for standard ASE deployment\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/enterprise-integration/_images/standard-ase-deployment.png\" /></p>",
            "sample_code": true,
            "github_url": "https://github.com/mspnp/app-service-environments-ILB-deployments",
            "code_languages": [
                "azurecli"
            ],
            "name": "ase-standard-deployment",
            "popularity": 0,
            "topic": "Management and Governance"
        },
        {
            "tags": [
                "all-items",
                "integration-services",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/enterprise-integration/queues-events.yml",
            "http_url": "/azure/architecture/reference-architectures/enterprise-integration/queues-events",
            "word_count": 1062,
            "read_time": "5 min read",
            "Title": "Enterprise integration using queues and events",
            "MetaDescription": "Recommended architecture for implementing an enterprise integration pattern with Azure Logic Apps, Azure API Management, Azure Service Bus, and Azure Event Grid.",
            "category": [
                "integration",
                "developer-tools"
            ],
            "image": "/azure/architecture/reference-architectures/enterprise-integration/_images/enterprise-integration-queues-events.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\enterprise-integration\\_images\\enterprise-integration-queues-events.png",
            "publish_date": "12/03/2018",
            "Summary": "<p>This reference architecture integrates enterprise backend systems, using message queues and events to decouple services for greater scalability and reliability. The backend systems may include software as a service (SaaS) systems, Azure services, and existing web services in your enterprise.</p>\n<p><img alt=\"Reference architecture for enterprise integration using queues and events\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/enterprise-integration/_images/enterprise-integration-queues-events.png\" /></p>",
            "name": "queues-events",
            "popularity": 220,
            "topic": "Integration"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-disaster-recovery-enterprise-scale-dr-'",
                "acom-architecture",
                "all-items",
                "bcdr",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/disaster-recovery-enterprise-scale-dr.md",
            "http_url": "/azure/architecture/solution-ideas/articles/disaster-recovery-enterprise-scale-dr",
            "word_count": 257,
            "read_time": "2 min read",
            "Title": "Enterprise-scale disaster recovery",
            "MetaDescription": "A large enterprise architecture for SharePoint, Dynamics CRM, and Linux web servers hosted on an on-premises datacenter with failover to Azure infrastructure.",
            "category": [
                "management-and-governance",
                "hybrid"
            ],
            "image": "/azure/architecture/solution-ideas/media/disaster-recovery-enterprise-scale-dr.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\disaster-recovery-enterprise-scale-dr.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p>DNS traffic is routed via <a href=\"https://azure.microsoft.com/services/traffic-manager\">Traffic Manager</a> which can easily move traffic from one site to another based on policies defined by your organization.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/site-recovery\">Azure Site Recovery</a> orchestrates the replication of machines and manages the configuration of the failback procedures.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage/blobs\">Blob storage</a> stores the replica images of all machines that are protected by Site Recovery.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/active-directory\">Azure Active Directory</a> is the replica of the on-premises <a href=\"https://azure.microsoft.com/services/active-directory\">Azure Active Directory</a> services allowing cloud applications to be authenticated and authorized by your company.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/vpn-gateway\">VPN Gateway</a>: The VPN gateway maintains the communication between the on-premises network and the cloud network securely and privately.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/virtual-network\">Virtual Network</a>: The virtual network is where the failover site will be created when a disaster occurs.</p>"
            ],
            "name": "disaster-recovery-enterprise-scale-dr",
            "popularity": 188,
            "topic": "Management and Governance",
            "hybrid-topic": "Management"
        },
        {
            "tags": [
                "all-items",
                "data-flow",
                "example-code",
                "github",
                "json",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/serverless/cloud-automation.md",
            "http_url": "/azure/architecture/reference-architectures/serverless/cloud-automation",
            "word_count": 2975,
            "read_time": "12 min read",
            "Title": "Event-based cloud automation",
            "MetaDescription": "Recommended architecture for implementing cloud automation using serverless technologies.",
            "category": [
                "developer-tools"
            ],
            "image": "/azure/architecture/reference-architectures/serverless/_images/cloud-automation.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\serverless\\_images\\cloud-automation.png",
            "publish_date": "1/14/2020",
            "Flow": {
                "FlowStep_A": "[Cost center tagging](https://github.com/mspnp/serverless-automation/blob/main/src/automation/cost-center/deployment.md): This implementation tracks the cost centers of each Azure resource. The [Azure Policy](/azure/governance/policy/) service [tags all new resources](/azure/azure-resource-manager/resource-group-using-tags) in a group with a default cost center ID. The Event Grid monitors resource creation events, and then calls an [Azure function](/azure/azure-functions/). The function interacts with Azure Active Directory, and validates the cost center ID for the new resource. If different, it updates the tag and sends out an email to the resource owner. The REST queries for Azure Active Directory are mocked out for simplicity. Azure AD can also be integrated using the [Azure AD PowerShell module](/powershell/module/azuread/?view=azureadps-2.0)."
            },
            "sample_code": true,
            "github_url": "https://github.com/mspnp/serverless-automation/blob/main/src/automation/cost-center/deployment.md",
            "code_languages": [
                "json"
            ],
            "name": "cloud-automation",
            "popularity": 208,
            "topic": "Developer Tools"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "fcp",
                "github",
                "is-deployable",
                "networking",
                "powershell",
                "reference-architecture",
                "seodec18",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/hybrid-networking/expressroute.yml",
            "http_url": "/azure/architecture/reference-architectures/hybrid-networking/expressroute",
            "word_count": 3046,
            "read_time": "13 min read",
            "Title": "Extend an on-premises network using ExpressRoute",
            "MetaDescription": "Implement a secure site-to-site network architecture that spans an Azure virtual network and an on-premises network connected using Azure ExpressRoute.",
            "category": [
                "hybrid",
                "networking"
            ],
            "image": "/azure/architecture/reference-architectures/hybrid-networking/images/expressroute.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\hybrid-networking\\images\\expressroute.png",
            "publish_date": "7/23/2019",
            "sample_code": true,
            "github_url": "https://github.com/mspnp/template-building-blocks/wiki",
            "visio_diagram": "https://arch-center.azureedge.net/hybrid-network-architectures.vsdx",
            "code_languages": [
                "powershell"
            ],
            "name": "expressroute",
            "popularity": 219,
            "topic": "Networking",
            "hybrid-topic": "Networking"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "github",
                "networking",
                "reference-architecture",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/hybrid-networking/vpn.yml",
            "http_url": "/azure/architecture/reference-architectures/hybrid-networking/vpn",
            "word_count": 2866,
            "read_time": "11 min read",
            "Title": "Extend an on-premises network using VPN",
            "MetaDescription": "A secure site-to-site network architecture that spans an Azure virtual network and an on-premises network connected using a VPN.",
            "category": [
                "hybrid",
                "networking"
            ],
            "image": "/azure/architecture/reference-architectures/hybrid-networking/images/vpn.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\hybrid-networking\\images\\vpn.png",
            "publish_date": "1/24/2020",
            "sample_code": true,
            "github_url": "https://github.com/mspnp/samples/blob/master/solutions/secure-hybrid-network/README.md",
            "visio_diagram": "https://arch-center.azureedge.net/hybrid-network-architectures.vsdx",
            "name": "vpn",
            "popularity": 227,
            "topic": "Networking",
            "hybrid-topic": "Networking"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "github",
                "identity",
                "powershell",
                "reference-architecture",
                "seodec18",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/identity/adfs.yml",
            "http_url": "/azure/architecture/reference-architectures/identity/adfs",
            "word_count": 3313,
            "read_time": "13 min read",
            "Title": "Extend on-premises AD FS to Azure",
            "MetaDescription": "Implement a secure hybrid network architecture with Active Directory Federation Service authorization in Azure.",
            "category": [
                "identity",
                "hybrid"
            ],
            "image": "/azure/architecture/reference-architectures/identity/images/adfs.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\identity\\images\\adfs.png",
            "publish_date": "12/18/2018",
            "sample_code": true,
            "github_url": "https://github.com/mspnp/identity-reference-architectures",
            "visio_diagram": "https://arch-center.azureedge.net/identity-architectures.vsdx",
            "code_languages": [
                "powershell"
            ],
            "name": "adfs",
            "popularity": 217,
            "topic": "Identity",
            "hybrid-topic": "Identity"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-extend-your-on-premises-big-data-investments-with-hdinsight-'",
                "acom-architecture",
                "all-items",
                "data",
                "expressroute",
                "hdinsight",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/extend-your-on-premises-big-data-investments-with-hdinsight.md",
            "http_url": "/azure/architecture/solution-ideas/articles/extend-your-on-premises-big-data-investments-with-hdinsight",
            "word_count": 41,
            "read_time": "1 min read",
            "Title": "Extend your on-premises big data investments with HDInsight",
            "MetaDescription": "Extend your on-premises big data investments to the cloud and transform your business using the advanced analytics capabilities of HDInsight.",
            "category": [
                "analytics",
                "hybrid"
            ],
            "image": "/azure/architecture/solution-ideas/media/extend-your-on-premises-big-data-investments-with-hdinsight.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\extend-your-on-premises-big-data-investments-with-hdinsight.png",
            "publish_date": "12/16/2019",
            "name": "extend-your-on-premises-big-data-investments-with-hdinsight",
            "popularity": 90,
            "topic": "Analytics",
            "hybrid-topic": "Data"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-extract-transform-and-load-using-hdinsight-'",
                "acom-architecture",
                "all-items",
                "data",
                "data-factory",
                "data-lake-storage",
                "hdinsight",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/extract-transform-and-load-using-hdinsight.md",
            "http_url": "/azure/architecture/solution-ideas/articles/extract-transform-and-load-using-hdinsight",
            "word_count": 30,
            "read_time": "1 min read",
            "Title": "Extract, transform, and load (ETL) using HDInsight",
            "MetaDescription": "Extract, transform, and load your big data clusters on demand with Hadoop MapReduce and Apache Spark.",
            "category": [
                "analytics",
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/extract-transform-and-load-using-hdinsight.svg",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\extract-transform-and-load-using-hdinsight.svg",
            "publish_date": "12/16/2019",
            "name": "extract-transform-and-load-using-hdinsight",
            "popularity": 123,
            "topic": "Analytics"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-faq-chatbot-with-data-champion-model-'",
                "acom-architecture",
                "all-items",
                "chatbot",
                "data-flow",
                "faq",
                "faq-chatbot",
                "interactive-diagram",
                "qna",
                "qna-maker",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/faq-chatbot-with-data-champion-model.md",
            "http_url": "/azure/architecture/solution-ideas/articles/faq-chatbot-with-data-champion-model",
            "word_count": 148,
            "read_time": "1 min read",
            "Title": "FAQ Chatbot with data champion model",
            "MetaDescription": "The QnA Maker tool makes it super easy for the content owners to maintain their knowledge base of QnAs. Combined with Bot Service and LUIS, it's easy to setup an FAQ chatbot which responds from different knowledge bases depending on the intent of the query.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/faq-chatbot-with-data-champion-model.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\faq-chatbot-with-data-champion-model.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>The QnA Maker tool makes it easy for the content owners to maintain their knowledge base of Questions and Answers. Combined with Bot Service and Language Understanding, it becomes simple to setup a FAQ chatbot which responds from different knowledge bases depending on the intent of the query.</p>",
            "Flow": {
                "FlowStep_A": "Employee access FAQ Bot",
                "FlowStep_B": "Azure Active Director validates the employee's identity",
                "FlowStep_C": "Query is send to a LUIS model to get the intent of the query",
                "FlowStep_D": "Based in the intent, the query is redirected to the appropriate Knowledge base",
                "FlowStep_E": "QnA Maker gives the best match to the incoming query",
                "FlowStep_F": "The result is shown to the employee"
            },
            "name": "faq-chatbot-with-data-champion-model",
            "popularity": 25,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-facilities-management-powered-by-mixed-reality-and-iot-'",
                "acom-architecture",
                "all-items",
                "azure-active-directory",
                "azure-digital-twins",
                "azure-spatial-anchors",
                "cosmos-db",
                "data-flow",
                "event-hubs",
                "functions",
                "interactive-diagram",
                "iot",
                "microsoft-hololens",
                "solution-idea",
                "web-service"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/facilities-management-powered-by-mixed-reality-and-iot.md",
            "http_url": "/azure/architecture/solution-ideas/articles/facilities-management-powered-by-mixed-reality-and-iot",
            "word_count": 458,
            "read_time": "2 min read",
            "Title": "Facilities management powered by mixed reality and IoT",
            "MetaDescription": "Improve uptime and operations in hospitality, manufacturing, retail, and more with mixed reality and IoT. This scenario shows how you can visualize a virtual replica of your physical space with real-time data in the context of your environment. It is built on Azure Spatial Anchors and Azure Digital Twins. After reviewing this solution architecture, dive right in and explore our reference sample.",
            "category": [
                "mixed-reality",
                "iot"
            ],
            "image": "/azure/architecture/solution-ideas/media/facilities-management-powered-by-mixed-reality-and-iot.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\facilities-management-powered-by-mixed-reality-and-iot.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/spatial-anchors\">Spatial Anchors</a>: Create multi-user, spatially aware mixed reality experiences</p>",
                "<p><a href=\"https://azure.microsoft.com/services/active-directory\">Azure Active Directory</a>: Synchronize on-premises directories and enable single sign-on</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cosmos-db\">Azure Cosmos DB</a>: Globally distributed, multi-model database for any scale</p>",
                "<p><a href=\"https://azure.microsoft.com/services/app-service\">App Service</a>: Quickly create powerful cloud apps for web and mobile</p>",
                "<p><a href=\"https://azure.microsoft.com/services/event-hubs\">Event Hubs</a>: Receive telemetry from millions of devices</p>",
                "<p><a href=\"https://azure.microsoft.com/services/digital-twins\">Azure Digital Twins</a>: Build next-generation IoT spatial intelligence solutions</p>"
            ],
            "Summary": "<p>Improve uptime and operations in hospitality, manufacturing, retail, and more with mixed reality and IoT. This scenario shows how you can visualize a virtual replica of your physical space with real-time data in the context of your environment. It is built on <a href=\"https://azure.microsoft.com/services/spatial-anchors\">Azure Spatial Anchors</a> and <a href=\"https://azure.microsoft.com/services/digital-twins\">Azure Digital Twins</a>.</p>",
            "Flow": {
                "FlowStep_A": "The client authenticates to the facilities management web service and specifies the name of the space where it's located in the Azure Digital Twins object model.",
                "FlowStep_B": "The client's web service authenticates itself to Azure Active Directory.",
                "FlowStep_C": "The Azure AD token is then sent to the Azure Spatial Anchors service to retrieve an access token for the client to later use.",
                "FlowStep_D": "Your app service retrieves information about the IoT sensors present in the area specified by the client and returns IoT sensor IDs, as well as the anchor IDs they correspond to in Azure Spatial Anchors.",
                "FlowStep_E": "The Azure Spatial Anchors authorization token is returned to the client alongside the anchor IDs of the IoT sensors and additional metadata required by the client application.",
                "FlowStep_F": "The client application completes a visual scan of the environment and retrieves its position in the area. Using the nearby API of Azure Spatial Anchors, it retrieves the position of all nearby anchors.",
                "FlowStep_G": "The client application requests IoT sensor data and controls to be displayed as holograms in the space, where the sensors are located, making it easy for the operator to detect and fix any issues. The data is fetched by the app's web service from Azure Cosmos DB, the service storing this data.",
                "FlowStep_H": "When IoT sensor data is updated, Azure Digital Twins pushes it to Event Hubs.",
                "FlowStep_I": "Azure Functions uses an Event Hubs trigger to process the change and update data in Azure Cosmos DB as needed."
            },
            "name": "facilities-management-powered-by-mixed-reality-and-iot",
            "popularity": 140,
            "topic": "Mixed Reality"
        },
        {
            "tags": [
                "all-items",
                "example-workload",
                "fcp"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/iot/field-cloud-edge-gateways.md",
            "http_url": "/azure/architecture/example-scenario/iot/field-cloud-edge-gateways",
            "word_count": 210,
            "read_time": "1 min read",
            "Title": "Field and cloud edge gateways",
            "MetaDescription": "Learn about Iot gateways, communications protocols, and provisioning.",
            "category": [
                "iot"
            ],
            "image": "/azure/architecture/example-scenario/iot/media/field-edge-gateways.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\iot\\media\\field-edge-gateways.png",
            "publish_date": "8/21/2020",
            "name": "field-cloud-edge-gateways",
            "popularity": 0,
            "topic": "Internet of Things"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-finance-management-apps-using-azure-database-for-mysql-'",
                "acom-architecture",
                "all-items",
                "analytics",
                "azure",
                "mysql",
                "solution-idea",
                "solutions",
                "use-cases"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/finance-management-apps-using-azure-database-for-mysql.md",
            "http_url": "/azure/architecture/solution-ideas/articles/finance-management-apps-using-azure-database-for-mysql",
            "word_count": 41,
            "read_time": "1 min read",
            "Title": "Finance management apps using Azure Database for MySQL",
            "MetaDescription": "Use Azure Database for MySQL to securely store critical data and provide high-value analytics and insights over aggregated data to users.",
            "category": [
                "databases",
                "analytics"
            ],
            "image": "/azure/architecture/solution-ideas/media/finance-management-apps-using-azure-database-for-mysql.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\finance-management-apps-using-azure-database-for-mysql.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Securely store critical data and provide high-value analytics and insights over aggregated data to users, using in-built security and performance.</p>",
            "name": "finance-management-apps-using-azure-database-for-mysql",
            "popularity": 103,
            "topic": "Databases"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-finance-management-apps-using-azure-database-for-postgresql-'",
                "acom-architecture",
                "all-items",
                "analytics",
                "azure",
                "postgresql",
                "solution-idea",
                "solutions",
                "use-cases"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/finance-management-apps-using-azure-database-for-postgresql.md",
            "http_url": "/azure/architecture/solution-ideas/articles/finance-management-apps-using-azure-database-for-postgresql",
            "word_count": 35,
            "read_time": "1 min read",
            "Title": "Finance management apps using Azure Database for PostgreSQL",
            "MetaDescription": "Use Azure Database for PostgreSQL to securely store critical data and provide high-value analytics and insights over aggregated data to users.",
            "category": [
                "databases",
                "analytics"
            ],
            "image": "/azure/architecture/solution-ideas/media/finance-management-apps-using-azure-database-for-postgresql.svg",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\finance-management-apps-using-azure-database-for-postgresql.svg",
            "publish_date": "12/16/2019",
            "Summary": "<p>Securely store critical data and provide high-value analytics and insights over aggregated data to users, using in-built security and performance.</p>",
            "name": "finance-management-apps-using-azure-database-for-postgresql",
            "popularity": 81,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "data-flow",
                "example-workload",
                "fcp"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/gateway/firewall-application-gateway.md",
            "http_url": "/azure/architecture/example-scenario/gateway/firewall-application-gateway",
            "word_count": 3358,
            "read_time": "14 min read",
            "Title": "Firewall and Application Gateway for virtual networks",
            "MetaDescription": "Learn about options and best practices for using Azure Firewall and Azure Application Gateway security in virtual networks.",
            "category": [
                "networking"
            ],
            "image": "/azure/architecture/example-scenario/gateway/images/decision-tree.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\gateway\\images\\decision-tree.png",
            "publish_date": "6/26/2020",
            "Summary": "<p>To secure Azure application workloads, you use protective measures like authentication and encryption in the applications themselves. You can also add security layers to the virtual machine (VM) networks that host the applications. This article describes <a href=\"https://azure.microsoft.com/services/virtual-network/\">Azure Virtual Network</a> security services like Azure Firewall and Azure Application Gateway, when to use each service, and network design options that combine both services.</p>\n<ul>\n<li>\n<p><a href=\"https://learn.microsoft.com/azure/firewall/overview\">Azure Firewall</a> is a managed next-generation firewall that offers <a href=\"https://learn.microsoft.com/azure/virtual-network/nat-overview\">network address translation (NAT)</a>. Azure Firewall bases packet filtering on Internet Protocol (IP) addresses and Transmission Control Protocol and User Datagram Protocol (TCP/UDP) ports, or on application-based HTTP(S) or SQL attributes. Azure Firewall also leverages Microsoft threat intelligence to identify malicious IP addresses. For more information, see the <a href=\"https://learn.microsoft.com/azure/firewall/\">Azure Firewall documentation</a>.</p>\n</li>\n<li>\n<p><a href=\"https://learn.microsoft.com/azure/application-gateway/overview\">Azure Application Gateway</a> is a managed web traffic load balancer and HTTP(S) full reverse proxy that can do secure socket layer (SSL) encryption and decryption. Application Gateway also uses Web Application Firewall to inspect web traffic and detect attacks at the HTTP layer. For more information, see the <a href=\"https://learn.microsoft.com/azure/application-gateway/\">Application Gateway documentation</a>.</p>\n</li>\n</ul>\n<p><a href=\"https://azure.microsoft.com/services/web-application-firewall/\">Azure Web Application Firewall (WAF)</a> on top of Azure Application Gateway is a security-hardened device with a limited attack surface that operates facing the public internet. For more information, see the <a href=\"https://learn.microsoft.com/azure/web-application-firewall/\">Web Application Firewall documentation</a>.</p>\n<p>These Azure services are complementary. One or the other may be best for your workloads, or you can integrate them for optimal protection at both the network and application layers. Use the following decision tree and the examples in this article to determine the best security option for your application's virtual network.</p>\n<p><img alt=\"Virtual network security decision tree\" src=\"https://learn.microsoft.com/azure/architecture/example-scenario/gateway/images/decision-tree.png\" /></p>\n<p>In general, use:</p>\n<ul>\n<li><a href=\"#azure-firewall-only\">Azure Firewall alone</a> when there are no web applications in the virtual network.</li>\n<li><a href=\"#application-gateway-only\">Application Gateway alone</a> when there are only web applications in the virtual network, and <a href=\"https://learn.microsoft.com/azure/virtual-network/security-overview\">network security groups (NSGs)</a> provide sufficient output filtering.</li>\n<li><a href=\"#firewall-and-application-gateway-in-parallel\">Azure Firewall and Application Gateway in parallel</a>, the most common design, when you want Azure Application Gateway to protect HTTP(S) applications from web attacks, and Azure Firewall to protect all other workloads and filter outbound traffic.</li>\n<li><a href=\"#application-gateway-before-firewall\">Application Gateway in front of Azure Firewall</a> when you want Azure Firewall to inspect all traffic and WAF to protect web traffic, and the application needs to know the client's source IP address.</li>\n<li><a href=\"#application-gateway-after-firewall\">Azure Firewall in front of Application Gateway</a> when you want Azure Firewall to inspect and filter traffic before it reaches the Application Gateway.</li>\n</ul>\n<p>Variations of the previous basic designs include <a href=\"#on-premises-clients\">on-premises application clients</a>, <a href=\"#hub-and-spoke-topology\">hub and spoke networks</a>, and <a href=\"https://learn.microsoft.com/azure/aks/intro-kubernetes\">Azure Kubernetes Service (AKS)</a> implementations. You can add services like an <a href=\"https://learn.microsoft.com/azure/api-management/api-management-key-concepts\">API Management</a> gateway, or you can replace the Azure resources with third-party <a href=\"#other-network-virtual-appliances\">network virtual appliances</a>.</p>",
            "Flow": {
                "FlowStep_A": "The client initiates the connection to the public IP address of the Azure Application Gateway:",
                "FlowStep_B": "The Application Gateway instance terminates the connection from the client, and establishes a new connection with one of the back ends. The UDR to `192.168.1.0/24` in the Application Gateway subnet forwards the packet to the Azure Firewall, while preserving the destination IP to the web application:",
                "FlowStep_C": "Azure Firewall doesn't SNAT the traffic, since it's going to a private IP address, and forwards the traffic to the application VM if rules allow it. For more information, see [Azure Firewall SNAT][azfw-snat].",
                "FlowStep_D": "The VM answers the request, reversing source and destination IP addresses. The UDR to `192.168.200.0/24` captures the packet sent back to the Application Gateway and redirects it to Azure Firewall, while preserving the destination IP toward the Application Gateway.",
                "FlowStep_E": "Here again the Azure Firewall doesn't SNAT the traffic, since it's going to a private IP address, and forwards the traffic to the Application Gateway.",
                "FlowStep_F": "Finally, the Application Gateway instance answers the client:"
            },
            "name": "firewall-application-gateway",
            "popularity": 0,
            "topic": "Networking"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-forecast-energy-power-demand-'",
                "acom-architecture",
                "ai-ml",
                "all-items",
                "energy-demand",
                "energy-forecast",
                "power-forecast",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/forecast-energy-power-demand.md",
            "http_url": "/azure/architecture/solution-ideas/articles/forecast-energy-power-demand",
            "word_count": 238,
            "read_time": "2 min read",
            "Title": "Forecast Energy and Power Demand",
            "MetaDescription": "Learn how Microsoft Azure can help accurately forecast spikes in demand for energy products and services to give your company a competitive advantage.",
            "category": [
                "ai-machine-learning",
                "integration"
            ],
            "image": "/azure/architecture/solution-ideas/media/forecast-energy-power-demand.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\forecast-energy-power-demand.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/stream-analytics\">Azure Stream Analytics</a>: Stream Analytics aggregates energy consumption data in near real-time to write to Power BI.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/event-hubs\">Event Hubs</a> ingests raw energy consumption data and passes it on to Stream Analytics.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/machine-learning-studio\">Machine Learning Studio</a>: Machine Learning forecasts the energy demand of a particular region given the inputs received.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/sql-database\">Azure SQL Database</a>: SQL Database stores the prediction results received from Azure Machine Learning. These results are then consumed in the Power BI dashboard.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/data-factory\">Data Factory</a> handles orchestration and scheduling of the hourly model retraining.</p>",
                "<p><a href=\"https://powerbi.microsoft.com\">Power BI</a> visualizes energy consumption data from Stream Analytics as well as predicted energy demand from SQL Database.</p>"
            ],
            "Summary": "<p>Learn how Microsoft Azure can help accurately forecast spikes in demand for energy products and services to give your company a competitive advantage.</p>\n<p>This solution is built on the Azure managed services: <a href=\"https://azure.microsoft.com/services/stream-analytics\">Azure Stream Analytics</a>, <a href=\"https://azure.microsoft.com/services/event-hubs\">Event Hubs</a>, <a href=\"https://azure.microsoft.com/services/machine-learning-studio\">Machine Learning Studio</a>, <a href=\"https://azure.microsoft.com/services/sql-database\">Azure SQL Database</a>, <a href=\"https://azure.microsoft.com/services/data-factory\">Data Factory</a> and <a href=\"https://powerbi.microsoft.com\">Power BI</a>. These services run in a high-availability environment, patched and supported, allowing you to focus on your solution instead of the environment they run in.</p>",
            "name": "forecast-energy-power-demand",
            "popularity": 84,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-gaming-using-azure-database-for-mysql-'",
                "acom-architecture",
                "all-items",
                "azure",
                "gaming",
                "mysql",
                "scalability",
                "solution-idea",
                "solutions",
                "use-cases"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/gaming-using-azure-database-for-mysql.md",
            "http_url": "/azure/architecture/solution-ideas/articles/gaming-using-azure-database-for-mysql",
            "word_count": 34,
            "read_time": "1 min read",
            "Title": "Gaming using Azure Database for MySQL",
            "MetaDescription": "Scale your databases elastically to accommodate unpredictable bursts of traffic and deliver low-latency multi-player experiences.",
            "category": [
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/gaming-using-azure-database-for-mysql.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\gaming-using-azure-database-for-mysql.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Scale your databases elastically to accommodate unpredictable bursts of traffic and deliver low-latency multi-player experiences.</p>",
            "name": "gaming-using-azure-database-for-mysql",
            "popularity": 36,
            "topic": "Databases"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-gaming-using-cosmos-db-'",
                "acom-architecture",
                "all-items",
                "cosmos-db",
                "gaming",
                "scalability",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/gaming-using-cosmos-db.md",
            "http_url": "/azure/architecture/solution-ideas/articles/gaming-using-cosmos-db",
            "word_count": 36,
            "read_time": "1 min read",
            "Title": "Gaming using Azure Cosmos DB",
            "MetaDescription": "Elastically scale your database to accommodate unpredictable bursts of traffic and deliver low-latency multi-player experiences on a global scale.",
            "category": [
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/gaming-using-cosmos-db.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\gaming-using-cosmos-db.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Elastically scale your database to accommodate unpredictable bursts of traffic and deliver low-latency multi-player experiences on a global scale.</p>",
            "name": "gaming-using-cosmos-db",
            "popularity": 101,
            "topic": "Databases"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-globally-distributed-mission-critical-applications-using-cosmos-db-'",
                "acom-architecture",
                "all-items",
                "app-dev",
                "cosmos-db",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/globally-distributed-mission-critical-applications-using-cosmos-db.md",
            "http_url": "/azure/architecture/solution-ideas/articles/globally-distributed-mission-critical-applications-using-cosmos-db",
            "word_count": 37,
            "read_time": "1 min read",
            "Title": "Globally distributed applications using Azure Cosmos DB",
            "MetaDescription": "Guarantee access to users around the world with the high-availability and low-latency capabilities built into Microsoft's global datacenters.",
            "category": [
                "databases",
                "management-and-governance"
            ],
            "image": "/azure/architecture/solution-ideas/media/globally-distributed-mission-critical-applications-using-cosmos-db.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\globally-distributed-mission-critical-applications-using-cosmos-db.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Guarantee access to users around the world with the high-availability and low-latency capabilities built into Microsoft's global datacenters.</p>",
            "name": "globally-distributed-mission-critical-applications-using-cosmos-db",
            "popularity": 79,
            "topic": "Databases"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-security-compliance-blueprint-hipaa-hitrust-health-data-ai-'",
                "acom-architecture",
                "all-items",
                "cloud-storage-in-healthcare",
                "data",
                "data-flow",
                "healthcare-data-storage",
                "interactive-diagram",
                "medical-data-solutions",
                "medical-data-storage",
                "medical-records-management",
                "medical-records-storage",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/security-compliance-blueprint-hipaa-hitrust-health-data-ai.md",
            "http_url": "/azure/architecture/solution-ideas/articles/security-compliance-blueprint-hipaa-hitrust-health-data-ai",
            "word_count": 361,
            "read_time": "2 min read",
            "Title": "HIPAA and HITRUST compliant health data AI",
            "MetaDescription": "Manage HIPAA and HITRUST compliant health data and medical records with the highest level of built-in security.",
            "category": [
                "storage"
            ],
            "image": "/azure/architecture/solution-ideas/media/security-compliance-blueprint-hipaa-hitrust-health-data-ai.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\security-compliance-blueprint-hipaa-hitrust-health-data-ai.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/functions\">Azure Functions</a>: Process events with serverless code</p>",
                "<p><a href=\"https://azure.microsoft.com/services/event-grid\">Event Grid</a>: Get reliable event delivery at massive scale</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage\">Storage Accounts</a>: Durable, highly available, and massively scalable cloud storage</p>",
                "<p><a href=\"https://azure.microsoft.com/services/sql-database\">Azure SQL Database</a>: Managed, intelligent SQL in the cloud</p>",
                "<p><a href=\"https://azure.microsoft.com/services/machine-learning\">Azure Machine Learning</a>: Bring AI to everyone with an end-to-end, scalable, trusted platform with experimentation and model management</p>",
                "<p><a href=\"https://azure.microsoft.com/services/power-bi-embedded\">Power BI Embedded</a>: Embed fully interactive, stunning data visualizations in your applications</p>",
                "<p><a href=\"https://azure.microsoft.com/services/security-center\">Security Center</a>: Unify security management and enable advanced threat protection across hybrid cloud workloads</p>",
                "<p><a href=\"https://azure.microsoft.com/services/active-directory\">Azure Active Directory</a>: Synchronize on-premises directories and enable single sign-on</p>",
                "<p><a href=\"https://azure.microsoft.com/services/key-vault\">Key Vault</a>: Safeguard and maintain control of keys and other secrets</p>",
                "<p>Application Insights: Detect, triage, and diagnose issues in your web apps and services</p>",
                "<p><a href=\"https://azure.microsoft.com/services/monitor\">Azure Monitor</a>: Full observability into your applications, infrastructure, and network</p>",
                "<p><a href=\"https://www.microsoft.com/cloud-platform/operations-management-suite\">Operation Management Suite</a>: A collection of management services that were designed in the cloud from the start</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/role-based-access-control/built-in-roles\">RBAC and built-in roles</a>: Role-based access control (RBAC) has several built-in role definitions that you can assign to users, groups, and service principals.</p>"
            ],
            "Summary": "",
            "Flow": {
                "FlowStep_A": "Securely ingest bulk patient data into Azure Blob storage.",
                "FlowStep_B": "Event Grid publishes patient data to Azure Functions for processing, and securely stores patient data in SQL Database.",
                "FlowStep_C": "Analyze patient data using Machine Learning, and create a Machine Learning-trained model.",
                "FlowStep_D": "Ingest new patient data in HL7/FHIR format and publish to Azure Functions for processing. Store in SQL Database.",
                "FlowStep_E": "Analyze newly ingested data using the trained Machine Learning model.",
                "FlowStep_F": "Interact with patient data using Power BI while preserving Role-Based Access Control (RBAC)."
            },
            "name": "security-compliance-blueprint-hipaa-hitrust-health-data-ai",
            "popularity": 111,
            "topic": "Storage"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-azure-batch-rendering-'",
                "acom-architecture",
                "all-items",
                "cluster-orchestration",
                "data-flow",
                "hpc-architecture",
                "hpc-solution",
                "interactive-diagram",
                "media-render",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/azure-batch-rendering.md",
            "http_url": "/azure/architecture/solution-ideas/articles/azure-batch-rendering",
            "word_count": 333,
            "read_time": "2 min read",
            "Title": "HPC Media Rendering",
            "MetaDescription": "Optimize the media rendering process with a step-by-step HPC solution architecture from Azure that combines Azure CycleCloud and Avere vFXT.",
            "category": [
                "storage",
                "compute",
                "media"
            ],
            "image": "/azure/architecture/solution-ideas/media/azure-batch-rendering.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\azure-batch-rendering.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/pricing/details/virtual-machines/linux\">N-Series VMs</a>: N-series virtual machines are ideal for compute and graphics-intensive workloads, helping customers to fuel innovation through scenarios like high-end remote visualization, deep learning, and predictive analytics.</p>",
                "<p><a href=\"https://azure.microsoft.com/pricing/details/virtual-machines/linux\">H-Series VMs</a>: The H-series is a new family specifically designed to handle high performance computing workloads such as financial risk modeling, seismic and reservoir simulation, molecular modeling, and genomic research.</p>",
                "<p>Effectively manage common workloads with ease while creating and optimizing HPC clusters with Microsoft <a href=\"https://azure.microsoft.com/features/azure-cyclecloud\">Azure CycleCloud</a>.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage/avere-vfxt\">Avere vFXT</a>: Faster, more accessible data storage for high-performance computing at the edge</p>",
                "<p><a href=\"https://azure.microsoft.com/services/batch\">Azure Batch</a>: Cloud-scale job scheduling and compute management</p>"
            ],
            "Summary": "<p>This HPC media rendering solution architecture shows Azure CycleCloud monitoring a Pixar Tractor pipeline manager and orchestrating burst compute node capacity on-demand using Azure low-priority Virtual Machines Scale Sets. An Avere vFXT cache makes data from the existing on-premises filesystem and Azure Blob storage available to compute nodes in Azure.</p>",
            "Flow": {
                "FlowStep_A": "Operations team uses Azure CycleCloud to configure and launch rendering pipeline cluster.",
                "FlowStep_B": "Azure CycleCloud orchestrates virtual machine (VM) creation and software configuration for head nodes, license servers, and Avere vFXT Cache.",
                "FlowStep_C": "Artist submits a render job to the Pixar Tractor pipeline manager.",
                "FlowStep_D": "Azure CycleCloud detects the change in job queue depth and autostarts render farm nodes in Virtual Machines Scale Sets with location, SKU, and configuration customized by job requirements.",
                "FlowStep_E": "Render pipeline manager (head nodes) executes render jobs on the new render farm VMs.",
                "FlowStep_F": "Render jobs pull artifacts from on-premises and Azure Blob storage as needed from NFS-mounted Avere vFXT.",
                "FlowStep_G": "As each job finishes rendering, resulting artifacts are written back to storage through the Avere vFXT.",
                "FlowStep_H": "As job queue empties, Azure CycleCloud auto-stops render farm VMs to reduce cost."
            },
            "name": "azure-batch-rendering",
            "popularity": 13,
            "topic": "Storage"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-hpc-risk-analysis-'",
                "acom-architecture",
                "all-items",
                "data-flow",
                "finance",
                "hpc",
                "hpc-risk-analysis",
                "hybrid-risk-analysis",
                "interactive-diagram",
                "risk-analysis-solution",
                "risk-analysis-template",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/hpc-risk-analysis.md",
            "http_url": "/azure/architecture/solution-ideas/articles/hpc-risk-analysis",
            "word_count": 478,
            "read_time": "3 min read",
            "Title": "HPC Risk Analysis Template - Solution Architecture",
            "MetaDescription": "Build an HPC risk analysis solution architecture with a step-by-step flowchart from Microsoft Azure that combines CycleCloud, Avere vFXT and TIBCO GridServer.",
            "category": [
                "compute",
                "storage",
                "hybrid",
                "integration"
            ],
            "image": "/azure/architecture/solution-ideas/media/hpc-risk-analysis.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\hpc-risk-analysis.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/pricing/details/virtual-machines/linux\">N-Series Virtual Machines</a>: N-series virtual machines are ideal for compute and graphics-intensive workloads, helping customers to fuel innovation through scenarios like high-end remote visualization, deep learning, and predictive analytics.</p>",
                "<p><a href=\"https://azure.microsoft.com/pricing/details/virtual-machines/linux\">H-Series Virtual Machines</a>: The H-series is a new family specifically designed to handle high performance computing workloads such as financial risk modeling, seismic and reservoir simulation, molecular modeling, and genomic research.</p>",
                "<p>Effectively manage common workloads with ease while creating and optimizing HPC clusters with Microsoft <a href=\"https://azure.microsoft.com/features/azure-cyclecloud\">Azure CycleCloud</a>.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage/avere-vfxt\">Avere vFXT</a>: Faster, more accessible data storage for high-performance computing at the edge</p>",
                "<p><a href=\"https://www.tibco.com/resources/datasheet/tibco-gridserver\">TIBCO GridServer</a>&reg; is a market-leading infrastructure platform for grid and elastic computing-and the backbone of businesses operating in the world's most demanding markets. More than a million CPUs spread across a thousand global installations form enterprise grids managed by GridServer.</p>"
            ],
            "Flow": {
                "FlowStep_A": "Operations team uses Azure CycleCloud to configure and launch risk analysis grid in Azure.",
                "FlowStep_B": "Azure CycleCloud orchestrates VM creation and software configuration for TIBCO GridServer brokers and HPCCA, in-memory data cache, and Avere vFXT cache.",
                "FlowStep_C": "Quant (or scheduled batch) submits a risk analysis template workflow to the on-premises TIBCO GridServer director. Based on job policies and current on-premises use, the workflow is allowed to burst to Azure to expand on-premises grid capacity.",
                "FlowStep_D": "The TIBCO HPCCA detects the change in queue depth for each TIBCO broker and requests additional TIBCO engine capacity using the Azure CycleCloud Auto-Scaling API. Azure CycleCloud then autostarts engine nodes in Virtual Machine Scale Sets using the Azure H-series, HB-series, and HC-series VMs to optimize cost and performance and NC-series VMs to provide GPU capacity as required.",
                "FlowStep_E": "As soon as engine VMs join the Azure Grid, the brokers begin executing tasks to the new nodes.",
                "FlowStep_F": "Risk jobs pull artifacts from on-premises and Azure Blob storage as needed from NFS mounted Avere vFXT and/or via the fast in-memory cache.",
                "FlowStep_G": "As each task completes, results are returned to the submitter or driver and data is written back to the in-memory cache, or to NFS storage through the Avere vFXT, as required. Cached data is persisted either on-premises or in Azure Blob storage.",
                "FlowStep_H": "As task queues drain, the TIBCO HPCCA uses the Azure CycleCloud Auto-Scaling API to shrink the compute grid and reduce cost."
            },
            "name": "hpc-risk-analysis",
            "popularity": 54,
            "topic": "Compute",
            "hybrid-topic": "Apps"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-big-compute-with-azure-batch-'",
                "acom-architecture",
                "all-items",
                "big-compute-solutions",
                "data-flow",
                "hpc",
                "interactive-diagram",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/big-compute-with-azure-batch.md",
            "http_url": "/azure/architecture/solution-ideas/articles/big-compute-with-azure-batch",
            "word_count": 303,
            "read_time": "2 min read",
            "Title": "HPC System and Big Compute Solutions",
            "MetaDescription": "Explore Big Compute solutions with Azure Batch. Use HPC cloud systems for cloud-native application and batch processing.",
            "category": [
                "compute",
                "storage"
            ],
            "image": "/azure/architecture/solution-ideas/media/big-compute-with-azure-batch.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\big-compute-with-azure-batch.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/storage\">Storage Accounts</a>: Massively scalable object storage for unstructured data.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/batch\">Batch</a>: Cloud-scale job scheduling and compute management.</p>"
            ],
            "Summary": "<p>Big compute and high performance computing (HPC) workloads are typically compute-intensive and can be run in parallel, taking advantage of the scale and flexibility of the cloud. The workloads are often run asynchronously using batch processing, with compute resources required to run the work and job scheduling required to specify the work. Examples of Big Compute and HPC workloads include financial risk Monte Carlo simulations, image rendering, media transcoding, file processing, and engineering or scientific simulations.</p>\n<p>This solution implements a cloud-native application with Azure Batch, which provides compute resource allocation and management, application installation, resource autoscaling, and job scheduling as a platform service. Batch also offers higher-level workload accelerators specifically for running R in parallel, AI training, and rendering workloads.</p>\n<p>This solution is built on managed services including Virtual Machines, Storage, and Batch. These Azure services run in a high-availability environment, patched and supported, allowing you to focus on your solution.</p>\n<p>The links to the right provide documentation on deploying and managing the Azure products listed in the solution architecture above.</p>\n<p><a href=\"https://learn.microsoft.com/azure/batch\">Batch documentation</a></p>\n<p><a href=\"https://azure.microsoft.com/services/virtual-machines\">Virtual Machines</a></p>\n<p><a href=\"https://azure.microsoft.com/services/batch\">Azure Batch</a></p>\n<p><a href=\"https://azure.microsoft.com/services/storage\">Azure Blob Storage</a></p>",
            "Flow": {
                "FlowStep_A": "Upload input files and the applications to your Azure Storage account.",
                "FlowStep_B": "Create a Batch pool of compute nodes, a job to run the workload on the pool, and the tasks in the job.",
                "FlowStep_C": "Batch downloads input files and applications.",
                "FlowStep_D": "Batch monitors task execution.",
                "FlowStep_E": "Batch uploads task output.",
                "FlowStep_F": "Download output files."
            },
            "name": "big-compute-with-azure-batch",
            "popularity": 24,
            "topic": "Compute"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-hpc-cluster-'",
                "acom-architecture",
                "all-items",
                "hpc",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/hpc-cluster.md",
            "http_url": "/azure/architecture/solution-ideas/articles/hpc-cluster",
            "word_count": 181,
            "read_time": "1 min read",
            "Title": "HPC cluster deployed in the cloud",
            "MetaDescription": "High performance computing (HPC) applications can scale to thousands of compute cores, extend on-premises big compute, or run as a 100% cloud native solution. This HPC solution including the head node, compute nodes, and storage nodes, runs in Azure with no hardware infrastructure to maintain.",
            "category": [
                "compute",
                "storage"
            ],
            "image": "/azure/architecture/solution-ideas/media/hpc-cluster.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\hpc-cluster.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/virtual-machines\">HPC head node</a></p>",
                "<p><a href=\"https://azure.microsoft.com/services/virtual-machine-scale-sets\">Virtual Machine Scale Sets</a></p>",
                "<p><a href=\"https://azure.microsoft.com/services/virtual-network\">Virtual Network</a> provides IP connectivity between the head node, compute nodes, and storage nodes.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage\">Storage Accounts</a>: Azure Storage blobs store the disks backing the virtual machines and provides long-term storage of unstructured data and executable files used by the HPC application.</p>"
            ],
            "Summary": "<p>High performance computing (HPC) applications can scale to thousands of compute cores, extend on-premises big compute, or run as a 100% cloud native solution. This HPC solution including the head node, compute nodes, and storage nodes, runs in Azure with no hardware infrastructure to maintain.</p>\n<p>This solution is built on the Azure managed services: <a href=\"https://azure.microsoft.com/services/virtual-machine-scale-sets\">Virtual Machine Scale Sets</a>, <a href=\"https://azure.microsoft.com/services/virtual-network\">Virtual Network</a> and <a href=\"https://azure.microsoft.com/services/storage\">Storage Accounts</a>. These services run in a high-availability environment, patched and supported, allowing you to focus on your solution instead of the environment they run in.</p>",
            "name": "hpc-cluster",
            "popularity": 60,
            "topic": "Compute"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "example-code",
                "example-workload",
                "fcp",
                "github",
                "pricing-guidance"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/infrastructure/iaas-high-availability-disaster-recovery.md",
            "http_url": "/azure/architecture/example-scenario/infrastructure/iaas-high-availability-disaster-recovery",
            "word_count": 1657,
            "read_time": "7 min read",
            "Title": "High availability and disaster recovery scenarios for IaaS apps.",
            "MetaDescription": "Choose among high-availability and disaster recovery options like availability sets, availability zones, and regional DR for deploying IaaS apps to the cloud.",
            "category": [
                "management-and-governance"
            ],
            "image": "/azure/architecture/example-scenario/infrastructure/media/ha-decision-tree.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\infrastructure\\media\\ha-decision-tree.png",
            "publish_date": "4/06/2020",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "Summary": "<p>This article presents a decision tree and examples of high-availability (HA) and disaster recovery (DR) options when deploying multitier infrastructure-as-a-service (IaaS) apps to Azure.</p>\n<p>Multitier or <a >n-tier</a> architectures are common in traditional on-premises apps, so they're a natural choice for migrating on-premises apps to the cloud, or when developing apps for both on-premises and the cloud. N-tier architectures are typically implemented as IaaS apps divided into logical layers and physical tiers, with a top web or presentation tier, a middle business tier, and a data tier. </p>\n<p>In an IaaS n-tier app, each tier runs on a separate set of VMs. The web and business tiers are stateless, meaning any VM in the tier can handle any request for that tier. The data tier is a replicated database, object storage, or file storage. Multiple VMs in each tier provide resiliency if one VM fails, and load balancers distribute requests across the VMs. </p>\n<p>You can scale out tiers by adding more VMs to the pools, and use <a href=\"https://learn.microsoft.com/azure/virtual-machine-scale-sets/overview\">virtual machine scale sets</a> to automatically scale out identical VMs. Because you use load balancers, you can scale out tiers without affecting app uptime.</p>\n<p>If the service-level agreement (SLA) for an IaaS app requires &gt; 99% availability, you can place VMs in <em>availability sets</em>, <em>availability zones</em>, and <em>proximity placement groups</em> to configure high availability for the app. The HA and DR solutions you choose depend on the required SLA, latency considerations, and regional DR requirements.</p>",
            "sample_code": true,
            "github_url": "https://github.com/Azure/SAP-on-Azure-Scripts-and-Utilities/tree/master/AvZone-Latency-Test",
            "name": "iaas-high-availability-disaster-recovery",
            "popularity": 0,
            "topic": "Management and Governance"
        },
        {
            "tags": [
                "all-items",
                "dotnetcli",
                "example-code",
                "github",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/enterprise-integration/ase-high-availability-deployment.md",
            "http_url": "/azure/architecture/reference-architectures/enterprise-integration/ase-high-availability-deployment",
            "word_count": 1511,
            "read_time": "7 min read",
            "Title": "High availability enterprise deployment using App Services Environment",
            "MetaDescription": "Recommended architecture for deploying an enterprise application using App Services Environment in multiple availability zones.",
            "category": [
                "management-and-governance",
                "featured"
            ],
            "image": "/azure/architecture/reference-architectures/enterprise-integration/_images/ha-ase-deployment.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\enterprise-integration\\_images\\ha-ase-deployment.png",
            "publish_date": "5/08/2020",
            "Summary": "<p><a href=\"https://learn.microsoft.com/azure/availability-zones/az-overview\">Availability zones</a> are physically separated collections of datacenters within a given region. Replicating your deployments across multiple zones, ensures that local outages limited to a zone do not negatively impact the availability of your application. This architecture shows how you can improve the resiliency of an ASE deployment by deploying in multiple availability zones. These zones are not related to proximity. They can map to different physical locations for different subscriptions. This architecture assumes a single subscription deployment.</p>\n<p><img alt=\"GitHub logo\" src=\"https://learn.microsoft.com/azure/architecture/_images/github.png\" /> A reference implementation for this architecture is available on <a href=\"https://github.com/mspnp/app-service-environments-ILB-deployments\">GitHub</a>.</p>\n<p><img alt=\"Reference architecture for high availability ASE deployment\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/enterprise-integration/_images/ha-ase-deployment.png\" /></p>",
            "sample_code": true,
            "github_url": "https://github.com/mspnp/app-service-environments-ILB-deployments",
            "code_languages": [
                "dotnetcli"
            ],
            "name": "ase-high-availability-deployment",
            "popularity": 0,
            "topic": "Management and Governance"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-highly-available-sharepoint-farm-'",
                "acom-architecture",
                "all-items",
                "bcdr",
                "data-flow",
                "interactive-diagram",
                "sharepoint-farm-solution",
                "sharepoint-intranet",
                "sharepoint-intranet-solutions",
                "sharepoint-intranet-template",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/highly-available-sharepoint-farm.md",
            "http_url": "/azure/architecture/solution-ideas/articles/highly-available-sharepoint-farm",
            "word_count": 391,
            "read_time": "2 min read",
            "Title": "Highly available SharePoint farm",
            "MetaDescription": "Learn how to deploy a highly available SharePoint farm for intranet capabilities with a step-by-step solution architecture template from Azure.",
            "category": [
                "web",
                "management-and-governance"
            ],
            "image": "/azure/architecture/solution-ideas/media/highly-available-sharepoint-farm.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\highly-available-sharepoint-farm.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/features/resource-manager\">Azure Resource Group</a>: Container that holds related resources for an Azure solution</p>",
                "<p><a href=\"https://azure.microsoft.com/services/virtual-network\">Virtual Network</a>: Provision private networks, optionally connect to on-premises datacenters</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage\">Storage Accounts</a>: Durable, highly available, and massively scalable cloud storage</p>",
                "<p><a href=\"https://azure.microsoft.com/services/active-directory\">Azure Active Directory</a>: Synchronize on-premises directories and enable single sign-on</p>",
                "<p>SharePoint Server: Microsoft's collaboration server product</p>",
                "<p>Host enterprise <a href=\"https://azure.microsoft.com/services/virtual-machines/sql-server\">SQL Server</a> apps in the cloud</p>",
                "<p><a href=\"https://azure.microsoft.com/services/load-balancer\">Load Balancer</a>: Deliver high availability and network performance to your applications</p>",
                "<p><a href=\"https://azure.microsoft.com/services/expressroute\">Azure ExpressRoute</a>: Dedicated private network fiber connections to Azure</p>"
            ],
            "Summary": "<p>This solution provides a highly available deployment of SharePoint using a load balanced Azure Active Directory (Azure AD), highly available SQL always on instance, and highly available SharePoint resources. It addresses the requirement to deliver highly available intranet capability using the latest and greatest supported platforms.</p>",
            "Flow": {
                "FlowStep_A": "Create resource group for the storage, network, and virtual machine, plus other dependent elements.",
                "FlowStep_B": "Create virtual network to host the virtual machines and load balancers for the deployment. Ensure the network has appropriate network security groups implemented to protect network traffic flow.",
                "FlowStep_C": "Create the storage accounts that will host the virtual hard disks (VHDs) for the machine images.",
                "FlowStep_D": "Create the Active Directory installation using either a new virtual machine or Azure AD domain services. If using Azure AD domain services,  consider synchronizing identities to Azure AD with Azure AD Connect.",
                "FlowStep_E": "Create a Windows failover cluster and install a supported version of SQL Server on an Azure virtual machine (VM) or deploy pay-as-you-go instances of SQL Server.",
                "FlowStep_F": "Deploy SharePoint onto multiple Azure VMs, or, use trial images from the gallery that already have SharePoint Server installed.",
                "FlowStep_G": "Create the SharePoint farm.",
                "FlowStep_H": "Set up an Azure external load balancer to direct incoming HTTPS traffic to the SharePoint server.",
                "FlowStep_I": "Use ExpressRoute or VPN Gateway for management access to resource group.",
                "FlowStep_J": "On-premises users can access the SharePoint sites via the internet, ExpressRoute, or VPN Gateway.",
                "FlowStep_K": "External users can be granted access as required to the SharePoint sites for testing."
            },
            "name": "highly-available-sharepoint-farm",
            "popularity": 52,
            "topic": "Web"
        },
        {
            "tags": [
                "all-items",
                "reference-architecture",
                "seodec18",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/app-service-web-app/multi-region.yml",
            "http_url": "/azure/architecture/reference-architectures/app-service-web-app/multi-region",
            "word_count": 1885,
            "read_time": "8 min read",
            "Title": "Highly available multi-region web application",
            "MetaDescription": "Recommended architecture for a highly available web application running in multiple regions in Azure.",
            "category": [
                "web",
                "management-and-governance"
            ],
            "image": "/azure/architecture/reference-architectures/app-service-web-app/images/multi-region-web-app-diagram.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\app-service-web-app\\images\\multi-region-web-app-diagram.png",
            "publish_date": "8/14/2019",
            "Summary": "<p>This reference architecture shows how to run an Azure App Service application in multiple regions to achieve high availability.</p>\n<p><img alt=\"Reference architecture for a web application with high availability\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/app-service-web-app/images/multi-region-web-app-diagram.png\" /></p>\n<p><em>Download a <a href=\"https://arch-center.azureedge.net/app-service-reference-architectures.vsdx\">Visio file</a> of this architecture.</em></p>",
            "visio_diagram": "https://arch-center.azureedge.net/app-service-reference-architectures.vsdx",
            "name": "multi-region",
            "popularity": 236,
            "topic": "Web"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-homomorphic-encryption-lab-'---fcp",
                "all-items",
                "encryption",
                "example-code",
                "github",
                "homomorphic-encryption",
                "microsoft-seal",
                "security",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/homomorphic-encryption-seal.md",
            "http_url": "/azure/architecture/solution-ideas/articles/homomorphic-encryption-seal",
            "word_count": 760,
            "read_time": "4 min read",
            "Title": "Homomorphic encryption with SEAL",
            "MetaDescription": "Learn about homomorphic encryption, and get an overview and example of how to use the Microsoft SEAL encryption library.",
            "category": [
                "security"
            ],
            "image": "/azure/architecture/solution-ideas/media/seal.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\seal.png",
            "publish_date": "7/13/2020",
            "Summary": "<p>Companies often send, receive, and store their cloud data in encrypted form. But to take advantage of cloud computing services, companies must provide either unencrypted data, or the keys to decrypt it, which puts their data at increased risk. <em>Homomorphic encryption</em> allows computation directly on encrypted data, making it easier to leverage the potential of the cloud for privacy-critical data.</p>\n<p>This article discusses how and when to use homomorphic encryption, and how to implement homomorphic encryption with the open-source <a href=\"https://github.com/microsoft/SEAL#introduction\">Microsoft Simple Encrypted Arithmetic Library (SEAL)</a>.</p>",
            "sample_code": true,
            "github_url": "https://github.com/microsoft/SEAL#introduction",
            "name": "homomorphic-encryption-seal",
            "popularity": 0,
            "topic": "Security"
        },
        {
            "tags": [
                "all-items",
                "azurecli",
                "example-code",
                "fcp",
                "github",
                "networking",
                "reference-architecture",
                "seodec18",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/hybrid-networking/hub-spoke.yml",
            "http_url": "/azure/architecture/reference-architectures/hybrid-networking/hub-spoke",
            "word_count": 1727,
            "read_time": "7 min read",
            "Title": "Hub-spoke network topology in Azure",
            "MetaDescription": "Learn how to implement a hub-spoke topology in Azure, where the hub is a virtual network and the spokes are virtual networks that peer with the hub.",
            "category": [
                "networking",
                "management-and-governance",
                "hybrid"
            ],
            "image": "/azure/architecture/reference-architectures/hybrid-networking/images/hub-spoke.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\hybrid-networking\\images\\hub-spoke.png",
            "publish_date": "9/30/2020",
            "Summary": "<p>ADMIN_USER=adminuser\nADMIN_PASSWORD=Password2020!</p>",
            "sample_code": true,
            "github_url": "https://github.com/Azure/azure-quickstart-templates/tree/master/101-hub-and-spoke-sandbox",
            "visio_diagram": "https://arch-center.azureedge.net/hybrid-network-hub-spoke.vsdx",
            "code_languages": [
                "azurecli"
            ],
            "name": "hub-spoke",
            "popularity": 241,
            "topic": "Networking",
            "hybrid-topic": "Networking"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-hybrid-connectivity-'",
                "acom-architecture",
                "all-items",
                "azure-hybrid-connection",
                "azure-hybrid-network",
                "data-flow",
                "hybrid-connection",
                "hybrid-infrastructure",
                "hybrid-network",
                "interactive-diagram",
                "networking",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/hybrid-connectivity.md",
            "http_url": "/azure/architecture/solution-ideas/articles/hybrid-connectivity",
            "word_count": 236,
            "read_time": "2 min read",
            "Title": "Hybrid Connection",
            "MetaDescription": "Azure's Hybrid Connection is a foundational blueprint that is applicable to most Azure Stack Hub solutions, allowing you to establish connectivity for any application that involves communications between the Azure public cloud and on-premises Azure Stack Hub components.",
            "category": [
                "hybrid",
                "networking"
            ],
            "image": "/azure/architecture/solution-ideas/media/hybrid-connectivity.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\hybrid-connectivity.png",
            "publish_date": "9/01/2020",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/virtual-network\">Virtual Network</a>: Provision private networks, optionally connect to on-premises datacenters.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/vpn-gateway\">Virtual Network Gateway</a>: Learn how to configure VPN Gateway, a virtual private network gateway.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/virtual-machines\">Virtual Machines</a>: Provision Windows and Linux virtual machines in seconds.</p>",
                "<p><a href=\"https://azure.microsoft.com/overview/azure-stack\">Azure Stack Hub</a> is a hybrid cloud platform that lets you use Azure services on-premises.</p>"
            ],
            "Summary": "<p>Azure Stack Hub enables you to deploy Azure services on-premises or in the cloud with a consistent application logic, development paradigm, and operations methodology.</p>\n<p>Hybrid cloud applications are a single system that has components running in both Azure and Azure Stack Hub. This solution blueprint is relevant to establishing connectivity for any application that involves communications between the Azure public cloud and on-premises Azure Stack Hub components. Hybrid connectivity is a foundational blueprint that will be applicable to most Azure Stack Hub solutions.</p>\n<p>Note: This doesn't apply to Azure Stack Hub deployments that are disconnected from the public internet.</p>",
            "Flow": {
                "FlowStep_A": "Deploy a virtual network in Azure and Azure Stack Hub.",
                "FlowStep_B": "Deploy a virtual network gateway in Azure and Azure Stack Hub.",
                "FlowStep_C": "Deploy virtual machines in each virtual network.",
                "FlowStep_D": "Establish a VPN connection over the public internet between the network gateways."
            },
            "name": "hybrid-connectivity",
            "popularity": 195,
            "topic": "Networking",
            "hybrid-topic": "Networking"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "data",
                "data-flow",
                "example-workload",
                "pricing-guidance",
                "sql-server",
                "tsp-team"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/data/hybrid-etl-with-adf.md",
            "http_url": "/azure/architecture/example-scenario/data/hybrid-etl-with-adf",
            "word_count": 1078,
            "read_time": "5 min read",
            "Title": "Hybrid ETL with Azure Data Factory",
            "MetaDescription": "Hybrid ETL with existing on-premises SQL Server Integration Services (SSIS) deployments and Azure Data Factory.",
            "category": [
                "databases",
                "hybrid"
            ],
            "image": "/azure/architecture/example-scenario/data/media/architecture-diagram-hybrid-etl-with-adf.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\data\\media\\architecture-diagram-hybrid-etl-with-adf.png",
            "publish_date": "11/20/2019",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/storage/blobs/storage-blobs-overview\">Blob storage</a> is used to store files and as a source for Data Factory to retrieve data.</p>",
                "<p><a href=\"https://learn.microsoft.com/sql/integration-services/sql-server-integration-services\">SQL Server Integration Services</a> contains the on-premises ETL packages used to execute task-specific workloads.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/data-factory/introduction\">Azure Data Factory</a> is the cloud orchestration engine that takes data from multiple sources and combines, orchestrates, and loads the data into a data warehouse.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/sql-data-warehouse/sql-data-warehouse-overview-what-is\">Azure Synapse</a> centralizes data in the cloud for easy access using standard ANSI SQL queries.</p>"
            ],
            "Flow": {},
            "name": "hybrid-etl-with-adf",
            "popularity": 182,
            "topic": "Databases",
            "hybrid-topic": "Data"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-hybrid-hpc-in-azure-with-hpc-pack-'",
                "acom-architecture",
                "all-items",
                "azure-hpc-pack",
                "data-flow",
                "hpc",
                "hpc-pack",
                "hybrid-hpc",
                "hybrid-infrastructure",
                "interactive-diagram",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/hybrid-hpc-in-azure-with-hpc-pack.md",
            "http_url": "/azure/architecture/solution-ideas/articles/hybrid-hpc-in-azure-with-hpc-pack",
            "word_count": 241,
            "read_time": "2 min read",
            "Title": "Hybrid HPC in Azure with HPC Pack",
            "MetaDescription": "Get a hybrid high performance computing solution built with Windows Server technology. Use Azure HPC Pack to create a hybrid HPC environment.",
            "category": [
                "compute",
                "hybrid",
                "management-and-governance"
            ],
            "image": "/azure/architecture/solution-ideas/media/hybrid-hpc-in-azure-with-hpc-pack.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\hybrid-hpc-in-azure-with-hpc-pack.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/virtual-machines\">Virtual Machines</a>: Create Linux and Windows virtual machines in seconds.</p>",
                "<p><a href=\"https://www.visualstudio.com/vs\">Microsoft HPC Pack</a>: Free high performance computing (HPC) solution built on Microsoft Azure and Windows Server technologies.</p>"
            ],
            "Summary": "<p>Microsoft HPC Pack is a free high performance computing (HPC) solution built on Microsoft Azure and Windows Server technologies. HPC Pack combines a comprehensive set of deployment, administration, job scheduling, and monitoring tools for your Windows and Linux HPC cluster environment, providing a flexible platform for developing and running HPC applications on premises and in Azure.</p>\n<p>This solution shows the process for using HPC Pack to create a hybrid (on-premises and Azure) HPC environment.</p>\n<p>The links to the right provide documentation on deploying and managing the Azure products listed in the solution architecture above.</p>\n<p><a href=\"https://technet.microsoft.com/library/cc514029(v=ws.11).aspx\">Documentation Home Page</a></p>\n<p><a href=\"https://learn.microsoft.com/azure/virtual-machines/windows/hpcpack-cluster-options\">HPC Pack Azure Deployment Options</a></p>",
            "Flow": {
                "FlowStep_A": "Log into on-premises head node",
                "FlowStep_B": "Add Azure compute nodes to the cluster",
                "FlowStep_C": "Start the compute nodes",
                "FlowStep_D": "Submit jobs to the cluster",
                "FlowStep_E": "HPC Pack sends jobs to on-premises and Azure nodes based upon the node group selected",
                "FlowStep_F": "Monitor job progress",
                "FlowStep_G": "Stop the compute nodes or configure auto-scaling"
            },
            "name": "hybrid-hpc-in-azure-with-hpc-pack",
            "popularity": 21,
            "topic": "Compute",
            "hybrid-topic": "Apps"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-hybrid-identity-'",
                "acom-architecture",
                "all-items",
                "azure-active-directory",
                "azure-active-directory-tenant",
                "azure-hybrid-identity",
                "data-flow",
                "hybrid-identity",
                "hybrid-infrastructure",
                "interactive-diagram",
                "service-principles",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/hybrid-identity.md",
            "http_url": "/azure/architecture/solution-ideas/articles/hybrid-identity",
            "word_count": 177,
            "read_time": "1 min read",
            "Title": "Hybrid Identity",
            "MetaDescription": "The Hybrid Identity blueprint enables teams to manage applications and user identity consistently across clouds with the utilization of Azure Stack Hub",
            "category": [
                "identity",
                "hybrid"
            ],
            "image": "/azure/architecture/solution-ideas/media/hybrid-identity.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\hybrid-identity.png",
            "publish_date": "9/01/2020",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/overview/azure-stack\">Azure Stack Hub</a> is a hybrid cloud platform that lets you use Azure services on-premises.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/virtual-machines\">Virtual Machines</a>: Provision Windows and Linux virtual machines in seconds.</p>",
                "<p>Learn how to synchronize directories and enable single sign-on with <a href=\"https://azure.microsoft.com/services/active-directory\">Azure Active Directory</a> (Azure AD).</p>"
            ],
            "Summary": "<p>The need to keep application components on-premises doesn't have to be a barrier to adopting cloud technologies. With Azure Stack Hub, app components can reside on-premises while interacting with components running in Azure public cloud. This blueprint enables teams to manage identity for users as well as applications in a way that is consistent across clouds.</p>",
            "Flow": {
                "FlowStep_A": "Set up an Azure Active Directory tenant.",
                "FlowStep_B": "Create users.",
                "FlowStep_C": "Deploy, manage, and operate application resources on Azure and Azure Stack Hub.",
                "FlowStep_D": "Create service principles.",
                "FlowStep_E": "Deploy with service principles.",
                "FlowStep_F": "Application resources can communicate over network."
            },
            "name": "hybrid-identity",
            "popularity": 114,
            "topic": "Identity",
            "hybrid-topic": "Identity"
        },
        {
            "tags": [
                "all-items",
                "fcp",
                "reference-architecture",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "hybrid/hybrid-security-monitoring.md",
            "http_url": "/azure/architecture/hybrid/hybrid-security-monitoring",
            "word_count": 3740,
            "read_time": "15 min read",
            "Title": "Hybrid Security Monitoring using Azure Security Center and Azure Sentinel",
            "MetaDescription": "Integration of monitoring the security configuration and telemetry of on-premises and Azure operating system workloads",
            "category": [
                "hybrid",
                "monitoring",
                "security"
            ],
            "image": "/azure/architecture/hybrid/images/hybrid-security-monitoring.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\hybrid\\images\\hybrid-security-monitoring.png",
            "publish_date": "8/19/2020",
            "Summary": "<p>the security configuration and telemetry of on-premises and Azure operating system workloads. This includes Azure Stack.</p>\n<p><img alt=\"Diagram illustrating deployed Microsoft Monitoring Agent on on-premises systems as well as on Azure based virtual machines transferring data to Azure Security Center and Azure Sentinel\" src=\"https://learn.microsoft.com/azure/architecture/hybrid/images/hybrid-security-monitoring.png\" /></p>\n<p><em>Download a <a href=\"https://arch-center.azureedge.net/hybrid-security-monitoring.vsdx\">Visio file</a> of this architecture.</em></p>\n<p>Typical uses for this architecture include:</p>\n<ul>\n<li>Best practices for integrating on-premises security and telemetry monitoring with Azure-based workloads</li>\n<li>How to integrate Azure Security Center with Azure Stack</li>\n<li>How to integrate Azure Security Center with Azure Sentinel</li>\n</ul>",
            "visio_diagram": "https://arch-center.azureedge.net/hybrid-security-monitoring.vsdx",
            "name": "hybrid-security-monitoring",
            "popularity": 0,
            "topic": "Security",
            "hybrid-topic": "Security"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-sharepoint-farm-microsoft-365-'",
                "acom-architecture",
                "all-items",
                "data-flow",
                "hybrid-infrastructure",
                "interactive-diagram",
                "microsoft-365-sharepoint-hybrid",
                "sharepoint-farm-solution",
                "sharepoint-hybrid",
                "sharepoint-hybrid-architecture",
                "sharepoint-hybrid-solution",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/sharepoint-farm-microsoft-365.md",
            "http_url": "/azure/architecture/solution-ideas/articles/sharepoint-farm-microsoft-365",
            "word_count": 402,
            "read_time": "2 min read",
            "Title": "Hybrid SharePoint Farm with Microsoft 365",
            "MetaDescription": "Deliver highly available intranet capability by deploying SharePoint and sharing hybrid workloads with Microsoft 365. Setup this solution with step-by-step instructions.",
            "category": [
                "web",
                "hybrid"
            ],
            "image": "/azure/architecture/solution-ideas/media/sharepoint-farm-microsoft-365.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\sharepoint-farm-microsoft-365.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/features/resource-manager\">Azure Resource Group</a>: Container that holds related resources for an Azure solution</p>",
                "<p><a href=\"https://azure.microsoft.com/services/virtual-network\">Virtual Network</a>: Provision private networks, optionally connect to on-premises datacenters</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage\">Storage Accounts</a>: Durable, highly available, and massively scalable cloud storage</p>",
                "<p><a href=\"https://azure.microsoft.com/services/active-directory\">Azure Active Directory</a>: Synchronize on-premises directories and enable single sign-on</p>",
                "<p>SharePoint Server: Microsoft's collaboration server product</p>",
                "<p>Host enterprise <a href=\"https://azure.microsoft.com/services/virtual-machines/sql-server\">SQL Server</a> apps in the cloud</p>",
                "<p><a href=\"https://azure.microsoft.com/services/load-balancer\">Load Balancer</a>: Deliver high availability and network performance to your applications</p>",
                "<p><a href=\"https://azure.microsoft.com/services/expressroute\">Azure ExpressRoute</a>: Dedicated private network fiber connections to Azure</p>",
                "<p><a href=\"https://azure.microsoft.com/services/vpn-gateway\">VPN Gateway</a>: Establish secure, cross-premises connectivity</p>",
                "<p>Azure AD Connect: Synchronize on-premises directories and enable single sign-on</p>",
                "<p>Active Directory Federation Services: Synchronize on-premises directories and enable single sign-on</p>",
                "<p>Hybrid Workloads: Scales between on-premises environments and the cloud</p>"
            ],
            "Summary": "<p>This solution provides a highly available deployment of SharePoint using a load balanced Azure Active Directory (Azure AD), highly available SQL always on instance, and highly available SharePoint resources. It addresses the need to deliver highly available intranet capability using the latest and greatest supported platforms.</p>",
            "Flow": {
                "FlowStep_A": "Create resource group to host all Azure based infrastructure and services.",
                "FlowStep_B": "Create virtual network in Azure.",
                "FlowStep_C": "Deploy Windows Servers to host Active Directory services for SharePoint and SQL server service accounts and machine accounts.",
                "FlowStep_D": "Deploy SQL Server Always on for HA support for the SharePoint farm.",
                "FlowStep_E": "Deploy SharePoint Severs. In this scenario we are using 2 Frontend with Distributed Cache and 2 Application with Search roles. This give us high availability.",
                "FlowStep_F": "Install Azure AD Connect on an on-premises server to synchronize your identities to Azure Active Directory.",
                "FlowStep_G": "Optionally configure Active Directory Federation Services on premises to support federated authentication to Microsoft 365.",
                "FlowStep_H": "Deploy ExpressRoute or setup a site-to-site VPN link for administrative access to the servers hosted in Azure IaaS.",
                "FlowStep_I": "Setup and provision external access to the Hybrid farm hosted in Azure IaaS",
                "FlowStep_J": "Setup and configure Hybrid Workloads between Microsoft 365 and the SharePoint farm."
            },
            "name": "sharepoint-farm-microsoft-365",
            "popularity": 0,
            "topic": "Web",
            "hybrid-topic": "Apps"
        },
        {
            "tags": [
                "all-items",
                "fcp",
                "reference-architecture",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "hybrid/hybrid-perf-monitoring.md",
            "http_url": "/azure/architecture/hybrid/hybrid-perf-monitoring",
            "word_count": 2810,
            "read_time": "11 min read",
            "Title": "Hybrid availability and performance monitoring",
            "MetaDescription": "Using Azure Monitor to monitor performance and availability for operating system workloads running on-premises, in third-party cloud providers, and in Microsoft Azure",
            "category": [
                "hybrid",
                "monitoring",
                "management-and-governance"
            ],
            "image": "/azure/architecture/hybrid/images/hybrid-perf-monitoring.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\hybrid\\images\\hybrid-perf-monitoring.png",
            "publish_date": "7/27/2020",
            "Summary": "<p>This reference architecture illustrates how to design Azure Monitor to monitor performance and availability for operating system (OS) workloads running in virtual machines (VMs) in Microsoft Azure, in on-premises environments, and with third-party cloud providers.</p>\n<p><img alt=\"Diagram illustrating monitoring and availability functions of Azure Monitor for OS workloads in Azure, in on-premises environments, and with third-party cloud providers. Data is being sent into a Log Analytics workspace. The data is used by Application Insights, Analysis, Visualization, Alerts, and Autoscale services as part of Azure Monitor\" src=\"https://learn.microsoft.com/azure/architecture/hybrid/images/hybrid-perf-monitoring.png\" /></p>\n<p><em>Download a <a href=\"https://arch-center.azureedge.net/hybrid-perf-monitoring.vsdx\">Visio file</a> of this architecture.</em></p>",
            "visio_diagram": "https://arch-center.azureedge.net/hybrid-perf-monitoring.vsdx",
            "name": "hybrid-perf-monitoring",
            "popularity": 0,
            "topic": "Management and Governance",
            "hybrid-topic": "Management"
        },
        {
            "tags": [
                "all-items",
                "fcp",
                "reference-architecture",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "hybrid/hybrid-file-services.md",
            "http_url": "/azure/architecture/hybrid/hybrid-file-services",
            "word_count": 2783,
            "read_time": "10 min read",
            "Title": "Hybrid file services",
            "MetaDescription": "Use Azure File Sync and Azure Files to extend file services hosting capabilities across cloud and on-premises file share resources.",
            "category": [
                "hybrid",
                "storage"
            ],
            "image": "/azure/architecture/hybrid/images/hybrid-file-services.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\hybrid\\images\\hybrid-file-services.png",
            "publish_date": "7/28/2020",
            "Summary": "<p>This reference architecture illustrates how to use Azure File Sync and Azure Files to extend file services hosting capabilities across cloud and on-premises file share resources.</p>\n<p><img alt=\"An Azure hybrid file services topology diagram.\" src=\"https://learn.microsoft.com/azure/architecture/hybrid/images/hybrid-file-services.png\" /></p>\n<p><em>Download a <a href=\"https://arch-center.azureedge.net/hybrid-file-services.vsdx\">Visio file</a> of this architecture.</em></p>\n<p>Typical uses for this architecture include:</p>\n<ul>\n<li>Hosting file shares that need to be accessible from cloud and on-premises environments.</li>\n<li>Synchronizing data between multiple on-premises data stores with a single cloud-based source.</li>\n</ul>",
            "visio_diagram": "https://arch-center.azureedge.net/hybrid-file-services.vsdx",
            "name": "hybrid-file-services",
            "popularity": 0,
            "topic": "Storage",
            "hybrid-topic": "Data"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "data-flow",
                "example-workload",
                "pricing-calculator",
                "pricing-guidance"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/ai/intelligent-apps-image-processing.md",
            "http_url": "/azure/architecture/example-scenario/ai/intelligent-apps-image-processing",
            "word_count": 910,
            "read_time": "4 min read",
            "Title": "Image classification on Azure",
            "MetaDescription": "Learn how to build image processing into your applications by using Azure services such as the Computer Vision API and Azure Functions.",
            "category": [
                "ai-machine-learning",
                "media"
            ],
            "image": "/azure/architecture/example-scenario/ai/media/architecture-intelligent-apps-image-processing.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\ai\\media\\architecture-intelligent-apps-image-processing.png",
            "publish_date": "7/05/2018",
            "pricing_calculator": "https://azure.com/e/f9b59d238b43423683db73f4a31dc380",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/cognitive-services/computer-vision/home\">Computer Vision API</a> is part of the Cognitive Services suite and is used to retrieve information about each image.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/azure-functions/functions-overview\">Azure Functions</a> provides the back-end API for the web application, as well as the event processing for uploaded images.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/event-grid/overview\">Event Grid</a> triggers an event when a new image is uploaded to blob storage. The image is then processed with Azure functions.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/storage/blobs/storage-blobs-introduction\">Blob storage</a> stores all of the image files that are uploaded into the web application, as well any static files that the web application consumes.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/cosmos-db/introduction\">Azure Cosmos DB</a> stores metadata about each image that is uploaded, including the results of the processing from Computer Vision API.</p>"
            ],
            "Summary": "<p>This scenario is relevant for businesses that need to process images.</p>\n<p>Potential applications include classifying images for a fashion website, analyzing text and images for insurance claims, or understanding telemetry data from game screenshots. Traditionally, companies would need to develop expertise in machine learning models, train the models, and finally run the images through their custom process to get the data out of the images.</p>\n<p>By using Azure services such as the Computer Vision API and Azure Functions, companies can eliminate the need to manage individual servers, while reducing costs and leveraging the expertise that Microsoft has already developed around processing images with Cognitive Services. This example scenario specifically addresses an image-processing use case. If you have different AI needs, consider the full suite of <a href=\"https://learn.microsoft.com/azure/#pivot=products&amp;panel=ai\">Cognitive Services</a>.</p>",
            "Flow": {
                "FlowStep_A": "The API layer is built using Azure Functions. These APIs enable the application to upload images and retrieve data from Azure Cosmos DB.",
                "FlowStep_B": "When an image is uploaded via an API call, it's stored in Blob storage.",
                "FlowStep_C": "Adding new files to Blob storage triggers an Event Grid notification to be sent to an Azure Function.",
                "FlowStep_D": "Azure Functions sends a link to the newly uploaded file to the Computer Vision API to analyze.",
                "FlowStep_E": "Once the data has been returned from the Computer Vision API, Azure Functions makes an entry in Azure Cosmos DB to persist the results of the analysis along with the image metadata."
            },
            "name": "intelligent-apps-image-processing",
            "popularity": 106,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-image-classification-with-convolutional-neural-networks-'",
                "acom-architecture",
                "ai-ml",
                "all-items",
                "automated-manufacturing-solutions",
                "convolutional-neural-network",
                "decision-tree-algorithm",
                "discrete-manufacturing",
                "example-code",
                "failure-detection",
                "github",
                "gradient-boosting-decision-tree",
                "image-classification",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/image-classification-with-convolutional-neural-networks.md",
            "http_url": "/azure/architecture/solution-ideas/articles/image-classification-with-convolutional-neural-networks",
            "word_count": 468,
            "read_time": "2 min read",
            "Title": "Image classification with Convolutional Neural Networks",
            "MetaDescription": "Explore transfer learning, convolutional neural networks, and gradient-boosting decision tree algorithms.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/image-classification-with-convolutional-neural-networks.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\image-classification-with-convolutional-neural-networks.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p>Azure Blob Storage: Data is ingested and stored in Azure Blob Storage.</p>",
                "<p>GPU based Azure Data Science Virtual Machine: The core development environment is the Azure Ubuntu-based GPU DSVM. The data is pulled from blob onto an Azure virtual hard disk (VHD) attached to the DSVM. On that VHD, the data is processed, the images are featurized using a Deep Neural Network, and a Boosted Tree model is trained. DSVM IPython Notebook server is used for solution development.</p>",
                "<p>Microsoft Machine Learning for Apache Spark HDInsight Spark Cluster: As an alternative to DSVM-based training, for big datasets, we use MMLSpark to build a highly scalable training solution.</p>",
                "<p>Azure Container Registry: The model and web application are packaged into a Docker image and written to Azure Container Registry.</p>",
                "<p>Azure Machine Learning Model Management Service: Azure Machine Learning Model Management service is used to deploy and manage the final model on a VM and to scale out using Azure Kubernetes Service to a Kubernetes managed Azure cluster. A predictive web service and a Java ETL service are also written onto the VM, each in its own container.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/kubernetes-service\">Azure Kubernetes Service (AKS)</a>: Deployment for this solution uses Azure Kubernetes Service running a Kubernetes-managed cluster. The containers are deployed from images stored in Azure Container Registry.</p>"
            ],
            "Summary": "<p>Lean manufacturing, cost control, and waste reduction are imperative for manufacturing to remain competitive. In circuit-board manufacturing, faulty boards can cost manufacturers money and productivity. Assembly lines rely on human operators to quickly review and validate boards flagged as potentially faulty by assembly-line test machines.</p>\n<p>This solution analyzes electronic component images generated by assembly-line cameras in a circuit-board manufacturing plant and detects their error status. The goal is to minimize or remove the need for human intervention. The solution builds an image classification system using a convolutional neural network with 50 hidden layers, pretrained on 350,000 images in an ImageNet dataset to generate visual features of the images by removing the last network layer. These features are then used to train a boosted decision tree to classify the image as \"pass\" or \"fail\" and final scoring conducted on edge machines at the plant. The classification performance results are good (time-based cross-validation AUC&gt;.90) which indicates the solution is suitable to drastically minimize human intervention for electronic-components failure detection in assembled circuit boards.</p>\n<p>Using this solution to automate failure detection instead of relying solely on human operators helps improve the identification of faulty electronic components and boost productivity.</p>",
            "sample_code": true,
            "github_url": "https://github.com/azure/mmlspark",
            "name": "image-classification-with-convolutional-neural-networks",
            "popularity": 122,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-immutable-infrastructure-cicd-using-jenkins-and-terraform-on-azure-virtual-architecture-overview-'",
                "acom-architecture",
                "all-items",
                "ci-cd",
                "continuous-delivery",
                "continuous-deployment",
                "continuous-integration",
                "data-flow",
                "devops",
                "interactive-diagram",
                "is-deployable",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/immutable-infrastructure-cicd-using-jenkins-and-terraform-on-azure-virtual-architecture-overview.md",
            "http_url": "/azure/architecture/solution-ideas/articles/immutable-infrastructure-cicd-using-jenkins-and-terraform-on-azure-virtual-architecture-overview",
            "word_count": 263,
            "read_time": "2 min read",
            "Title": "Immutable Infrastructure CI/CD using Jenkins and Terraform on Azure Virtual Architecture overview",
            "MetaDescription": "Azure is a world-class cloud for hosting virtual machines running Windows or Linux. Whether you use Java, Node.js, Go, or PHP to develop your applications, you'll need a continuous integration and continuous deployment (CI/CD) pipeline to push changes to these virtual machines automatically.",
            "category": [
                "devops",
                "developer-tools"
            ],
            "image": "/azure/architecture/solution-ideas/media/immutable-infrastructure-cicd-using-jenkins-and-terraform-on-azure-virtual-architecture-overview.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\immutable-infrastructure-cicd-using-jenkins-and-terraform-on-azure-virtual-architecture-overview.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/managed-disks\">Managed Disks</a>: Persistent, secured disk storage for Azure virtual machines.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/virtual-machine-scale-sets\">Virtual Machine Scale Sets</a>: Manage and scale up to thousands of Linux and Windows virtual machines.</p>",
                "<p>Log Analytics: Collect, search, and visualize machine data from on-premises and cloud.</p>",
                "<p><a href=\"https://azure.microsoft.com/products/visual-studio\">Visual Studio Code</a>: Build and deploy multi-platform apps to get the most from Azure services.</p>"
            ],
            "Flow": {
                "FlowStep_A": "Change application source code.",
                "FlowStep_B": "Commit code to GitHub.",
                "FlowStep_C": "Continuous Integration Trigger to Jenkins.",
                "FlowStep_D": "Jenkins triggers a Packer image build to create a VM and stores it as a VM image using Azure Managed Disks.",
                "FlowStep_E": "Jenkins triggers Terraform to provision a new Virtual Machine Scale Set using the Azure Managed Disks VM image.",
                "FlowStep_F": "Azure Log Analytics collects and analyzes logs.",
                "FlowStep_G": "Monitor application and make improvements."
            },
            "name": "immutable-infrastructure-cicd-using-jenkins-and-terraform-on-azure-virtual-architecture-overview",
            "popularity": 144,
            "topic": "DevOps"
        },
        {
            "tags": [
                "all-items",
                "bash",
                "example-code",
                "fcp",
                "github",
                "networking",
                "reference-architecture",
                "seodec18",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/hybrid-networking/shared-services.md",
            "http_url": "/azure/architecture/reference-architectures/hybrid-networking/shared-services",
            "word_count": 1473,
            "read_time": "6 min read",
            "Title": "Implement a hub-spoke network topology",
            "MetaDescription": "Learn how to implement shared services in a hub-spoke topology in Azure, building on another reference architecture for hub-spoke topology.",
            "category": [
                "hybrid",
                "networking",
                "developer-tools"
            ],
            "image": "/azure/architecture/reference-architectures/hybrid-networking/images/shared-services.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\hybrid-networking\\images\\shared-services.png",
            "publish_date": "8/19/2019",
            "sample_code": true,
            "github_url": "https://github.com/Azure/azure-quickstart-templates/tree/master/101-hub-and-spoke-sandbox",
            "visio_diagram": "https://arch-center.azureedge.net/hybrid-network-hub-spoke.vsdx",
            "code_languages": [
                "bash"
            ],
            "name": "shared-services",
            "popularity": 233,
            "topic": "Networking",
            "hybrid-topic": "Networking"
        },
        {
            "tags": [
                "all-items",
                "bash",
                "example-code",
                "github",
                "networking",
                "reference-architecture",
                "seodec18",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/dmz/secure-vnet-dmz.yml",
            "http_url": "/azure/architecture/reference-architectures/dmz/secure-vnet-dmz",
            "word_count": 2138,
            "read_time": "9 min read",
            "Title": "Implement a secure hybrid network",
            "MetaDescription": "See a secure hybrid network that extends an on-premises network to Azure with a perimeter network between the on-premises network and an Azure virtual network.",
            "category": [
                "networking",
                "security",
                "hybrid"
            ],
            "image": "/azure/architecture/reference-architectures/dmz/images/dmz-private.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\dmz\\images\\dmz-private.png",
            "publish_date": "1/07/2020",
            "sample_code": true,
            "github_url": "https://github.com/Azure/NetworkMonitoring/tree/master/AzureCT",
            "visio_diagram": "https://arch-center.azureedge.net/dmz-reference-architectures.vsdx",
            "code_languages": [
                "bash"
            ],
            "name": "secure-vnet-dmz",
            "popularity": 238,
            "topic": "Networking",
            "hybrid-topic": "Networking"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-website-content-tag-suggestion-with-deep-learning-and-nlp-'",
                "acom-architecture",
                "ai-ml",
                "all-items",
                "automated-manufacturing-solutions",
                "convolutional-neural-network",
                "decision-tree-algorithm",
                "discrete-manufacturing",
                "failure-detection",
                "gradient-boosting-decision-tree",
                "image-classification",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/website-content-tag-suggestion-with-deep-learning-and-nlp.md",
            "http_url": "/azure/architecture/solution-ideas/articles/website-content-tag-suggestion-with-deep-learning-and-nlp",
            "word_count": 391,
            "read_time": "2 min read",
            "Title": "Suggest content tags with deep learning and NLP",
            "MetaDescription": "See how deep learning and natural language processing can be used effectively with the Microsoft AI platform.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/website-content-tag-suggestion-with-deep-learning-and-nlp.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\website-content-tag-suggestion-with-deep-learning-and-nlp.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p>Microsoft SQL Server: Data is stored, structured, and indexed using Microsoft SQL Server.</p>",
                "<p>GPU based Azure Data Science Virtual Machine: The core development environment is the Microsoft Windows Server 2016 GPU DSVM NC24.</p>",
                "<p>Azure Machine Learning: Used for model training, including hyperparameter tuning, and deployment of the final model, including scaling out to a Kubernetes-managed Azure cluster.</p>",
                "<p>Jupyter Notebooks on Azure Data Science VM: Jupyter Notebooks is used as the base IDE for the model, which was developed in Python.</p>",
                "<p>Azure Container Registry: The Model Management Service creates and packages real-time web services as Docker containers. These containers are uploaded and registered via Azure Container Registry.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/kubernetes-service\">Azure Kubernetes Service (AKS)</a>: Deployment for this solution uses Azure Kubernetes Service running a Kubernetes-managed cluster. The containers are deployed from images stored in Azure Container Registry.</p>"
            ],
            "Summary": "<p>Social sites, forums, and other text-heavy Q&amp;A services rely heavily on tagging, which enables indexing and user search. Without appropriate tagging, these sites are far less effective. Often, however, tagging is left to the users' discretion. And since users don't have lists of commonly searched terms or a deep understanding of the categorization or information architecture of a site, posts are frequently mislabeled. This makes it difficult or impossible to find that content when it's needed later.</p>\n<p>By combining deep learning and natural language processing (NLP) with data on site-specific search terms, this solution helps greatly improve tagging accuracy on your site. As your user types their post, it offers highly used terms as suggested tags, making it easier for others to find the information they're providing.</p>",
            "name": "website-content-tag-suggestion-with-deep-learning-and-nlp",
            "popularity": 107,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-instant-broadcasting-on-serverless-architecture-'",
                "acom-architecture",
                "all-items",
                "data-flow",
                "interactive-diagram",
                "media",
                "serverless",
                "signalr-service",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/instant-broadcasting-on-serverless-architecture.md",
            "http_url": "/azure/architecture/solution-ideas/articles/instant-broadcasting-on-serverless-architecture",
            "word_count": 75,
            "read_time": "1 min read",
            "Title": "Instant Broadcasting on Serverless Architecture",
            "MetaDescription": "Simplify one-to-many real-time communication and updates using serverless code",
            "category": [
                "media",
                "developer-tools"
            ],
            "image": "/azure/architecture/solution-ideas/media/instant-broadcasting-on-serverless-architecture.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\instant-broadcasting-on-serverless-architecture.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Simplify one-to-many real-time communication and updates using serverless code.</p>",
            "Flow": {
                "FlowStep_A": "Client pulls web app content from blob storage",
                "FlowStep_B": "Web app receives SignalR token and endpoint",
                "FlowStep_C": "User connects to web app",
                "FlowStep_D": "Connection triggers database event via Functions",
                "FlowStep_E": "Functions pushes data to SignalR Service"
            },
            "name": "instant-broadcasting-on-serverless-architecture",
            "popularity": 77,
            "topic": "Media"
        },
        {
            "tags": [
                "acom-architecture",
                "all-items",
                "data-flow",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/aks-iot-data-streaming.md",
            "http_url": "/azure/architecture/solution-ideas/articles/aks-iot-data-streaming",
            "word_count": 433,
            "read_time": "2 min read",
            "Title": "Instant IoT data streaming with AKS",
            "MetaDescription": "Ingest and analyze high volumes of IoT data and generate real-time recommendations",
            "category": [
                "containers",
                "iot",
                "analytics"
            ],
            "image": "/azure/architecture/solution-ideas/media/aks-iot-data-streaming.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\aks-iot-data-streaming.png",
            "publish_date": "4/17/2020",
            "Summary": "",
            "Flow": {
                "FlowStep_A": "Sensor data is generated and streamed to Azure API Management",
                "FlowStep_B": "AKS cluster runs microservices that are deployed as containers behind a service mesh; containers are built using a DevOps process and stored in Azure Container Registry",
                "FlowStep_C": "Ingest service stores data in an Azure Cosmos DB",
                "FlowStep_D": "Asynchronously, the analysis service receives the data and streams it to Apache Kafka and Azure HDInsight",
                "FlowStep_E": "Data scientists can analyze the big data for use in machine learning models using Splunk",
                "FlowStep_F": "Data is processed by the processing service, which stores the result in Azure Database for PostgreSQL and caches the data in an Azure Cache for Redis",
                "FlowStep_G": "A web app running in Azure App Service is used to visualize the results"
            },
            "name": "aks-iot-data-streaming",
            "popularity": 0,
            "topic": "Containers"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "github",
                "identity",
                "reference-architecture",
                "seodec18",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/identity/azure-ad.yml",
            "http_url": "/azure/architecture/reference-architectures/identity/azure-ad",
            "word_count": 3359,
            "read_time": "13 min read",
            "Title": "Integrate on-premises AD domains with Azure AD",
            "MetaDescription": "Implement a secure hybrid network architecture using Azure Active Directory (Azure AD).",
            "category": [
                "identity",
                "hybrid"
            ],
            "image": "/azure/architecture/reference-architectures/identity/images/azure-ad.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\identity\\images\\azure-ad.png",
            "publish_date": "8/28/2019",
            "sample_code": true,
            "github_url": "https://github.com/mspnp/identity-reference-architectures/tree/master/azure-ad",
            "visio_diagram": "https://arch-center.azureedge.net/identity-architectures.vsdx",
            "name": "azure-ad",
            "popularity": 239,
            "topic": "Identity",
            "hybrid-topic": "Identity"
        },
        {
            "tags": [
                "all-items",
                "identity",
                "reference-architecture",
                "seodec18"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/identity/index.yml",
            "http_url": "/azure/architecture/reference-architectures/identity",
            "word_count": 939,
            "read_time": "4 min read",
            "Title": "Integrate on-premises AD with Azure",
            "MetaDescription": "Compare reference architectures for integrating on-premises Active Directory with Azure.",
            "category": [
                "identity",
                "hybrid"
            ],
            "image": "/azure/architecture/reference-architectures/identity/index.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\identity\\index.png",
            "publish_date": "7/30/2019",
            "name": "identity",
            "popularity": 239,
            "topic": "Identity",
            "hybrid-topic": "Identity"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-intelligent-apps-using-azure-database-for-mysql-'",
                "acom-architecture",
                "all-items",
                "app-dev",
                "azure",
                "mysql",
                "solution-idea",
                "solutions",
                "use-cases"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/intelligent-apps-using-azure-database-for-mysql.md",
            "http_url": "/azure/architecture/solution-ideas/articles/intelligent-apps-using-azure-database-for-mysql",
            "word_count": 36,
            "read_time": "1 min read",
            "Title": "Intelligent apps using Azure Database for MySQL",
            "MetaDescription": "Use Azure Database for MySQL to develop sophisticated machine learning and visualization apps for actionable insights and analytics.",
            "category": [
                "databases",
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/intelligent-apps-using-azure-database-for-mysql.svg",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\intelligent-apps-using-azure-database-for-mysql.svg",
            "publish_date": "12/16/2019",
            "Summary": "<p>Develop sophisticated, transformational apps using state of the art machine learning algorithms and integrated visualization tools to get actionable insights and analytics.</p>",
            "name": "intelligent-apps-using-azure-database-for-mysql",
            "popularity": 28,
            "topic": "Databases"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-intelligent-apps-using-azure-database-for-postgresql-'",
                "acom-architecture",
                "all-items",
                "app-dev",
                "azure",
                "postgresql",
                "solution-idea",
                "solutions",
                "use-cases"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/intelligent-apps-using-azure-database-for-postgresql.md",
            "http_url": "/azure/architecture/solution-ideas/articles/intelligent-apps-using-azure-database-for-postgresql",
            "word_count": 42,
            "read_time": "1 min read",
            "Title": "Intelligent apps using Azure Database for PostgreSQL",
            "MetaDescription": "Use Azure Database for PostgreSQL to develop sophisticated machine learning and visualization apps for actionable insights and analytics.",
            "category": [
                "databases",
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/intelligent-apps-using-azure-database-for-postgresql.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\intelligent-apps-using-azure-database-for-postgresql.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Develop sophisticated, transformational apps using state of the art machine learning algorithms and integrated visualization tools to get actionable insights and analytics.</p>",
            "name": "intelligent-apps-using-azure-database-for-postgresql",
            "popularity": 26,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "ecommerce",
                "example-code",
                "example-workload",
                "fasttrack",
                "github",
                "pricing-calculator",
                "pricing-guidance",
                "web-app"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/apps/ecommerce-search.yml",
            "http_url": "/azure/architecture/example-scenario/apps/ecommerce-search",
            "word_count": 1485,
            "read_time": "6 min read",
            "Title": "Intelligent product search engine for e-commerce",
            "MetaDescription": "This example scenario shows how using Azure Search can dramatically increase the relevance of search results for your e-commerce customers.",
            "category": [
                "web",
                "analytics"
            ],
            "image": "/azure/architecture/example-scenario/apps/media/architecture-ecommerce-search.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\apps\\media\\architecture-ecommerce-search.png",
            "publish_date": "9/14/2018",
            "pricing_calculator": "https://azure.com/e/db2672a55b6b4d768ef0060a8d9759bd",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/app-service/app-service-web-overview\">App Services - Web Apps</a> hosts web applications allowing autoscale and high availability without having to manage infrastructure.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/sql-database/sql-database-technical-overview\">SQL Database</a> is a general-purpose relational database-managed service in Microsoft Azure that supports structures such as relational data, JSON, spatial, and XML.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/search/search-what-is-azure-search\">Azure Search</a> is a search-as-a-service cloud solution that provides a rich search experience over private, heterogeneous content in web, mobile, and enterprise applications.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/bot-service\">Bot Service</a> provides tools to build, test, deploy, and manage intelligent bots.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/cognitive-services\">Cognitive Services</a> lets you use intelligent algorithms to see, hear, speak, understand, and interpret your user needs through natural methods of communication.</p>"
            ],
            "sample_code": true,
            "github_url": "https://github.com/Azure/fta-customerfacingapps/tree/master/ecommerce/articles",
            "name": "ecommerce-search",
            "popularity": 113,
            "topic": "Web"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-interactive-price-analytics-'",
                "acom-architecture",
                "ai-gallery",
                "all-items",
                "analytics",
                "artificial-intelligence",
                "azure",
                "example-code",
                "github",
                "solution-architectures",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/interactive-price-analytics.md",
            "http_url": "/azure/architecture/solution-ideas/articles/interactive-price-analytics",
            "word_count": 826,
            "read_time": "4 min read",
            "Title": "Interactive Price Analytics",
            "MetaDescription": "The Pricing Analytics solution uses your transactional history data to show you how the demand for your products responds to the prices you offer, to recommend pricing changes, and allow you to simulate how changes in price would affect your demand, at a fine granularity.",
            "category": [
                "analytics",
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/interactive-price-analytics.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\interactive-price-analytics.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>The Price Analytics solution uses your transactional history data to show you how the demand for your products responds to the prices you offer, to recommend pricing changes, and allow you to simulate how changes in price would affect your demand, at a fine granularity.</p>\n<p>The solution provides a dashboard, where you can see optimal pricing recommendations, item elasticities at a item-site-channel-segment level, estimates of related-product effects such \"as cannibalization\", forecasts given current process, and model performance metrics.</p>\n<p>Direct interaction with the pricing model in Excel lets you simply paste your sales data there and analyze your prices without the need to integrate the data into the solution database first, simulate promotions and plot demand curves (showing demand response to price), and access dashboard data in numerical form.</p>\n<p>The rich functionality is not confined to Excel. It is driven by web services that you, or your implementation partner, can call directly from your business applications, integrating price analysis into your business applications.</p>",
            "sample_code": true,
            "github_url": "https://github.com/Azure/cortana-intelligence-price-analytics/blob/master/User%20Guide/UserGuide.md",
            "name": "interactive-price-analytics",
            "popularity": 29,
            "topic": "Analytics"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-interactive-voice-response-bot-'",
                "acom-architecture",
                "ai-gallery",
                "all-items",
                "artificial-intelligence",
                "azure",
                "chatbot",
                "example-code",
                "github",
                "solution-architectures",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/interactive-voice-response-bot.md",
            "http_url": "/azure/architecture/solution-ideas/articles/interactive-voice-response-bot",
            "word_count": 485,
            "read_time": "3 min read",
            "Title": "Interactive voice response app with bot",
            "MetaDescription": "This solution creates an intelligent interactive voice response (IVR) application that processes customer order requests for bicycles and bicycle accessories. Businesses with no existing IVR solution can easily get started automating requests, or, where existing human-operated systems exist, this solution can be extended to incorporate existing functionality and workflows.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/interactive-voice-response-app-bot.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\interactive-voice-response-app-bot.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>This solution creates an intelligent interactive voice response (IVR) application that processes customer order requests for bicycles and bicycle accessories. Businesses with no existing IVR solution can easily get started automating requests, or, where existing human-operated systems exist, this solution can be extended to incorporate existing functionality and workflows.</p>",
            "sample_code": true,
            "github_url": "https://github.com/ujjwalmsft/cortana-intelligence-call-center-solution",
            "name": "interactive-voice-response-bot",
            "popularity": 71,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-interactive-querying-with-hdinsight-'",
                "acom-architecture",
                "all-items",
                "analytics",
                "data-factory",
                "data-lake-storage",
                "hdinsight",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/interactive-querying-with-hdinsight.md",
            "http_url": "/azure/architecture/solution-ideas/articles/interactive-querying-with-hdinsight",
            "word_count": 33,
            "read_time": "1 min read",
            "Title": "Interactive querying with HDInsight",
            "MetaDescription": "Perform fast, interactive SQL queries at scale over structured or unstructured data with Apache Hive LLAP.",
            "category": [
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/interactive-querying-with-hdinsight.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\interactive-querying-with-hdinsight.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Perform fast, interactive SQL queries at scale over structured or unstructured data with Apache Hive LLAP.</p>",
            "name": "interactive-querying-with-hdinsight",
            "popularity": 86,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "fcp",
                "iot",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/iot-connected-platform.md",
            "http_url": "/azure/architecture/solution-ideas/articles/iot-connected-platform",
            "word_count": 643,
            "read_time": "3 min read",
            "Title": "IoT Connected Platform for COVID-19 detection and prevention",
            "MetaDescription": "Deploy a connected ecosystem of intelligent IoT Edge devices, Azure services, and cloud-powered apps to create safe and healthy public spaces.",
            "category": [
                "iot"
            ],
            "image": "/azure/architecture/solution-ideas/media/insight-connected-platform.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\insight-connected-platform.png",
            "publish_date": "6/12/2020",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/iot-edge/\">Azure IoT Edge</a> intelligent devices recognize and respond to sensor input by using onboard processing. These devices can respond rapidly, or even offline. Intelligent Edge devices limit costs by preprocessing and sending only necessary data to the cloud.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/iot-hub/\">Azure IoT Hub</a> connects virtually any IoT device with Azure cloud services. IoT Hub enables highly secure and reliable bi-directional communication, management, and provisioning for IoT Edge devices.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/stream-analytics\">Azure Stream Analytics (ASA)</a> provides real-time serverless stream processing with built-in machine learning (ML) models to perform anomaly detection directly in streaming jobs.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage/data-lake-storage/\">Azure Data Lake Storage</a> is a data lake storage solution for big data analytics, combining <a href=\"https://azure.microsoft.com/services/storage/blobs/\">Azure Blob Storage</a> capabilities with a high-performance file system.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/databricks/\">Azure Databricks</a> is a fast, easy, and collaborative Apache Spark-based analytics service that can read and analyze data lake data.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cognitive-services/\">Azure Cognitive Services</a> are artificial intelligence (AI) services and cognitive APIs that help build intelligent apps. For example, <a href=\"https://azure.microsoft.com/services/cognitive-services/computer-vision/\">Computer Vision</a> helps count and monitor people density and movements. <a href=\"https://azure.microsoft.com/services/cognitive-services/speech-to-text/\">Speech to Text</a>, <a href=\"https://azure.microsoft.com/services/cognitive-services/text-to-speech/\">Text to Speech</a>, and <a href=\"https://azure.microsoft.com/services/cognitive-services/language-understanding-intelligent-service/\">Language Understanding</a> help provide verbal responses and interactions.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/kubernetes-service/\">Azure Kubernetes Service (AKS)</a> is a managed, serverless Kubernetes platform for microservices apps. Kubernetes is open-source orchestration software for deploying, managing, and scaling containerized apps.</p>",
                "<p>Azure <a href=\"https://azure.microsoft.com/services/api-management/\">API Management</a> deploys Azure, third-party, and external APIs side by side to optimize traffic flow, provide unified control and visibility, and ensure security and compliance.</p>",
                "<p><a href=\"https://powerbi.microsoft.com\">Microsoft Power BI</a> visualizations enable well-informed and data-driven reporting and decision making.</p>"
            ],
            "name": "iot-connected-platform",
            "popularity": 0,
            "topic": "Internet of Things"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "data-analytics",
                "data-flow",
                "example-workload",
                "iot",
                "pricing-guidance"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/data/big-data-with-iot.yml",
            "http_url": "/azure/architecture/example-scenario/data/big-data-with-iot",
            "word_count": 1199,
            "read_time": "5 min read",
            "Title": "IoT and data analytics",
            "MetaDescription": "Use IoT devices and data analytics to provide comprehensive management and operation of construction projects.",
            "category": [
                "iot",
                "analytics",
                "management-and-governance"
            ],
            "image": "/azure/architecture/example-scenario/data/media/architecture-big-data-with-iot.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\data\\media\\architecture-big-data-with-iot.png",
            "publish_date": "8/29/2018",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/iot-hub/about-iot-hub\">IoT Hub</a> acts as a central message hub for secure bi-directional communication with per-device identity between the cloud platform and the construction equipment and other site elements. IoT Hub can rapidly collect data for each device for ingestion into the data analytics pipeline.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/stream-analytics/stream-analytics-introduction\">Azure Stream Analytics</a> is an event-processing engine that can analyze high volumes of data streaming from devices and other data sources. It also supports extracting information from data streams to identify patterns and relationships. In this scenario, Stream Analytics ingests and analyzes data from IoT devices and stores the results in Azure SQL Database.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/sql-database/sql-database-technical-overview\">Azure SQL Database</a> contains the results of analyzed data from IoT devices and meters, which can be viewed by analysts and users via an Azure-based Web application.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/storage/blobs/storage-blobs-introduction\">Blob storage</a> stores image data gathered from the IoT hub devices. The image data can be viewed via the web application.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/traffic-manager/traffic-manager-overview\">Traffic Manager</a> controls the distribution of user traffic for service endpoints in different Azure regions.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/load-balancer/load-balancer-overview\">Load Balancer</a> distributes data submissions from construction equipment devices across the VM-based web services to provide high availability.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-machines\">Azure Virtual Machines</a> host the web services that receive and ingest the construction results data into the Apache Cassandra database.</p>",
                "<p><a href=\"https://cassandra.apache.org\">Apache Cassandra</a> is a distributed NoSQL database used to store construction data for later processing by Apache Spark.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/app-service/app-service-web-overview\">Web Apps</a> hosts the end-user web application, which can be used to query and view source data and images. Users can also initiate batch jobs in Apache Spark via the application.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/hdinsight/spark/apache-spark-overview\">Apache Spark on HDInsight</a> supports in-memory processing to boost the performance of big-data analytic applications. In this scenario, Spark is used to run complex algorithms over the data stored in Apache Cassandra.</p>"
            ],
            "Summary": "<p>This example scenario is relevant to organizations building solutions that integrate data from many IoT devices into a comprehensive data analysis architecture to improve and automate decision making. Potential applications include construction, mining, manufacturing, or other industry solutions involving large volumes of data from many IoT-based data inputs.</p>\n<p>In this scenario, a construction equipment manufacturer builds vehicles, meters, and drones that use IoT and GPS technologies to emit telemetry data. The company wants to modernize their data architecture to better monitor operating conditions and equipment health. Replacing the company's legacy solution using on-premises infrastructure would be both time intensive and labor intensive, and would not be able to scale sufficiently to handle the anticipated data volume.</p>\n<p>The company wants to build a cloud-based \"smart construction\" solution. It should gather a comprehensive set of data for a construction site and automate the operation and maintenance of the various elements of the site. The company's goals include:</p>\n<ul>\n<li>Integrating and analyzing all construction site equipment and data to minimize equipment downtime and reduce theft.</li>\n<li>Remotely and automatically controlling construction equipment to mitigate the effects of a labor shortage, ultimately requiring fewer workers and enabling lower-skilled workers to succeed.</li>\n<li>Minimizing the operating costs and labor requirements for the supporting infrastructure, while increasing productivity and safety.</li>\n<li>Easily scaling the infrastructure to support increases in telemetry data.</li>\n<li>Complying with all relevant legal requirements by provisioning resources in-country/region without compromising system availability.</li>\n<li>Using open-source software to maximize the investment in workers' current skills.</li>\n</ul>\n<p>Using managed Azure services such as IoT Hub and HDInsight will allow the customer to rapidly build and deploy a comprehensive solution with a lower operating cost. If you have additional data analytics needs, you should review the list of available <a href=\"https://azure.microsoft.com/product-categories/analytics\">fully managed data analytics services in Azure</a>.</p>",
            "Flow": {
                "FlowStep_A": "Construction equipment collects sensor data and sends the construction results data at regular intervals to load balanced web services hosted on a cluster of Azure virtual machines.",
                "FlowStep_B": "The custom web services ingest the construction results data and store it in an Apache Cassandra cluster also running on Azure virtual machines.",
                "FlowStep_C": "Another dataset is gathered by IoT sensors on various construction equipment and sent to IoT Hub.",
                "FlowStep_D": "Raw data collected is sent directly from IoT Hub to Azure blob storage and is immediately available for viewing and analysis.",
                "FlowStep_E": "Data collected via IoT Hub is processed in near real time by an Azure Stream Analytics job and stored in an Azure SQL database.",
                "FlowStep_F": "The Smart Construction Cloud web application is available to analysts and end users to view and analyze sensor data and imagery.",
                "FlowStep_G": "Batch jobs are initiated on demand by users of the web application. The batch job runs in Apache Spark on HDInsight and analyzes new data stored in the Cassandra cluster."
            },
            "name": "big-data-with-iot",
            "popularity": 131,
            "topic": "Internet of Things"
        },
        {
            "tags": [
                "all-items",
                "csharp",
                "example-code",
                "example-workload",
                "fcp"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/iot/cloud-to-device.md",
            "http_url": "/azure/architecture/example-scenario/iot/cloud-to-device",
            "word_count": 1057,
            "read_time": "5 min read",
            "Title": "IoT application-to-device commands",
            "MetaDescription": "Learn about how applications can use cloud-to-device messaging or direct methods to send commands to IoT devices.",
            "category": [
                "iot"
            ],
            "image": "/azure/architecture/example-scenario/iot/media/cloud-to-device-message.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\iot\\media\\cloud-to-device-message.png",
            "publish_date": "8/10/2020",
            "code_languages": [
                "csharp"
            ],
            "sample_code": true,
            "name": "cloud-to-device",
            "popularity": 0,
            "topic": "Internet of Things"
        },
        {
            "tags": [
                "all-items",
                "fcp",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/iot-power-management.md",
            "http_url": "/azure/architecture/solution-ideas/articles/iot-power-management",
            "word_count": 891,
            "read_time": "4 min read",
            "Title": "IoT connected light, power, and internet for emerging markets",
            "MetaDescription": "Learn how Veriown uses solar-powered IoT devices with Azure services to provide low-cost, clean power, light, and internet connectivity to remote customers.",
            "category": [
                "iot"
            ],
            "image": "/azure/architecture/solution-ideas/media/iot-power-architecture.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\iot-power-architecture.png",
            "publish_date": "8/17/2020",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/application-gateway/overview\">Azure Application Gateway</a> manages and load balances traffic to and from cloud web apps.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/aks/intro-kubernetes\">Azure Kubernetes Service (AKS)</a> hosts and simplifies <a href=\"https://kubernetes.io/\">Kubernetes</a> orchestration of <a href=\"https://www.docker.com/\">Docker</a> containerized apps.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/container-registry/container-registry-intro\">Azure Container Registry (ACR)</a> is a managed, private registry service that supports AKS applications at scale.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/iot-hub/about-iot-hub\">Azure IoT Hub</a> is a central cloud message hub for bi-directional communications between IoT applications and devices.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/databricks/scenarios/what-is-azure-databricks\">Azure Databricks</a> is a fast, easy, and collaborative <a href=\"https://spark.apache.org/\">Apache Spark</a>-based analytics service for big data pipelines.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/synapse-analytics/sql-data-warehouse/sql-data-warehouse-overview-what-is\">Azure Synapse Analytics</a>, formerly SQL Data Warehouse, is an analytics service that brings together enterprise data warehousing and big data analytics.</p>",
                "<p><a href=\"https://learn.microsoft.com/power-bi/fundamentals/power-bi-overview\">Power BI</a> is a collection of software services, apps, and connectors that turn data into coherent, immersive, interactive visualizations and reports.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/machine-learning/overview-what-is-azure-ml\">Azure Machine Learning</a> is a cloud-based ML environment that uses existing data to forecast future behaviors, outcomes, and trends.</p>"
            ],
            "name": "iot-power-management",
            "popularity": 0,
            "topic": "Internet of Things"
        },
        {
            "tags": [
                "all-items",
                "example-workload",
                "fcp"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/iot/devices-platform-application.md",
            "http_url": "/azure/architecture/example-scenario/iot/devices-platform-application",
            "word_count": 306,
            "read_time": "2 min read",
            "Title": "IoT solution architecture",
            "MetaDescription": "Understand the topological relationship between IoT devices, platform, and applications. Learn about Iot gateways, communications protocols, and provisioning.",
            "category": [
                "iot"
            ],
            "image": "/azure/architecture/example-scenario/iot/media/devices-platform-application.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\iot\\media\\devices-platform-application.png",
            "publish_date": "8/10/2020",
            "Summary": "<p>Topologically, Azure\u00a0Internet-of-Things (IoT) solutions are a collection of assets and components divided across <em>IoT devices</em>,\u00a0the <em>IoT platform</em>, and <em>IoT applications</em>.\u00a0<a >Events, insights, and actions</a>\u00a0are data flow and processing pipelines that occur\u00a0across these structural parts.</p>\n<p><img alt=\"A diagram showing the relationship between devices, the IoT platform, and an application.\" src=\"media/devices-platform-application.png\" /></p>\n<p>This article describes IoT device, platform, and application characteristics. The article also discusses IoT Edge gateways, and IoT platform attestation, authentication, protocols, and provisioning.</p>",
            "name": "devices-platform-application",
            "popularity": 0,
            "topic": "Internet of Things"
        },
        {
            "tags": [
                "all-items",
                "example-workload",
                "fcp"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/iot/introduction-to-solutions.md",
            "http_url": "/azure/architecture/example-scenario/iot/introduction-to-solutions",
            "word_count": 1116,
            "read_time": "5 min read",
            "Title": "IoT solutions conceptual overview",
            "MetaDescription": "Get an overview of the functional interactions between events, insights, and actions in Azure Internet of Things (IoT) solutions.",
            "category": [
                "iot"
            ],
            "image": "/azure/architecture/example-scenario/iot/media/devices-events-insights.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\iot\\media\\devices-events-insights.png",
            "publish_date": "8/10/2020",
            "Summary": "<p>Connected sensors, devices, and intelligent operations can transform businesses and enable new growth\u00a0opportunities with <a href=\"https://azure.microsoft.com/overview/iot/\">Azure Internet of Things (IoT)</a> solutions.\u00a0This content complements existing <a href=\"https://learn.microsoft.com/azure/iot-fundamentals\">Azure IoT documentation</a> with concepts and patterns to consider when designing and developing IoT solutions.</p>\n<p>Azure\u00a0<em>IoT solutions</em> involve <em>events</em> that generate <em>insights</em> to inform <em>actions</em> that improve a business or process. IoT solutions use events, insights, and actions to connect devices, or things, to cloud applications and achieve end-to-end scenarios. The terms <em>thing</em> and <em>device</em> both mean a connected physical device in an IoT solution.</p>\n<p><img alt=\"A diagram showing devices generating events, which inform insights and actions.\" src=\"media/devices-events-insights.png\" />\u00a0</p>\n<p>Events, insights, and actions are functional concepts that exist across the <a >devices, platform, and applications</a> of an IoT solution. To illustrate, consider an application that monitors cooling system temperatures for food storage, and calls emergency maintenance services if a temperature becomes dangerously low or high:</p>\n<p><img alt=\"A diagram illustrating the relationship between events, insights, and actions in an IoT solution used to monitor a food storage system.\" src=\"media/events-insights-actions.png\" /></p>\n<p>The cooling system sends operating temperatures as telemetry to a connected application through <a href=\"https://learn.microsoft.com/azure/iot-hub/about-iot-hub\">Azure IoT Hub</a>. Backup systems exist in case a primary cooling system malfunctions or goes offline. Devices can receive commands to adjust temperature or start and stop operation.</p>\n<p>The following process occurs in this example:</p>\n<ol>\n<li><strong>Devices send events.</strong> Devices send temperature samples from the primary cooling system to the application's IoT Hub, via device-to-cloud events, every 30 seconds. </li>\n<li><strong>Events generate insights.</strong> Routing rules in the IoT Hub evaluate events for any immediate contextual insights, such as temperatures at malfunctioning levels.</li>\n<li><strong>Insights inform actions.</strong> If the temperature is at a malfunctioning level, event routing sends the event to a specific handler to take action. The handler invokes an action to another process to dispatch maintenance to the site, and sends a command to the backup system to start while maintenance is enroute to the location.</li>\n</ol>\n<p>Considering events, insights, and actions allows expansion of the cooling system monitoring scenario. The system can add more complex insights and actions by using the events from the cooling system devices:</p>\n<p><img alt=\"A diagram illustrating the events, insights, and actions associated with the cooling system monitoring scenario.\" src=\"media/events-downstream.png\" /></p>\n<p>While the series of events doesn't change, gathering events and applying different types of insights to the events enables taking additional actions with the data. This strategy becomes more powerful when applied to large numbers of devices operating at multiple locations.</p>",
            "name": "introduction-to-solutions",
            "popularity": 0,
            "topic": "Internet of Things"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-iot-using-cosmos-db-'",
                "acom-architecture",
                "all-items",
                "alternative-choices",
                "cosmos-db",
                "data-flow",
                "iot",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/iot-using-cosmos-db.md",
            "http_url": "/azure/architecture/solution-ideas/articles/iot-using-cosmos-db",
            "word_count": 1253,
            "read_time": "5 min read",
            "Title": "IoT using Azure Cosmos DB",
            "MetaDescription": "Scale instantly and elastically to accommodate diverse and unpredictable IoT workloads without sacrificing ingestion or query performance.",
            "category": [
                "iot",
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/iot-using-cosmos-db.svg",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\iot-using-cosmos-db.svg",
            "publish_date": "3/23/2020",
            "alternative_choices": "alternatives",
            "Summary": "<p>Scale instantly and elastically to accommodate diverse and unpredictable IoT workloads without sacrificing ingestion or query performance.</p>\n<p>Azure Cosmos DB is Microsoft\u2019s globally distributed, multi-model database. Azure Cosmos DB was built from the ground up with global distribution and horizontal scale at its core. It offers turnkey global distribution across any number of Azure regions by transparently scaling and replicating your data wherever your users are. You can elastically scale throughput and storage worldwide, and pay only for the throughput and storage you need.</p>\n<p>Azure Cosmos DB is ideally suited for IoT solutions. Azure Cosmos DB can ingest device telemetry data at high rates and can serve indexed queries back with low latency and high availability.</p>\n<p>Azure Cosmos DB is a multi-model database with wire protocol\u2013compatible API endpoints for Cassandra, MongoDB, SQL, Gremlin, Etcd, and Table along with built-in support for Jupyter Notebook files.</p>",
            "Flow": {
                "FlowStep_A": "Events generated from IoT devices are sent to the analyze and transform layer through Azure IoT Hub as a stream of messages. Azure IoT Hub stores streams of data in partitions for a configurable amount of time.",
                "FlowStep_B": "Azure Databricks, running Apache Spark Streaming, picks up the messages in real time from IoT Hub, processes the data based on the business logic and sends the data to Serving layer for storage. Spark Streaming can provide real time analytics such as calculating moving averages, min and max values over time periods.",
                "FlowStep_C": "Device messages are stored in Azure Cosmos DB as JSON documents. This is considered the **hot data store**. Different JSON schemas representing different device vendors can be stored in Azure Cosmos DB or converted to a canonical JSON schema.",
                "FlowStep_D": "The storage layer consists of:",
                "FlowStep_E": "Microsoft Power BI can be used by your users to analyze warehoused data.",
                "FlowStep_F": "Web, mobile and other applications can be built on the storage layer. For example, you can expose APIs based on the storage layer data for third-party uses.",
                "FlowStep_G": "Use Azure Cosmos DB change feed to execute an Azure function each time a device message is added or updated in Azure Cosmos DB.",
                "FlowStep_H": "Some device messages (for example, a fault code) may require an action to be performed on the device. Using the Azure IoT Hub Service API, the Azure Function can connect to Azure IoT Hub and perform an action on the device (for example, reboot) using either:"
            },
            "name": "iot-using-cosmos-db",
            "popularity": 121,
            "topic": "Internet of Things"
        },
        {
            "tags": [
                "all-items",
                "cse",
                "example-code",
                "example-workload",
                "fcp",
                "github"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/banking/jmeter-load-testing-pipeline-implementation-reference.md",
            "http_url": "/azure/architecture/example-scenario/banking/jmeter-load-testing-pipeline-implementation-reference",
            "word_count": 687,
            "read_time": "3 min read",
            "Title": "JMeter implementation reference for load testing pipeline solution",
            "MetaDescription": "Scalable cloud load testing pipeline creates and destroys infrastructure on-demand for stress testing.",
            "category": [
                "devops"
            ],
            "image": "/azure/architecture/example-scenario/banking/images/load-testing-pipeline-jmeter.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\banking\\images\\load-testing-pipeline-jmeter.png",
            "publish_date": "8/11/2020",
            "components": [
                "<p>Azure</p>",
                "<p><a href=\"https://azure.microsoft.com/services/devops/pipelines/\">Azure Pipelines</a></p>",
                "<p><a href=\"https://azure.microsoft.com/services/container-registry/\">Azure Container Registry (ACR)</a></p>",
                "<p><a href=\"https://azure.microsoft.com/services/container-instances/\">Azure Container Instances (ACI)</a></p>",
                "<p>Open-source</p>",
                "<p><a href=\"https://jmeter.apache.org/\">Apache JMeter</a></p>",
                "<p><a href=\"https://www.terraform.io/\">Terraform</a></p>"
            ],
            "Summary": "<p>This article provides an overview of an implementation for a scalable cloud load testing pipeline. The testing pipeline does a lot to carry out stress testing:</p>\n<ul>\n<li>\n<p>Creates infrastructure on-demand</p>\n</li>\n<li>\n<p>Deploys the infrastructure</p>\n</li>\n<li>\n<p>Executes testing</p>\n</li>\n<li>\n<p>Reports results</p>\n</li>\n<li>\n<p>Destroys infrastructure on-demand</p>\n</li>\n</ul>\n<p>The implementation uses <a >banking system cloud transformation solution</a>.</p>\n<p>This implementation enables the following capabilities:</p>\n<ul>\n<li>\n<p>Viewing combined data in a dashboard to monitor the scalability and performance of a solution infrastructure.</p>\n</li>\n<li>\n<p>The ability to determine:</p>\n</li>\n<li>\n<p>The impact of infrastructure scalability.</p>\n</li>\n<li>\n<p>The reaction to failures in the existing architectural design and various workloads.</p>\n</li>\n</ul>\n<p>The CSE team made these determinations by observing a set of simulations. They ran functional scenarios in the simulations and monitored the performance and scalability of the infrastructure.</p>\n<ul>\n<li>Supports any system that exposes a JMeter supported endpoint. For example: Azure Container Instances (ACI), Azure Kubernetes Service (AKS), and so on. Carries out pod/node autoscaling and performance tests on all services.</li>\n</ul>\n<p>The implementation also supports:</p>\n<ul>\n<li>\n<p>Executing performance tests over the microservices until the solution reaches or surpasses a target of a set number of transactions per second.</p>\n</li>\n<li>\n<p>Executing horizontal pod/node autoscaling tests over microservices.</p>\n</li>\n<li>\n<p>Providing observability on specific solution component(s) by activating metrics captured (for example, with Prometheus and Grafana).</p>\n</li>\n<li>\n<p>Providing a detailed report about the tests executed, the applications' behavior and the partitioning strategies adopted where applicable (for example, Kafka).</p>\n</li>\n</ul>\n<p>This implementation provides the following advantages:</p>\n<ul>\n<li>\n<p>Full integration with Azure.</p>\n</li>\n<li>\n<p>Alternative to other proprietary/deprecating solutions.</p>\n</li>\n<li>\n<p>Fully open-source.</p>\n</li>\n</ul>",
            "sample_code": true,
            "github_url": "https://github.com/Azure-Samples/jmeter-aci-terraform",
            "name": "jmeter-load-testing-pipeline-implementation-reference",
            "popularity": 0,
            "topic": "DevOps"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-java-cicd-using-jenkins-and-azure-web-apps-'",
                "acom-architecture",
                "all-items",
                "ci-cd",
                "continuous-delivery",
                "continuous-deployment",
                "continuous-integration",
                "data-flow",
                "devops",
                "interactive-diagram",
                "is-deployable",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/java-cicd-using-jenkins-and-azure-web-apps.md",
            "http_url": "/azure/architecture/solution-ideas/articles/java-cicd-using-jenkins-and-azure-web-apps",
            "word_count": 282,
            "read_time": "2 min read",
            "Title": "Java CI/CD using Jenkins and Azure Web Apps",
            "MetaDescription": "Azure App Service is a fast and simple way to create web apps using Java, Node, PHP or ASP.NET, as well as support for custom language runtimes using Docker. A continuous integration and continuous deployment (CI/CD) pipeline that pushes each of your changes automatically to Azure app services allows you to deliver value faster to your customers.",
            "category": [
                "devops",
                "web",
                "containers"
            ],
            "image": "/azure/architecture/solution-ideas/media/java-cicd-using-jenkins-and-azure-web-apps.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\java-cicd-using-jenkins-and-azure-web-apps.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/app-service/web\">Azure Web Apps</a>: Quickly create and deploy mission critical Web apps at scale</p>",
                "<p><a href=\"https://azure.microsoft.com/services/container-instances\">Container Instances</a>: Easily run containers on Azure without managing servers</p>",
                "<p><a href=\"https://azure.microsoft.com/services/mysql\">Azure Database for MySQL</a>: Managed MySQL database service for app developers</p>",
                "<p>Application Insights: Detect, triage, and diagnose issues in your web apps and services</p>",
                "<p><a href=\"https://azure.microsoft.com/services/devops\">Azure DevOps</a>: Build and deploy multi-platform apps to get the most from Azure services</p>"
            ],
            "Flow": {
                "FlowStep_A": "Change application source code",
                "FlowStep_B": "Commit code to GitHub",
                "FlowStep_C": "Continuous Integration Trigger to Jenkins",
                "FlowStep_D": "Jenkins triggers a build job using Azure Container Instances for a dynamic build agent",
                "FlowStep_E": "Jenkins builds and stores artifact in Azure Storage",
                "FlowStep_F": "Jenkins deploys Java application to Azure Web Apps backed by Azure Database for MySQL",
                "FlowStep_G": "Azure App Insights provides metrics on application performance",
                "FlowStep_H": "Monitor application and make improvements"
            },
            "name": "java-cicd-using-jenkins-and-azure-web-apps",
            "popularity": 74,
            "topic": "DevOps"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-digital-media-speech-text-'",
                "acom-architecture",
                "all-items",
                "solution-idea",
                "speech"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/digital-media-speech-text.md",
            "http_url": "/azure/architecture/solution-ideas/articles/digital-media-speech-text",
            "word_count": 465,
            "read_time": "2 min read",
            "Title": "Keyword search/speech-to-text/OCR digital media",
            "MetaDescription": "A speech-to-text solution allows you to identify speech in static video files so you can manage it as standard content, such as allowing employees to search within training videos for spoken words or phrases, and then enabling them to quickly navigate to the specific moment in the video.",
            "category": [
                "ai-machine-learning",
                "media"
            ],
            "image": "/azure/architecture/solution-ideas/media/digital-media-speech-text.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\digital-media-speech-text.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p>Stores large amounts of unstructured data, such as text or binary data, that can be accessed from anywhere in the world via HTTP or HTTPS. You can use <a href=\"https://azure.microsoft.com/services/storage/blobs\">Blob storage</a> to expose data publicly to the world, or to store application data privately.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/media-services/encoding\">Azure encoding</a>: Encoding jobs are one of the most common processing operations in Media Services. You create encoding jobs to convert media files from one encoding to another.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/media-services/live-on-demand\">Azure streaming endpoint</a>: Represents a streaming service that can deliver content directly to a client player application, or to a content delivery network (CDN) for further distribution.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cdn\">Content Delivery Network</a>: Provides secure, reliable content delivery with broad global reach and a rich feature set.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/media-services/media-player\">Azure Media Player</a>: Uses industry standards, such as HTML5 (MSE/EME) to provide an enriched adaptive streaming experience. Regardless of the playback technology used, developers have a unified JavaScript interface to access APIs.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/search\">Azure Cognitive Search</a>: Delegates search-as-a-service server and infrastructure management to Microsoft, leaving you with a ready-to-use service that you can populate with your data, and then use to add search to your web or mobile application.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/app-service/web\">Web Apps</a>: Hosts the website or web application.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/media-services/media-indexer\">Azure Media Indexer</a>: Enables you to make the content of your media files searchable and to generate a full-text transcript for closed-captioning and keywords. You can process one media file or multiple media files in a batch.</p>"
            ],
            "name": "digital-media-speech-text",
            "popularity": 27,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-migrate-existing-applications-with-aks-'",
                "acom-architecture",
                "all-items",
                "app-dev",
                "chat",
                "data-flow",
                "devops",
                "interactive-diagram",
                "signalr-service",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/migrate-existing-applications-with-aks.md",
            "http_url": "/azure/architecture/solution-ideas/articles/migrate-existing-applications-with-aks",
            "word_count": 138,
            "read_time": "1 min read",
            "Title": "Lift and shift to containers with AKS",
            "MetaDescription": "Lift and shift to containers with AKS",
            "category": [
                "migration",
                "containers"
            ],
            "image": "/azure/architecture/solution-ideas/media/migrate-existing-applications-with-aks.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\migrate-existing-applications-with-aks.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Easily migrate existing application to container(s) and run within the Azure managed Kubernetes service (AKS). Control access via integration with Azure Active Directory and access SLA-backed Azure Services such as Azure Database for MySQL using OSBA (Open Service Broker for Azure) for your data needs.</p>",
            "Flow": {
                "FlowStep_A": "User converts existing application to container(s) &amp; publishes container image(s)to the Azure Container Registry",
                "FlowStep_B": "Using Azure Portal or command line, user deploys containers to AKS cluster",
                "FlowStep_C": "Azure Active Directory is used to control access to AKS resources",
                "FlowStep_D": "Easily access SLA-backed Azure Services such as Azure Database for MySQL using OSBA (Open Service Broker for Azure)"
            },
            "name": "migrate-existing-applications-with-aks",
            "popularity": 137,
            "topic": "Migration"
        },
        {
            "tags": [
                "all-items",
                "data-flow",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/lob.md",
            "http_url": "/azure/architecture/solution-ideas/articles/lob",
            "word_count": 313,
            "read_time": "2 min read",
            "Title": "Line of Business Extension",
            "MetaDescription": "This example shows how you can modernize your legacy systems that cannot support new processes and provide better user experience.",
            "category": [
                "mobile",
                "functions"
            ],
            "image": "/azure/architecture/solution-ideas/media/lob.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\lob.png",
            "publish_date": "8/24/2020",
            "Summary": "",
            "Flow": {
                "FlowStep_A": "Supplier data stored in CDS is moved to SQL via Data Factory.",
                "FlowStep_B": "Purchase order (PO) data stored in ERP system is sent to Azure SQL database.",
                "FlowStep_C": "Azure Functions uses API to surface PO data monthly and creates a task for user to review.",
                "FlowStep_D": "Power Apps retrieves data from Azure SQL Database through API.",
                "FlowStep_E": "User reviews and updates POs in Power Apps and sends this data to suppliers through CSV export.",
                "FlowStep_F": "Power BI reports trends in supplier status."
            },
            "name": "lob",
            "popularity": 0,
            "topic": "Mobile"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "example-code",
                "example-workload",
                "fasttrack",
                "github",
                "hpc",
                "linux",
                "pricing-guidance"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/infrastructure/linux-vdi-citrix.yml",
            "http_url": "/azure/architecture/example-scenario/infrastructure/linux-vdi-citrix",
            "word_count": 1293,
            "read_time": "5 min read",
            "Title": "Linux virtual desktops with Citrix",
            "MetaDescription": "Learn about Virtual Desktop Infrastructure. This example uses a Citrix-based solution for Linux desktops on Azure.",
            "category": [
                "compute"
            ],
            "image": "/azure/architecture/example-scenario/infrastructure/media/azure-citrix-sample-diagram.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\infrastructure\\media\\azure-citrix-sample-diagram.png",
            "publish_date": "9/12/2018",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-network/virtual-networks-overview\">Azure Virtual Network</a> allows resources such as VMs to securely communicate with each other, the internet, and on-premises networks. Virtual networks provide isolation and segmentation, filter and route traffic, and allow connection between locations. One virtual network will be used for all resources in this scenario.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-network/security-overview\">Network security groups</a> contain a list of security rules that allow or deny inbound or outbound network traffic based on source or destination IP address, port, and protocol. The virtual networks in this scenario are secured with network security group rules that restrict the flow of traffic between the application components.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/application-gateway/overview\">Azure Load Balancer</a> distributes inbound traffic according to rules and health probes. A load balancer provides low latency and high throughput, and scales up to millions of flows for all TCP and UDP applications. An internal load balancer is used in this scenario to distribute traffic on the Citrix NetScaler.</p>",
                "<p><a >Azure Hybrid File Sync</a> will be used for all shared storage. The storage will replicate to two file servers using Hybrid File Sync.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/sql-database/sql-database-technical-overview\">Azure SQL Database</a> is a managed relational database service based on the latest stable version of the Microsoft SQL Server Database Engine. In this example, it is used to host Citrix databases.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/expressroute/expressroute-introduction\">ExpressRoute</a> lets you extend your on-premises networks into the Microsoft cloud over a private connection facilitated by a connectivity provider.</p>",
                "<p><a href=\"https://learn.microsoft.com/windows-server/identity/ad-ds/get-started/virtual-dc/active-directory-domain-services-overview\">Active Directory Domain Services</a> is used for Directory Services and user authentication.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-machines/windows/tutorial-availability-sets\">Azure Availability Sets</a> will ensure that the VMs you deploy on Azure are distributed across multiple isolated hardware nodes in a cluster. Doing this ensures that if a hardware or software failure within Azure happens, only a subset of your VMs are affected and that your overall solution remains available and operational.</p>",
                "<p><a href=\"https://www.citrix.com/products/citrix-adc\">Citrix ADC (NetScaler)</a> is an application delivery controller that performs application-specific traffic analysis to intelligently distribute, optimize, and secure Layer 4-Layer 7 (L4\u2013L7) network traffic for web applications.</p>",
                "<p><a href=\"https://www.citrix.com/products/citrix-virtual-apps-and-desktops/citrix-storefront.html\">Citrix Storefront</a> is an enterprise app store that improves security and simplifies deployments, delivering a modern, unmatched near-native user experience across Citrix Receiver on any platform. StoreFront makes it easy to manage multi-site and multi-version Citrix Virtual Apps and Desktops environments.</p>",
                "<p><a href=\"https://www.citrix.com/buy/licensing/overview.html\">Citrix License Server</a> will manage the licenses for Citrix products.</p>",
                "<p><a href=\"https://docs.citrix.com/en-us/citrix-virtual-apps-desktops-service\">Citrix XenDesktops VDA</a> enables connections to applications and desktops. The VDA is installed on the machine that runs the applications or virtual desktops for the user. It enables the machines to register with Delivery Controllers and manage the High Definition eXperience (HDX) connection to a user device.</p>",
                "<p><a href=\"https://docs.citrix.com/en-us/xenapp-and-xendesktop/7-15-ltsr/manage-deployment/delivery-controllers\">Citrix Delivery Controller</a> is the server-side component responsible for managing user access, plus brokering and optimizing connections. Controllers also provide the Machine Creation Services that create desktop and server images.</p>"
            ],
            "Summary": "<p>This example scenario is applicable to any industry that needs a Virtual Desktop Infrastructure (VDI) for Linux Desktops. VDI refers to the process of running a user desktop inside a virtual machine that lives on a server in the datacenter. The customer in this scenario chose to use a Citrix-based solution for their VDI needs.</p>\n<p>Organizations often have heterogeneous environments with multiple devices and operating systems being used by employees. It can be challenging to provide consistent access to applications while maintaining a secure environment. A VDI solution for Linux desktops will allow your organization to provide access irrespective of the device or OS used by the end user.</p>\n<p>Some benefits of this scenario include the following:</p>\n<ul>\n<li>Return on investment will be higher with shared Linux virtual desktops by giving more users access to the same infrastructure. By consolidating resources on a centralized VDI environment, the end user devices don't need to be as powerful.</li>\n<li>Performance will be consistent regardless of the end user device.</li>\n<li>Users can access Linux applications from any device (including non-Linux devices).</li>\n<li>Sensitive data can be secured in the Azure datacenter for all distributed employees.</li>\n</ul>",
            "sample_code": true,
            "github_url": "https://github.com/MicrosoftDocs/azure-docs/edit/master/articles/storage/files/storage-sync-files-planning.md",
            "name": "linux-vdi-citrix",
            "popularity": 132,
            "topic": "Compute"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-digital-media-live-stream-'",
                "acom-architecture",
                "all-items",
                "media",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/digital-media-live-stream.md",
            "http_url": "/azure/architecture/solution-ideas/articles/digital-media-live-stream",
            "word_count": 415,
            "read_time": "2 min read",
            "Title": "Live streaming digital media",
            "MetaDescription": "A live streaming solution allows you to capture video in real-time and broadcast it to consumers in real time, such as streaming interviews, conferences, and sporting events online.",
            "category": [
                "media"
            ],
            "image": "/azure/architecture/solution-ideas/media/digital-media-live-stream.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\digital-media-live-stream.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/media-services/latest/become-on-premises-encoder-partner\">Partner on-premises live encoder</a>: Outputs the live source for ingest into the cloud as RTMP, MPEG-Transport Stream, or fragmented mp4 formats.</p>",
                "<p>Stores large amounts of unstructured data, such as text or binary data, that can be accessed from anywhere in the world via HTTP or HTTPS. You can use <a href=\"https://azure.microsoft.com/services/storage/blobs\">Blob storage</a> to expose data publicly to the world, or to store application data privately.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/media-services\">Media Services</a>: Provides the ability to ingest, encode, preview, store, and deliver your live streaming content. Channels, programs, and streaming endpoints handle the live streaming functions, including ingestion, formatting, DVR, security, scalability, and redundancy.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/media-services/live-on-demand\">Azure streaming endpoint</a>: Represents a streaming service that can deliver content directly to a client player application, or to a content delivery network (CDN) for further distribution.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cdn\">Content Delivery Network</a>: Provides secure, reliable content delivery with broad global reach and a rich feature set.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/media-services/media-player\">Azure Media Player</a>: Uses industry standards such as HTML5 (MSE/EME) to provide an enriched adaptive streaming experience. Regardless of the playback technology used, developers have a unified JavaScript interface to access APIs.</p>",
                "<p><a href=\"https://learn.microsoft.com/api/Redirect/documentation/articles/web-sites-monitor\">Preview monitoring</a>: Provides the ability to preview and validate a live stream before further processing and delivery.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/media-services/content-protection\">Multi-DRM content protection</a>: Delivers content securely using multi-DRM (PlayReady, Widevine, FairPlay Streaming) or AES clear key encryption.</p>"
            ],
            "Summary": "<p>A live streaming solution allows you to capture video in real-time and broadcast it to consumers in real time, such as streaming interviews, conferences, and sporting events online. In this solution, video is captured by a video camera and sent to a channel input endpoint. The channel receives the live input stream and makes it available for streaming through a streaming endpoint to a web browser or mobile app. The channel also provides a preview monitoring endpoint to preview and validate your stream before further processing and delivery. The channel can also record and store the ingested content in order to be streamed later (video-on-demand).</p>\n<p>This solution is built on the Azure managed services: <a href=\"https://azure.microsoft.com/services/media-services\">Media Services</a> and <a href=\"https://azure.microsoft.com/services/cdn\">Content Delivery Network</a>. These services run in a high-availability environment, patched and supported, allowing you to focus on your solution instead of the environment they run in.</p>",
            "name": "digital-media-live-stream",
            "popularity": 115,
            "topic": "Media"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-loan-chargeoff-prediction-with-azure-hdinsight-spark-clusters-'",
                "acom-architecture",
                "ai-gallery",
                "all-items",
                "artificial-intelligence",
                "azure",
                "finance",
                "solution-architectures",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/loan-chargeoff-prediction-with-azure-hdinsight-spark-clusters.md",
            "http_url": "/azure/architecture/solution-ideas/articles/loan-chargeoff-prediction-with-azure-hdinsight-spark-clusters",
            "word_count": 782,
            "read_time": "4 min read",
            "Title": "Loan ChargeOff Prediction with Azure HDInsight Spark Clusters",
            "MetaDescription": "Using Azure HDInsight R Server, a lending institution can leverage machine learning predictive analytics to predict the likelihood of loans getting charged off and run a report on the analytics result stored in HDFS and hive tables.",
            "category": [
                "databases",
                "analytics"
            ],
            "image": "/azure/architecture/solution-ideas/media/loan-chargeoff-prediction-with-azure-hdinsight-spark-clusters.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\loan-chargeoff-prediction-with-azure-hdinsight-spark-clusters.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>A charged off loan is a loan that is declared by a creditor (usually a lending institution) that an amount of debt is unlikely to be collected, usually when the loan repayment is severely delinquent by the debtor. Given that high chargeoff has negative impact on lending institutions' year end financials, lending institutions often monitor loan chargeoff risk very closely to prevent loans from getting charged-off. Using Azure HDInsight R Server, a lending institution can use machine learning predictive analytics to predict the likelihood of loans getting charged off and run a report on the analytics result stored in HDFS and hive tables.</p>",
            "name": "loan-chargeoff-prediction-with-azure-hdinsight-spark-clusters",
            "popularity": 10,
            "topic": "Databases"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-loan-chargeoff-prediction-with-sql-server-'",
                "acom-architecture",
                "ai-gallery",
                "all-items",
                "artificial-intelligence",
                "azure",
                "finance",
                "pricing-guidance",
                "solution-architectures",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/loan-chargeoff-prediction-with-sql-server.md",
            "http_url": "/azure/architecture/solution-ideas/articles/loan-chargeoff-prediction-with-sql-server",
            "word_count": 653,
            "read_time": "3 min read",
            "Title": "Loan ChargeOff Prediction with SQL Server",
            "MetaDescription": "This solution demonstrates how to build and deploy a machine learning model with SQL Server 2016 with R Services to predict if a Bank loan will need to be charged off within next 3 months",
            "category": [
                "databases",
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/loan-chargeoff-prediction-with-sql-server.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\loan-chargeoff-prediction-with-sql-server.png",
            "publish_date": "12/16/2019",
            "pricing_guidance": "pricing",
            "Summary": "<p>This solution demonstrates how to build and deploy a machine learning model with SQL Server 2016 with R Services to predict if a Bank loan will need to be charged off within next 3 months.</p>",
            "name": "loan-chargeoff-prediction-with-sql-server",
            "popularity": 8,
            "topic": "Databases"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-loan-credit-risk-analyzer-and-default-modeling-'",
                "acom-architecture",
                "all-items",
                "analytics",
                "credit-risk-analyzer",
                "credit-risk-modeling",
                "finance",
                "probability-of-default",
                "solution-idea",
                "sql-server"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/loan-credit-risk-analyzer-and-default-modeling.md",
            "http_url": "/azure/architecture/solution-ideas/articles/loan-credit-risk-analyzer-and-default-modeling",
            "word_count": 241,
            "read_time": "2 min read",
            "Title": "Loan Credit Risk + Default Modeling",
            "MetaDescription": "Using SQL Server 2016 with R Services, lenders can predict a borrower's credit risk and default probability to help issue fewer unprofitable loans.",
            "category": [
                "databases",
                "analytics"
            ],
            "image": "/azure/architecture/solution-ideas/media/loan-credit-risk-analyzer-and-default-modeling.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\loan-credit-risk-analyzer-and-default-modeling.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/sql/machine-learning/r/sql-server-r-services?view=sql-server-2016\">SQL Server R Services</a>: SQL Server stores the lender and borrower data. R-based analytics provide training and predicted models, as well as predicted results for consumption.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/machine-learning-studio\">Machine Learning Studio</a>: Machine Learning helps you easily design, test, operationalize, and manage predictive analytics solutions in the cloud.</p>",
                "<p><a href=\"https://powerbi.microsoft.com\">Power BI</a> provides an interactive dashboard with visualization that uses data stored in SQL Server to drive decisions on the predictions.</p>"
            ],
            "name": "loan-credit-risk-analyzer-and-default-modeling",
            "popularity": 88,
            "topic": "Databases"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-loan-credit-risk-with-sql-server-'",
                "acom-architecture",
                "ai-gallery",
                "all-items",
                "analytics",
                "artificial-intelligence",
                "azure",
                "finance",
                "pricing-guidance",
                "solution-architectures",
                "solution-idea",
                "sql-server"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/loan-credit-risk-with-sql-server.md",
            "http_url": "/azure/architecture/solution-ideas/articles/loan-credit-risk-with-sql-server",
            "word_count": 510,
            "read_time": "3 min read",
            "Title": "Loan Credit Risk with SQL Server",
            "MetaDescription": "Using SQL Server 2016 with R Services, a lending institution can make use of predictive analytics to reduce number of loans they offer to those borrowers most likely to default, increasing the profitability of their loan portfolio.",
            "category": [
                "databases",
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/loan-credit-risk-with-sql-server.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\loan-credit-risk-with-sql-server.png",
            "publish_date": "12/16/2019",
            "pricing_guidance": "pricing",
            "Summary": "<p>Using SQL Server 2016 with R Services, a lending institution can make use of predictive analytics to reduce number of loans they offer to those borrowers most likely to default, increasing the profitability of their loan portfolio.</p>",
            "name": "loan-credit-risk-with-sql-server",
            "popularity": 19,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "azcat-ai",
                "example-code",
                "github",
                "reference-architecture",
                "yaml"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/ai/mlops-python.md",
            "http_url": "/azure/architecture/reference-architectures/ai/mlops-python",
            "word_count": 1840,
            "read_time": "8 min read",
            "Title": "MLOps for Python models using Azure Machine Learning",
            "MetaDescription": "Implement continuous integration (CI), continuous delivery (CD), and retraining for Azure Machine Learning.",
            "category": [
                "ai-machine-learning",
                "devops",
                "featured"
            ],
            "image": "/azure/architecture/reference-architectures/ai/_images/ml-ops-python.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\ai\\_images\\ml-ops-python.png",
            "publish_date": "5/09/2019",
            "sample_code": true,
            "github_url": "https://github.com/microsoft/MLOpsPython/blob/master/docs/getting_started.md",
            "code_languages": [
                "yaml"
            ],
            "name": "mlops-python",
            "popularity": 164,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "all-items",
                "cse",
                "example-workload",
                "fcp"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/mlops/mlops-maturity-model.md",
            "http_url": "/azure/architecture/example-scenario/mlops/mlops-maturity-model",
            "word_count": 449,
            "read_time": "2 min read",
            "Title": "Machine Learning Operations maturity model",
            "MetaDescription": "Detailed explanation of the MLOps maturity model stages and defining characteristics of each stage.",
            "category": [
                "developer-tools",
                "hybrid"
            ],
            "image": "/azure/architecture/_images/reference-architectures.svg",
            "publish_date": "7/07/2020",
            "Summary": "<p>The purpose of this maturity model is to help clarify the Machine Learning Operations (MLOps) principles and practices. The maturity model shows the continuous improvement in the creation and operation of a production level machine learning application environment. You can use it as a metric for establishing the progressive requirements needed to measure the maturity of a machine learning production environment and its associated processes.</p>",
            "name": "mlops-maturity-model",
            "popularity": 0,
            "topic": "Developer Tools",
            "hybrid-topic": "Apps"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-machine-learning-model-deployment-aks-'",
                "acom-architecture",
                "ai-ml",
                "all-items",
                "chat",
                "data-flow",
                "devops",
                "interactive-diagram",
                "microservices",
                "signalr-service",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/machine-learning-model-deployment-aks.md",
            "http_url": "/azure/architecture/solution-ideas/articles/machine-learning-model-deployment-aks",
            "word_count": 138,
            "read_time": "1 min read",
            "Title": "Machine Learning model training with AKS",
            "MetaDescription": "Machine Learning with AKS",
            "category": [
                "ai-machine-learning",
                "containers"
            ],
            "image": "/azure/architecture/solution-ideas/media/machine-learning-model-deployment-to-aks.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\machine-learning-model-deployment-to-aks.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Deploy machine learning models on Azure Kubernetes Service (AKS) for high-scale production inference. Use familiar tools such as Kubeflow to simplify deployment of Machine Learning models. Your ML models will run in AKS clusters backed by GPU enabled VMs.</p>",
            "Flow": {
                "FlowStep_A": "Package ML model into a container and publish to ACR",
                "FlowStep_B": "Azure Blob storage hosts training data sets and trained model",
                "FlowStep_C": "Use Kubeflow to deploy training job to AKS, distributed training job to AKS includes Parameter servers and Worker nodes",
                "FlowStep_D": "Serve production model using Kubeflow, promoting a consistent environment across test, control and production",
                "FlowStep_E": "AKS supports GPU enabled VM"
            },
            "name": "machine-learning-model-deployment-aks",
            "popularity": 91,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "all-items",
                "cse",
                "example-code",
                "example-workload",
                "fcp",
                "github"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/mlops/mlops-technical-paper.md",
            "http_url": "/azure/architecture/example-scenario/mlops/mlops-technical-paper",
            "word_count": 6545,
            "read_time": "26 min read",
            "Title": "Machine learning operations (MLOps) framework to upscale machine learning Lifecycle with Azure Machine Learning",
            "MetaDescription": "How the machine learning operations (MLOps) maturity model was applied to implement a machine learning solution for predicting product shipping levels.",
            "category": [
                "developer-tools",
                "hybrid"
            ],
            "image": "/azure/architecture/example-scenario/mlops/media/data-sciene-lifecycle-model-flow.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\mlops\\media\\data-sciene-lifecycle-model-flow.png",
            "publish_date": "6/01/2020",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/machine-learning/\">Azure Machine Learning Service</a></p>",
                "<p><a href=\"https://learn.microsoft.com/azure/machine-learning/concept-compute-instance\">Azure Machine Learning Compute</a></p>",
                "<p><a href=\"https://learn.microsoft.com/azure/machine-learning/concept-ml-pipelines\">Azure Machine Learning Pipelines</a></p>"
            ],
            "sample_code": true,
            "github_url": "https://github.com/Microsoft/MLOpsPython",
            "name": "mlops-technical-paper",
            "popularity": 0,
            "topic": "Developer Tools",
            "hybrid-topic": "Apps"
        },
        {
            "tags": [
                "all-items",
                "data-flow",
                "example-code",
                "github",
                "pcp",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/machine-teaching.md",
            "http_url": "/azure/architecture/solution-ideas/articles/machine-teaching",
            "word_count": 5380,
            "read_time": "22 min read",
            "Title": "Machine teaching",
            "MetaDescription": "Learn how machine teaching incorporates artificial intelligence, machine learning, deep reinforcement learning, and subject matter expertise.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/machine-teaching-1-4.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\machine-teaching-1-4.png",
            "publish_date": "7/05/2020",
            "Summary": "<p>Artificial intelligence (AI) and machine learning (ML) offer unique opportunities and challenges for operations that span the virtual and physical worlds. AI and ML can recognize correlations between real-world input data and outcomes and make decisions that automate complex physical industrial systems. But AI machine learning systems can't perform higher-level cognitive functions like exploration, improvisation, creative thinking, or determination of causation.</p>\n<p><em>Machine teaching</em> is a new paradigm for machine learning systems that:\n- Infuses <em>subject matter expertise</em> into automated AI systems models.\n- Uses <a href=\"#reinforcement-learning\">deep reinforcement learning</a> to identify patterns in the learning process and adopt positive behaviors in its own methods.\n- Leverages <a href=\"#simulations\">simulated environments</a> to generate large amounts of synthetic data for domain-specific use cases and scenarios.</p>\n<p>Machine learning focuses on developing novel learning algorithms or improving existing algorithms. Machine teaching focuses on the efficacy of the teachers themselves. Abstracting away AI complexity to focus on subject matter expertise and real-world conditions creates powerful AI and ML models that turn automated control systems into <em>autonomous systems</em>.</p>",
            "Flow": {
                "FlowStep_A": "The problem owner collects and labels datasets, or assembles a label guideline so the labeling task can be outsourced.",
                "FlowStep_B": "The problem owner reviews the labels until their quality is satisfactory.",
                "FlowStep_C": "Machine-learning experts select an algorithm, model architecture, objective function, regularizers, and cross-validation sets.",
                "FlowStep_D": "Engineers train the model cyclically, adjusting the features or creating new features to improve model accuracy and speed.",
                "FlowStep_E": "The model is tested on a small sample. If the system doesn't do well in the test, the preceding steps are repeated.",
                "FlowStep_F": "Model performance is monitored in the field. If performance falls below a critical level, the model is modified by repeating the preceding steps.",
                "FlowStep_G": "The teacher first questions whether a training set is realizable.",
                "FlowStep_H": "If the training set isn't realizable, the teacher determines whether the issue is due to inadequate labeling or feature deficiencies. After correcting the labeling or adding features, the teacher again assesses whether the training set is realizable.",
                "FlowStep_I": "If the training set is realizable, the teacher assesses whether training quality criteria are being met.",
                "FlowStep_J": "If quality criteria aren't being met, the teacher finds the test errors and adds the fixes to the training set, then repeats the assessment steps.",
                "FlowStep_K": "Once the training set is realizable and quality criteria are met, the process finishes."
            },
            "sample_code": true,
            "github_url": "https://github.com/Microsoft/AirSim",
            "name": "machine-teaching",
            "popularity": 0,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "github",
                "pcp",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/autonomous-systems.md",
            "http_url": "/azure/architecture/solution-ideas/articles/autonomous-systems",
            "word_count": 1500,
            "read_time": "7 min read",
            "Title": "Machine teaching with the Microsoft Autonomous Systems platform",
            "MetaDescription": "Learn how the Microsoft Autonomous Systems platform uses machine teaching, deep reinforcement learning, and simulations to build and deploy autonomous systems with Bonsai.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/machine-teaching-1-2.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\machine-teaching-1-2.png",
            "publish_date": "7/05/2020",
            "Summary": "<p>Artificial intelligence (AI) and machine learning (ML) offer unique opportunities and challenges for automating complex industrial systems. <em>Machine teaching</em> is a new paradigm for building ML systems that moves the focus away from algorithms and onto successful model generation and deployment.</p>\n<p>Machine teaching infuses subject matter expertise into automated AI system training with <em>deep reinforcement learning (DRL)</em> and <em>simulations</em>. Abstracting away AI complexity to focus on subject matter expertise and real-world conditions creates models that turn automated control systems into <em>autonomous systems</em>.</p>\n<p>Autonomous systems:</p>\n<ul>\n<li>Combine human domain knowledge with AI and ML through machine teaching.</li>\n<li>Automate generation and management of DRL algorithms and models.</li>\n<li>Integrate simulations for model optimization and scalability during training.</li>\n<li>Deploy and scale for real-world use.</li>\n</ul>\n<p>The <a href=\"https://www.microsoft.com/ai/autonomous-systems-platform\">Microsoft Autonomous Systems platform</a> is an innovative framework for building, training, and deploying models by using machine teaching and simulations. Use the Autonomous Systems platform to help automate systems when:</p>\n<ul>\n<li>Existing control systems are fragile when deployed.</li>\n<li>ML logic doesn't adequately cover all scenarios.</li>\n<li>Describing the desired system behavior requires subject matter experts who understand the problem domain.</li>\n<li>Generating sufficient real-world data to cover all scenarios is difficult or impossible.</li>\n<li>Traditional control systems are difficult to deploy and scale to the real world.</li>\n</ul>\n<p>Machine teaching bridges AI science and software with traditional engineering and domain expertise. Example applications include motion control, machine calibration, smart buildings, industrial robotics, and process control.</p>",
            "sample_code": true,
            "github_url": "https://github.com/microsoft/AirSim/blob/master/azure/azure-env-creation/vm-arm-template.json",
            "name": "autonomous-systems",
            "popularity": 0,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "all-items",
                "fcp",
                "reference-architecture",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "hybrid/azure-arc-hybrid-config.md",
            "http_url": "/azure/architecture/hybrid/azure-arc-hybrid-config",
            "word_count": 1685,
            "read_time": "7 min read",
            "Title": "Manage configurations for Azure Arc enabled servers",
            "MetaDescription": "Use Azure Arc to extend Azure Resource Manager capabilities to Windows and Linux machines on any infrastructure.",
            "category": [
                "hybrid",
                "management-and-governance"
            ],
            "image": "/azure/architecture/hybrid/images/azure-arc-hybrid-config.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\hybrid\\images\\azure-arc-hybrid-config.png",
            "publish_date": "7/28/2020",
            "Summary": "<p>This reference architecture illustrates how Azure Arc enables you to manage, govern, and secure servers across on-premises, multiple cloud, and edge scenarios.</p>\n<p><img alt=\"An Azure Arc hybrid server topology diagram with Arc enabled servers connected to Azure.\" src=\"https://learn.microsoft.com/azure/architecture/hybrid/images/azure-arc-hybrid-config.png\" /></p>\n<p><em>Download a <a href=\"https://arch-center.azureedge.net/azure-arc-hybrid-config.vsdx\">Visio file</a> of this architecture.</em></p>\n<p>Typical uses for this architecture include:</p>\n<ul>\n<li>Organize, govern, and inventory large groups of virtual machines (VMs) and servers across multiple environments.</li>\n<li>Enforce organization standards and assess compliance at scale for all your resources anywhere with Azure Policy.</li>\n<li>Easily deploy extensions to Azure VMs and Arc enabled servers.</li>\n<li>Configure and enforce Azure Policy for VMs and servers hosted across multiple environments.</li>\n</ul>",
            "visio_diagram": "https://arch-center.azureedge.net/azure-arc-hybrid-config.vsdx",
            "name": "azure-arc-hybrid-config",
            "popularity": 0,
            "topic": "Management and Governance",
            "hybrid-topic": "Management"
        },
        {
            "tags": [
                "all-items",
                "fcp",
                "reference-architecture",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "hybrid/hybrid-server-os-mgmt.md",
            "http_url": "/azure/architecture/hybrid/hybrid-server-os-mgmt",
            "word_count": 2851,
            "read_time": "11 min read",
            "Title": "Manage hybrid Azure workloads using Windows Admin Center",
            "MetaDescription": "Deploy Windows Admin Center to manage environments on-premises and in Azure.",
            "category": [
                "hybrid",
                "management-and-governance"
            ],
            "image": "/azure/architecture/hybrid/images/hybrid-server-os-mgmt-wac-azure.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\hybrid\\images\\hybrid-server-os-mgmt-wac-azure.png",
            "publish_date": "7/29/2020",
            "Summary": "<p>This reference architecture illustrates how to design a hybrid Windows Admin Center solution to manage workloads that are hosted on-premises and in Microsoft Azure. This architecture includes two scenarios:</p>\n<ul>\n<li>Windows Admin Center deployed to a virtual machine (VM) in Azure.</li>\n<li>Windows Admin Center deployed to a server (physical or virtual) on-premises.</li>\n</ul>\n<p>The first diagram illustrates Windows Admin Center deployed to a VM in Azure.</p>\n<p><img alt=\"Deploy Windows Admin Center to a VM in Azure. Use VPN or ExpressRoute to manage on-premises VMs.\" src=\"https://learn.microsoft.com/azure/architecture/hybrid/images/hybrid-server-os-mgmt-wac-azure.png\" /></p>\n<p>The second diagram illustrates Windows Admin Center deployed on-premises.</p>\n<p><img alt=\"Deploy Windows Admin Center to a VM on-premises. Use Azure network adapter to integrate with resources in Azure.\" src=\"https://learn.microsoft.com/azure/architecture/hybrid/images/hybrid-server-os-mgmt-wac-onprem.png\" /></p>\n<p><em>Download a <a href=\"https://arch-center.azureedge.net/hybrid-server-os-mgmt.vsdx\">Visio file</a> of these architectures.</em></p>\n<p>Typical uses for this architecture include:</p>\n<ul>\n<li>Organizations that want to manage individual Windows Server instances, Hyper-Converged Infrastructure or Hyper-V VMs that run on-premises and in Microsoft Azure.</li>\n<li>Organizations that want to manage Windows Server instances hosted by other cloud providers.</li>\n</ul>",
            "visio_diagram": "https://arch-center.azureedge.net/hybrid-server-os-mgmt.vsdx",
            "name": "hybrid-server-os-mgmt",
            "popularity": 0,
            "topic": "Management and Governance",
            "hybrid-topic": "Management"
        },
        {
            "tags": [
                "ai",
                "all-items",
                "alternative-choices",
                "azcat-ai",
                "data-flow",
                "example-code",
                "example-workload",
                "github",
                "pricing-guidance"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/ai/news-feed-ingestion-and-near-real-time-analysis.md",
            "http_url": "/azure/architecture/example-scenario/ai/news-feed-ingestion-and-near-real-time-analysis",
            "word_count": 1334,
            "read_time": "5 min read",
            "Title": "Mass ingestion and analysis of news feeds on Azure",
            "MetaDescription": "Create a pipeline for ingesting and analyzing text, images, sentiment, and other data from RSS news feeds using only Azure services, including Azure Cosmos DB and Azure Cognitive Services.",
            "category": [
                "analytics",
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/example-scenario/ai/media/mass-ingestion-newsfeeds-architecture.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\ai\\media\\mass-ingestion-newsfeeds-architecture.png",
            "publish_date": "2/01/2019",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "Summary": "<p>This example scenario describes a pipeline for mass ingestion and near real-time analysis of documents using public RSS news feeds.  It uses Azure Cognitive Services to offer useful insights including text translation, facial recognition, and sentiment detection.</p>\n<p>This scenario contains examples for <a href=\"https://www.nasa.gov/rss/dyn/breaking_news.rss\">English</a>, <a href=\"http://government.ru/all/rss\">Russian</a>, and <a href=\"http://www.bamf.de/SiteGlobals/Functions/RSS/DE/Feed/RSSNewsfeed_Meldungen\">German</a> news feeds, but you can easily extend it to other RSS feeds. For ease of deployment, the data collection, processing, and analysis are based entirely on Azure services.</p>",
            "Flow": {
                "FlowStep_A": "An RSS news feed acts as the generator that obtains data from a document or article. For example, with an article, data typically includes a title, a summary of the original body of the news item, and sometimes images.",
                "FlowStep_B": "A generator or ingestion process inserts the article and any associated images into an Azure Cosmos DB [Collection][collection].",
                "FlowStep_C": "A notification triggers an ingest function in Azure Functions that stores the article text in Azure Cosmos DB and the article images (if any) in Azure Blob Storage.  The article is then passed to the next queue.",
                "FlowStep_D": "A translate function is triggered by the queue event. It uses the [Translate Text API][translate-text] of Azure Cognitive Services to detect the language, translate if necessary, and collect the sentiment, key phrases, and entities from the body and the title. Then it passes the article to the next queue.",
                "FlowStep_E": "A detect function is triggered from the queued article. It uses the [Computer Vision][vision] service to detect objects, landmarks, and written words in the associated image, then passes the article to the next queue.",
                "FlowStep_F": "A face function is triggered is triggered from the queued article. It uses the [Azure Face API][face] service to detect faces for gender and age in the associated image, then passes the article to the next queue.",
                "FlowStep_G": "When all functions are complete, the notify function is triggered. It loads the processed records for the article and scans them for any results you want. If found, the content is flagged and a notification is sent to the system of your choice."
            },
            "sample_code": true,
            "github_url": "https://github.com/Azure/cognitive-services",
            "name": "news-feed-ingestion-and-near-real-time-analysis",
            "popularity": 69,
            "topic": "Analytics"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-medical-data-storage-'",
                "acom-architecture",
                "all-items",
                "cloud-storage-in-healthcare",
                "data",
                "data-flow",
                "healthcare-data-storage",
                "interactive-diagram",
                "medical-data-solutions",
                "medical-data-storage",
                "medical-records-management",
                "medical-records-storage",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/medical-data-storage.md",
            "http_url": "/azure/architecture/solution-ideas/articles/medical-data-storage",
            "word_count": 325,
            "read_time": "2 min read",
            "Title": "Medical Data Storage Solutions",
            "MetaDescription": "Store healthcare data effectively and affordably with cloud-based solutions from Azure. Manage medical records with the highest level of built-in security.",
            "category": [
                "storage"
            ],
            "image": "/azure/architecture/solution-ideas/media/medical-data-storage.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\medical-data-storage.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/data-factory\">Data Factory</a>: Hybrid data integration at enterprise scale, made easy</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage/data-lake-storage\">Data Lake Storage</a>: Hyperscale repository for big data analytics workloads</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cognitive-services\">Cognitive Services</a>: Add smart API capabilities to enable contextual interactions</p>",
                "<p><a href=\"https://azure.microsoft.com/services/app-service/web\">Web Apps</a>: Quickly create and deploy mission critical web apps at scale</p>",
                "<p><a href=\"https://azure.microsoft.com/services/security-center\">Security Center</a>: Unify security management and enable advanced threat protection across hybrid cloud workloads</p>",
                "<p><a href=\"https://azure.microsoft.com/services/active-directory\">Azure Active Directory</a>: Synchronize on-premises directories and enable single sign-on</p>",
                "<p><a href=\"https://azure.microsoft.com/services/key-vault\">Key Vault</a>: Safeguard and maintain control of keys and other secrets</p>",
                "<p>Application Insights: Detect, triage, and diagnose issues in your web apps and services</p>",
                "<p><a href=\"https://azure.microsoft.com/services/monitor\">Azure Monitor</a>: Full observability into your applications, infrastructure, and network</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/machine-learning\">Machine Learning</a>: Easily build, deploy, and manage predictive analytics solutions</p>",
                "<p><a href=\"https://azure.microsoft.com/services/power-bi-embedded\">Power BI Embedded</a>: Embed fully interactive, stunning data visualizations in your applications</p>"
            ],
            "Summary": "<p>Cloud and hybrid solutions from Microsoft help you manage medical data storage efficiently and cost effectively, while infusing intelligence and maintaining compliance.</p>",
            "Flow": {
                "FlowStep_A": "Securely ingest medical image data using Azure Data Factory.",
                "FlowStep_B": "Securely store medical image data in Azure Data Lake Store and/or Azure Blob Storage.",
                "FlowStep_C": "Analyze medical image data using a pre-trained Azure Cognitive Services API or a custom developed Machine Learning model.",
                "FlowStep_D": "Store artificial intelligence (AI) and Machine Learning results in Azure Data Lake.",
                "FlowStep_E": "Interact AI and Machine Learning results using PowerBI, while preserving Role-Based Access Control (RBAC).",
                "FlowStep_F": "Securely interact with medical image data via a web based vendor neutral archive (VNA) image viewer."
            },
            "name": "medical-data-storage",
            "popularity": 92,
            "topic": "Storage"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-messaging-'",
                "acom-architecture",
                "all-items",
                "app-dev",
                "data",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/messaging.md",
            "http_url": "/azure/architecture/solution-ideas/articles/messaging",
            "word_count": 39,
            "read_time": "1 min read",
            "Title": "Messaging",
            "MetaDescription": "azure redis cache, web sockets, web communication frameworks, messaging publish and subscribe, azure cache for redis",
            "category": [
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/messaging.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\messaging.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Azure Cache for Redis supports standard publish and subscribe functionalities. It's ideal for routing real-time messages and scaling up web communication frameworks such as SignalR.</p>",
            "name": "messaging",
            "popularity": 48,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "github",
                "microservices",
                "reference-architecture",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/containers/aks-microservices/aks-microservices.yml",
            "http_url": "/azure/architecture/reference-architectures/containers/aks-microservices/aks-microservices",
            "word_count": 4228,
            "read_time": "17 min read",
            "Title": "Microservices architecture on Azure Kubernetes Service (AKS)",
            "MetaDescription": "Deploy a microservices architecture on Azure Kubernetes Service (AKS)",
            "category": [
                "containers"
            ],
            "image": "/azure/architecture/reference-architectures/containers/aks-microservices/images/aks.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\containers\\aks-microservices\\images\\aks.png",
            "publish_date": "5/07/2020",
            "sample_code": true,
            "github_url": "https://github.com/Azure/aad-pod-identity",
            "visio_diagram": "https://arch-center.azureedge.net/aks-reference-architecture.vsdx",
            "name": "aks-microservices",
            "popularity": 0,
            "topic": "Containers"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "github",
                "microservices",
                "reference-architecture",
                "xml"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/microservices/service-fabric.yml",
            "http_url": "/azure/architecture/reference-architectures/microservices/service-fabric",
            "word_count": 5601,
            "read_time": "22 min read",
            "Title": "Microservices architecture on Azure Service Fabric",
            "MetaDescription": "Use this reference architecture to see microservices deployed to Azure Service Fabric. This cluster configuration can be a starting point for most deployments.",
            "category": [
                "developer-tools"
            ],
            "image": "/azure/architecture/reference-architectures/microservices/_images/ra-sf-arch.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\microservices\\_images\\ra-sf-arch.png",
            "publish_date": "6/13/2019",
            "Summary": "<p>This reference architecture shows a microservices architecture deployed to Azure Service Fabric. It shows a basic cluster configuration that can be the starting point for most deployments.</p>\n<p><img alt=\"GitHub logo\" src=\"https://learn.microsoft.com/azure/architecture/_images/github.png\" /> A reference implementation of this architecture is available on <a href=\"https://github.com/mspnp/microservices-reference-implementation-servicefabric\">GitHub</a>.</p>\n<p><img alt=\"Service Fabric reference architecture\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/microservices/_images/ra-sf-arch.png\" /></p>\n<blockquote>\n<p>[!NOTE]\nThis article focuses on the <a href=\"https://learn.microsoft.com/azure/service-fabric/service-fabric-reliable-services-introduction\">Reliable Services</a> programming model for Service Fabric. Using Service Fabric to deploy and manage <a href=\"https://learn.microsoft.com/azure/service-fabric/service-fabric-containers-overview\">containers</a> is beyond the scope of this article.</p>\n</blockquote>",
            "sample_code": true,
            "github_url": "https://github.com/App-vNext/Polly",
            "code_languages": [
                "xml"
            ],
            "name": "service-fabric",
            "popularity": 216,
            "topic": "Developer Tools"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-microservices-with-aks-'",
                "acom-architecture",
                "all-items",
                "data-flow",
                "devops",
                "interactive-diagram",
                "kubernetes",
                "microservices",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/microservices-with-aks.md",
            "http_url": "/azure/architecture/solution-ideas/articles/microservices-with-aks",
            "word_count": 121,
            "read_time": "1 min read",
            "Title": "Microservices with AKS",
            "MetaDescription": "Microservices with AKS",
            "category": [
                "containers",
                "devops",
                "developer-tools"
            ],
            "image": "/azure/architecture/solution-ideas/media/microservices-with-aks.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\microservices-with-aks.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Use AKS to simplify the deployment and management of microservices based architecture. AKS streamlines horizontal scaling, self-healing, load balancing, secret management.</p>",
            "Flow": {
                "FlowStep_A": "Developer uses IDE such as Visual Studio to commit changes to GitHub",
                "FlowStep_B": "GitHub triggers a new build on Azure DevOps",
                "FlowStep_C": "Azure DevOps packages microservices as containers and pushes them to the Azure Container Registry",
                "FlowStep_D": "Containers are deployed to AKS cluster",
                "FlowStep_E": "Users access services via apps and website",
                "FlowStep_F": "Azure Active Directory is used to secure access to the resources",
                "FlowStep_G": "Microservices use databases to store and retrieve information"
            },
            "name": "microservices-with-aks",
            "popularity": 153,
            "topic": "Containers"
        },
        {
            "tags": [
                "all-items",
                "fcp",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/migrate-mainframe-apps-with-tmaxsoft-openframe.md",
            "http_url": "/azure/architecture/solution-ideas/articles/migrate-mainframe-apps-with-tmaxsoft-openframe",
            "word_count": 1396,
            "read_time": "5 min read",
            "Title": "Migrate IBM mainframe applications to Azure with TmaxSoft OpenFrame",
            "MetaDescription": "Find out how to migrate IBM zSeries mainframe applications to Azure. Learn how to use TmaxSoft OpenFrame for this task. Understand the lift and shift approach.",
            "category": [
                "mainframe",
                "migration"
            ],
            "image": "/azure/architecture/solution-ideas/media/migrate-mainframe-application-to-azure.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\migrate-mainframe-application-to-azure.png",
            "publish_date": "9/18/2020",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/expressroute/expressroute-introduction\">Azure ExpressRoute</a> extends on-premises networks into the Microsoft cloud. By using a connectivity provider, ExpressRoute establishes private connections to Microsoft cloud services like <a href=\"https://azure.microsoft.com/overview/what-is-azure/\">Microsoft Azure</a> and <a href=\"https://www.microsoft.com/microsoft-365/what-is-microsoft-365?rtc=1\">Microsoft 365</a>.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/bastion/bastion-overview\">Azure VM Bastion</a> provides secure and seamless <a href=\"https://learn.microsoft.com/troubleshoot/windows-server/remote/understanding-remote-desktop-protocol\">Remote Desktop Protocol (RDP)</a> and <a href=\"https://www.ssh.com/ssh/\">Secure Shell (SSH)</a> connectivity to VMs in a network. Instead of using a public IP address, users connect to the VMs directly from the Azure portal.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/load-balancer/load-balancer-overview\">Azure Load Balancer</a> operates at layer four of the <a href=\"https://www.networkworld.com/article/3239677/the-osi-model-explained-how-to-understand-and-remember-the-7-layer-network-model.html\">Open Systems Interconnection (OSI)</a> model. As the single point of contact for clients, Load Balancer distributes inbound traffic to back-end pool instances. It directs traffic according to configured load-balancing rules and health probes. The back-end pool instances can be Azure VMs or instances in a virtual machine scale set.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/virtual-machines/\">Azure VMs</a> are one of several types of on-demand, scalable computing resources that are available with Azure. An Azure VM provides the flexibility of virtualization. But it eliminates the maintenance demands of physical hardware. Azure VMs offer a choice of operating systems, including Windows and Linux.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-network/virtual-networks-overview\">Azure Virtual Networks</a> are the fundamental building blocks for private networks in Azure. These networks provide a way for many types of Azure resources, such as Azure VMs, to securely communicate with each other, the internet, and on-premises networks. An Azure virtual network is like a traditional network operating in a data center. But an Azure virtual network also provides scalability, availability, isolation, and other benefits of Azure's infrastructure.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/storage/files/storage-files-introduction\">Azure Files Storage Accounts and Azure File Shares</a> are fully managed file shares in the cloud. Azure file shares are accessible via the industry standard <a href=\"https://learn.microsoft.com/openspecs/windows_protocols/ms-smb/f210069c-7086-4dc2-885e-861d837df688\">Server Message Block (SMB)</a> protocol. They can be mounted concurrently by cloud or on-premises deployments. Windows, Linux, and macOS clients can access these file shares.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/sql-database/\">Azure SQL Database</a> is an intelligent, scalable relational database service built for the cloud. With AI-powered, automated features, Azure SQL Database handles database management functions like upgrading, patching, backups, and monitoring.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/site-recovery/\">Azure Site Recovery</a> provides replication, failover, and recovery processes to help keep applications running during outages.</p>"
            ],
            "Summary": "<p>TmaxSoft OpenFrame is a rehosting solution that makes it easy to lift existing IBM zSeries mainframe applications and shift them to Microsoft Azure. This lift-and-shift operation uses a no-code approach. TmaxSoft quickly migrates an existing application, as is, to a zSeries mainframe emulation environment on Azure.</p>\n<p>This reference architecture illustrates how the TmaxSoft OpenFrame solution runs on Azure. The approach consists of two virtual machines (VMs) running Linux in an <a href=\"https://www.webopedia.com/TERM/A/active_active.html\">active-active</a> configuration. An Azure Load Balancer distributes incoming traffic between the VMs. OpenFrame emulation software runs on the VMs and provides a zSeries runtime and facilities. Working with the OpenFrame software is an Azure SQL Database. This modernized database layer includes built-in business continuity features.</p>",
            "name": "migrate-mainframe-apps-with-tmaxsoft-openframe",
            "popularity": 0,
            "topic": "Migration"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "app-modernization",
                "example-workload",
                "fasttrack",
                "pricing-calculator",
                "pricing-guidance",
                "web-apps"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/apps/apim-api-scenario.yml",
            "http_url": "/azure/architecture/example-scenario/apps/apim-api-scenario",
            "word_count": 1081,
            "read_time": "5 min read",
            "Title": "Migrate a web app using Azure APIM",
            "MetaDescription": "In this scenario, an e-commerce company in the travel industry migrates a legacy web application by using Azure API Management.",
            "category": [
                "web",
                "migration",
                "integration"
            ],
            "image": "/azure/architecture/example-scenario/apps/media/architecture-apim-api-scenario.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\apps\\media\\architecture-apim-api-scenario.png",
            "publish_date": "9/13/2018",
            "pricing_calculator": "https://azure.com/e/0e916a861fac464db61342d378cc0bd6",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "name": "apim-api-scenario",
            "popularity": 178,
            "topic": "Web"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-modern-customer-support-portal-powered-by-an-agile-business-process-'",
                "acom-architecture",
                "all-items",
                "cloud-innovation",
                "cloud-migration",
                "data-flow",
                "interactive-diagram",
                "lift-and-shift-cloud-strategy",
                "lift-and-shift-solution",
                "lift-and-shift-strategy",
                "line-of-business-app",
                "lob-app",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/modern-customer-support-portal-powered-by-an-agile-business-process.md",
            "http_url": "/azure/architecture/solution-ideas/articles/modern-customer-support-portal-powered-by-an-agile-business-process",
            "word_count": 162,
            "read_time": "1 min read",
            "Title": "Modern Customer Support Portal",
            "MetaDescription": "This architecture shows how to easily connect multiple business systems to enable customer support.",
            "category": [
                "migration",
                "hybrid"
            ],
            "image": "/azure/architecture/solution-ideas/media/modern-customer-support-portal-powered-by-an-agile-business-process.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\modern-customer-support-portal-powered-by-an-agile-business-process.png",
            "publish_date": "12/16/2019",
            "Flow": {
                "FlowStep_A": "Customer submits feedback posted to a web endpoint.",
                "FlowStep_B": "The feedback is posted to Microsoft Cognitive Services Text Analytics API to extract sentiment and keywords.",
                "FlowStep_C": "The customer feedback creates a new case in Dynamics CRM or other CRM.",
                "FlowStep_D": "The solution sends a text message to the customer, thanking them for the feedback.",
                "FlowStep_E": "If the feedback sentiment scores lower than 0.3, the app posts this information to a customer service channel to respond."
            },
            "name": "modern-customer-support-portal-powered-by-an-agile-business-process",
            "popularity": 160,
            "topic": "Migration",
            "hybrid-topic": "Apps"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-modern-data-warehouse-'",
                "acom-architecture",
                "all-items",
                "big-data-warehouse",
                "cloud-data-warehouse",
                "data-flow",
                "interactive-diagram",
                "modern-data-warehouse",
                "modern-data-warehouse-architecture",
                "pricing-calculator",
                "pricing-guidance",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/modern-data-warehouse.md",
            "http_url": "/azure/architecture/solution-ideas/articles/modern-data-warehouse",
            "word_count": 378,
            "read_time": "2 min read",
            "Title": "Modern Data Warehouse Architecture",
            "MetaDescription": "Explore a cloud data warehouse that uses big data. Modern data warehouse brings together all your data and scales easily as your data grows.",
            "category": [
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/modern-data-warehouse.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\modern-data-warehouse.png",
            "publish_date": "12/16/2019",
            "pricing_calculator": "https://azure.com/e/4269bfbeee564d3cb88348a033e022e8",
            "pricing_guidance": "pricing-calculator",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/synapse-analytics\">Azure Synapse Analytics</a> is the fast, flexible and trusted cloud data warehouse that lets you scale, compute and store elastically and independently, with a massively parallel processing architecture.</p>",
                "<p>Azure <a href=\"https://azure.microsoft.com/services/data-factory\">Data Factory</a> is a hybrid data integration service that allows you to create, schedule and orchestrate your ETL/ELT workflows.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage/blobs\">Azure Blob storage</a> is a Massively scalable object storage for any type of unstructured data-images, videos, audio, documents, and more-easily and cost-effectively.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/databricks\">Azure Databricks</a> is a fast, easy, and collaborative Apache Spark-based analytics platform.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/analysis-services\">Azure Analysis Services</a> is an enterprise grade analytics as a service that lets you govern, deploy, test, and deliver your BI solution with confidence.</p>",
                "<p><a href=\"https://powerbi.microsoft.com\">Power BI</a> is a suite of business analytics tools that deliver insights throughout your organization. Connect to hundreds of data sources, simplify data prep, and drive ad hoc analysis. Produce beautiful reports, then publish them for your organization to consume on the web and across mobile devices.</p>"
            ],
            "Summary": "<p>A modern data warehouse lets you bring together all your data at any scale easily, and to get insights through analytical dashboards, operational reports, or advanced analytics for all your users.</p>",
            "Flow": {
                "FlowStep_A": "Combine all your structured, unstructured and semi-structured data (logs, files, and media) using Azure Data Factory to Azure Blob Storage.",
                "FlowStep_B": "Leverage data in Azure Blob Storage to perform scalable analytics with Azure Databricks and achieve cleansed and transformed data.",
                "FlowStep_C": "Cleansed and transformed data can be moved to Azure Synapse Analytics to combine with existing structured data, creating one hub for all your data. Leverage native connectors between Azure Databricks and Azure Synapse Analytics to access and move data at scale.",
                "FlowStep_D": "Build operational reports and analytical dashboards on top of Azure Data Warehouse to derive insights from the data, and use Azure Analysis Services to serve thousands of end users.",
                "FlowStep_E": "Run ad hoc queries directly on data within Azure Databricks."
            },
            "name": "modern-data-warehouse",
            "popularity": 228,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "fcp",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/net-app-modernization.md",
            "http_url": "/azure/architecture/solution-ideas/articles/net-app-modernization",
            "word_count": 592,
            "read_time": "3 min read",
            "Title": "Modernize .NET applications",
            "MetaDescription": "Modernize .NET applications with Azure SQL DB and Azure App Service",
            "category": [
                "integration",
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/net-app-modernization.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\net-app-modernization.png",
            "publish_date": "6/26/2020",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/app-service/overview\">Azure App Service</a> is an HTTP-based service for hosting web applications, REST APIs, and mobile back ends. You can take advantage of its DevOps capabilities, such as continuous deployment from Docker Hub, as shown here.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/azure-sql/database/sql-database-paas-overview\">Azure SQL Database</a> is a fully managed and intelligent relational database service built for the cloud. With SQL Database, you can create a highly available and high-performance data storage layer for modern cloud applications.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/devops/\">Azure DevOps</a> provides developer services to support teams to plan work, collaborate on code development, and build and deploy applications.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/dms/dms-overview\">Azure Database Migration Service</a> enables seamless migration from multiple database sources to Azure, with minimal downtime.</p>"
            ],
            "name": "net-app-modernization",
            "popularity": 0,
            "topic": "Integration"
        },
        {
            "tags": [
                "ai",
                "all-items",
                "alternative-choices",
                "azcat-ai",
                "example-code",
                "example-workload",
                "github",
                "shell"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/ai/movie-recommendations-with-machine-learning.md",
            "http_url": "/azure/architecture/example-scenario/ai/movie-recommendations-with-machine-learning",
            "word_count": 937,
            "read_time": "4 min read",
            "Title": "Movie recommendations on Azure",
            "MetaDescription": "Use machine learning to automate movie, product, and other recommendations using machine learning and an Azure Data Science Virtual Machine (DSVM) to train a model on Azure.",
            "category": [
                "ai-machine-learning",
                "media"
            ],
            "image": "/azure/architecture/example-scenario/ai/media/architecture-movie-recommender.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\ai\\media\\architecture-movie-recommender.png",
            "publish_date": "1/09/2019",
            "alternative_choices": "alternatives",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/machine-learning/data-science-virtual-machine/overview\">Data Science Virtual Machine</a> (DSVM) is an Azure virtual machine with deep learning frameworks and tools for machine learning and data science. The DSVM has a standalone Spark environment that can be used to run ALS.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/storage/blobs/storage-blobs-introduction\">Azure Blob storage</a> stores the dataset for movie recommendations.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/machine-learning/service\">Azure Machine Learning</a> is used to accelerate the building, managing, and deploying of machine learning models.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/cosmos-db/introduction\">Azure Cosmos DB</a> enables globally distributed and multi-model database storage.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/container-instances/container-instances-overview\">Azure Container Instances</a> is used to deploy the trained models to web or app services, optionally using <a href=\"https://learn.microsoft.com/azure/aks/intro-kubernetes\">Azure Kubernetes Service</a>.</p>"
            ],
            "Summary": "<p>This example scenario shows how a business can use machine learning to automate product recommendations for their customers. An Azure Data Science Virtual Machine (DSVM) is used to train a model on Azure that recommends movies to users based on ratings that have been given to movies.</p>\n<p>Recommendations can be useful in various industries from retail to news to media. Potential applications include providing product recommendations in a virtual store, providing news or post recommendations, or providing music recommendations. Traditionally, businesses had to hire and train assistants to make personalized recommendations to customers. Today, we can provide customized recommendations at scale by using Azure to train models to understand customer preferences.</p>",
            "sample_code": true,
            "github_url": "https://github.com/microsoft/recommenders/blob/master/examples/00_quick_start/als_movielens.ipynb",
            "code_languages": [
                "shell"
            ],
            "name": "movie-recommendations-with-machine-learning",
            "popularity": 76,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "all-items",
                "azurecli",
                "example-code",
                "reference-architecture",
                "seodec18",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/n-tier/multi-region-sql-server.yml",
            "http_url": "/azure/architecture/reference-architectures/n-tier/multi-region-sql-server",
            "word_count": 2443,
            "read_time": "10 min read",
            "Title": "Multi-region N-tier application",
            "MetaDescription": "Deploy an application on Azure virtual machines in multiple regions for high availability and resiliency.",
            "category": [
                "web",
                "databases",
                "management-and-governance"
            ],
            "image": "/azure/architecture/reference-architectures/n-tier/images/multi-region-sql-server.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\n-tier\\images\\multi-region-sql-server.png",
            "publish_date": "6/18/2019",
            "visio_diagram": "https://arch-center.azureedge.net/vm-reference-architectures.vsdx",
            "code_languages": [
                "azurecli"
            ],
            "sample_code": true,
            "name": "multi-region-sql-server",
            "popularity": 213,
            "topic": "Web"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "application-development",
                "bcdr",
                "example-workload",
                "pricing-calculator",
                "pricing-guidance",
                "product-team",
                "web-apps"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/infrastructure/multi-tier-app-disaster-recovery.yml",
            "http_url": "/azure/architecture/example-scenario/infrastructure/multi-tier-app-disaster-recovery",
            "word_count": 1197,
            "read_time": "5 min read",
            "Title": "Multi-tier web application built for HA/DR",
            "MetaDescription": "Create a multitier web application built for high availability and disaster recovery on Azure using Azure virtual machines, availability sets, availability zones, Azure Site Recovery, and Azure Traffic Manager.",
            "category": [
                "web",
                "featured"
            ],
            "image": "/azure/architecture/example-scenario/infrastructure/media/architecture-disaster-recovery-multi-tier-app.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\infrastructure\\media\\architecture-disaster-recovery-multi-tier-app.png",
            "publish_date": "11/16/2018",
            "pricing_calculator": "https://azure.com/e/6835332265044d6d931d68c917979e6d",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-machines/windows/manage-availability\">Availability sets</a> ensure that the VMs you deploy on Azure are distributed across multiple isolated hardware nodes in a cluster. If a hardware or software failure occurs within Azure, only a subset of your VMs are affected and your entire solution remains available and operational.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/availability-zones/az-overview\">Availability zones</a> protect your applications and data from datacenter failures. Availability zones are separate physical locations within an Azure region. Each zone consists of one or more datacenters equipped with independent power, cooling, and networking.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/site-recovery/azure-to-azure-quickstart\">Azure Site Recovery</a> allows you to replicate VMs to another Azure region for business continuity and disaster recovery needs. You can conduct periodic disaster recovery drills to ensure you meet the compliance needs. The VM will be replicated with the specified settings to the selected region so that you can recover your applications in the event of outages in the source region.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/traffic-manager\">Azure Traffic Manager</a> is a DNS-based traffic load balancer that distributes traffic optimally to services across global Azure regions while providing high availability and responsiveness.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/load-balancer/load-balancer-overview\">Azure Load Balancer</a> distributes inbound traffic according to defined rules and health probes. A load balancer provides low latency and high throughput, scaling up to millions of flows for all TCP and UDP applications. A public load balancer is used in this scenario to distribute incoming client traffic to the web tier. An internal load balancer is used in this scenario to distribute traffic from the business tier to the back-end SQL Server cluster.</p>"
            ],
            "Summary": "<p>This example scenario is applicable to any industry that needs to deploy resilient multitier applications built for high availability and disaster recovery. In this scenario, the application consists of three layers.</p>\n<ul>\n<li>Web tier: The top layer including the user interface. This layer parses user interactions and passes the actions to next layer for processing.</li>\n<li>Business tier: Processes the user interactions and makes logical decisions about the next steps. This layer connects the web tier and the data tier.</li>\n<li>Data tier: Stores the application data. Either a database, object storage, or file storage is typically used.</li>\n</ul>\n<p>Common application scenarios include any mission-critical application running on Windows or Linux. This can be an off-the-shelf application such as SAP and SharePoint or a custom line-of-business application.</p>",
            "name": "multi-tier-app-disaster-recovery",
            "popularity": 191,
            "topic": "Web"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "cse",
                "example-code",
                "example-workload",
                "fcp",
                "github"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/serverless/serverless-multicloud.md",
            "http_url": "/azure/architecture/example-scenario/serverless/serverless-multicloud",
            "word_count": 1559,
            "read_time": "7 min read",
            "Title": "Multicloud solutions with the Serverless Framework",
            "MetaDescription": "Develop and deploy serverless microservices across cloud providers with the open-source Serverless Framework and Serverless Multicloud Library.",
            "category": [
                "developer-tools",
                "hybrid"
            ],
            "image": "/azure/architecture/example-scenario/serverless/media/multi-cloud-serverless-architecture.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\serverless\\media\\multi-cloud-serverless-architecture.png",
            "publish_date": "3/30/2020",
            "alternative_choices": "alternatives",
            "Summary": "<p>This article describes how the Microsoft Commercial Software Engineering (CSE) team partnered with a global retailer to deploy a highly-available serverless solution across both Azure and Amazon Web Services (AWS) cloud platforms, using the <a href=\"https://serverless.com\">Serverless Framework</a>.</p>\n<p>In <em>serverless computing</em>, the cloud provider dynamically allocates microservices resources to run code, and only charges for the resources used. Serverless computing abstracts app code from infrastructure implementation, code deployment, and operational aspects like planning and maintenance.</p>\n<p>As with other services, each cloud provider has its own serverless implementation, and it's difficult for customers to use a different provider without considerable operational impact and costs. Potential customers may view this situation as weakening their bargaining position and agility. Vendor lock-in is one of the greatest obstacles to enterprise cloud adoption.</p>\n<p>The open-source <em>Serverless Framework</em> is a universal cloud interface for developing and deploying serverless computing solutions across cloud providers. Open-sourcing and common APIs for serverless functions help providers, customers, and partners build cross-cloud solutions for best-of-breed services. The Serverless Framework reduces barriers to cloud adoption by addressing the problems of vendor lock-in and cross-cloud provider redundancy. Customers can optimize their solutions based on cost, agility, and other considerations.</p>\n<p>CSE and the Azure product team collectively rewrote the <em>Serverless CLI</em> to support new Azure Functions features like Premium Functions, API Management, and KeyVault. The Serverless CLI now provides a standard interface for GitOps deployment to both Azure and AWS. The team also developed the <em>Serverless Multicloud Library</em>, which provides a <em>normalized runtime API</em> to deploy serverless apps to both AWS and Azure.</p>\n<p>This design provides high availability with <em>active-active</em> failover between multiple cloud platforms, as opposed to <em>active-passive</em> failover. If the service of one cloud provider becomes unhealthy or unavailable, this solution can reroute requests to another cloud platform.</p>\n<p>This project met the following technical goals:</p>\n<ul>\n<li>Create a cross-industry solution.</li>\n<li>Use the Multicloud Serverless Library to support a cloud-agnostic API that interfaces with microservices wherever they are deployed.</li>\n<li>Support a GitOps CI/CD process workflow for development, testing, and deployment on all supported cloud platforms.</li>\n<li>Use API-based access via an authenticated cloud gateway, and load balance between cloud platforms by using the gateway as a router.</li>\n</ul>\n<p>Other potential benefits of using the Serverless Framework include:</p>\n<ul>\n<li>Prevention or reduction of vendor lock-in</li>\n<li>40-60+% code reduction during development by using the Multicloud Serverless Library</li>\n<li>Development of best-of-breed solutions that combine different cloud providers' services</li>\n<li>Elimination of most platform and infrastructure complexity and maintenance requirements</li>\n<li>Easier data sharing, performance and cost comparisons, and ability to take advantage of special offerings</li>\n<li>Active-active high availability</li>\n</ul>",
            "sample_code": true,
            "github_url": "https://github.com/serverless/multicloud",
            "name": "serverless-multicloud",
            "popularity": 0,
            "topic": "Developer Tools",
            "hybrid-topic": "Apps"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "example-workload",
                "fcp",
                "pricing-guidance"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/multi-saas/multitenant-saas.md",
            "http_url": "/azure/architecture/example-scenario/multi-saas/multitenant-saas",
            "word_count": 2851,
            "read_time": "11 min read",
            "Title": "Multitenant SaaS on Azure",
            "MetaDescription": "Build a multitenant SaaS solution on Azure, designed for high availability, scalability, data security and isolation using App Service, Azure Kubernetes Service, and SQL Elastic Pools.",
            "category": [
                "identity"
            ],
            "image": "/azure/architecture/example-scenario/multi-saas/media/multitenant-saas.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\multi-saas\\media\\multitenant-saas.png",
            "publish_date": "7/16/2020",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternative-components",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/frontdoor/\">Azure Front Door</a>: A regional load balancer that routes client traffic to the correct region. It can fail over to the second region if region failure happens and it can secure the internet-facing entry point via <a href=\"https://learn.microsoft.com/azure/web-application-firewall/ag/ag-overview\">Azure Web Application Firewall</a>.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/active-directory/\">Azure Active Directory</a> (Azure AD): Acts as the identity provider for the entire application, enforcing authentication and end-to-end authorization of the request in the application.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/dns/\">Azure DNS</a>: A hosting service in Azure for domain name resolution. In a multitenant solution, multiple clients will be accessing the solution via their own individual domains. Use Azure DNS to configure and resolve client requests to their correct application stack.</p>",
                "<p><a >overview on Azure load-balancing</a>.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/app-service/\">App Service</a>: Azure's premier service for web applications and web-based APIs. Security integrates with services like Azure AD and <a href=\"https://azure.microsoft.com/services/key-vault/\">Azure Key Vault</a>. You can configure scaling to happen automatically. Also, the amount of resources available to scale to is flexible between the various App Service plans that the app can run on. App Service can also leverage integrated DevOps capabilities for continuous integration and deployment to multiple environments. These and other supporting features of the Azure platform allow for developers to focus on the development of their applications.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/kubernetes-service/\">Azure Kubernetes Service</a> (AKS): Orchestrates instances of container images deployed to a cluster. Managing multiple clients' data often involves implementing a suite of components to manage:</p>",
                "<p>Data modeling</p>",
                "<p>Data source connectivity</p>",
                "<p>Extract, transform, load (ETL)</p>",
                "<p>Import/export activities</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/sql-database/sql-database-elastic-pool\">Azure SQL Elastic Pools</a>: Provides a solution for managing a set of databases flexibly with a pool of resources. The service allocates resources on demand to the databases. It gives the developer of a multitenant SaaS architecture the power to deliver database resources to clients as they need it. The service also reduces the budget and overhead of maintaining multiple SQL Servers with large chunks of unused compute resources.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/search/\">Azure Cognitive Search</a> (formerly known as Azure Search): A service that adds a powerful indexing and query engine to your application. It gives clients access to strong query functionality. They can also use Azure's AI capabilities to enrich and enhance the query functionality. Azure Cognitive Search can account for multitenancy using an index-per-tenant or service-per-tenant strategy.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cache/\">Azure Cache for Redis</a>: Applies a caching layer as a service to the solution, providing an in-memory managed cache to reduce latency and increase performance for the clients. High throughput allows for a high volume of requests to handle multiple tenants accessing the system. You can flexibly scale up the service as application loads increase. It also supports encryption at rest to protect and isolate cached tenant data.</p>"
            ],
            "Summary": "<p>When you identify a portion of your business's software solution that can be unbranded and marketed to other businesses, it adds an entire new revenue stream for a company. However, configuring the solution to account for the load that a slew of tenants brings is often a challenging obstacle to tackle. Azure offers a range of services for managing a software solution that:</p>\n<ul>\n<li>\n<p>Flexibly maintains databases for all clients.</p>\n</li>\n<li>\n<p>Scales the business and logic tier of the solution to prevent bottlenecks at the compute layer.</p>\n</li>\n<li>\n<p>Integrates availability and regional failover.</p>\n</li>\n<li>\n<p>Provides end-to-end security at all levels of the solution.</p>\n</li>\n</ul>",
            "name": "multitenant-saas",
            "popularity": 0,
            "topic": "Identity"
        },
        {
            "tags": [
                "all-items",
                "bash",
                "example-code",
                "github",
                "reference-architecture",
                "seodec18",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/n-tier/n-tier-cassandra.yml",
            "http_url": "/azure/architecture/reference-architectures/n-tier/n-tier-cassandra",
            "word_count": 2862,
            "read_time": "11 min read",
            "Title": "N-tier application with Apache Cassandra",
            "MetaDescription": "Run Linux virtual machines for an N-tier architecture with Apache Cassandra in Microsoft Azure.",
            "category": [
                "databases",
                "web",
                "management-and-governance"
            ],
            "image": "/azure/architecture/reference-architectures/n-tier/images/n-tier-cassandra.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\n-tier\\images\\n-tier-cassandra.png",
            "publish_date": "8/21/2019",
            "sample_code": true,
            "github_url": "https://github.com/mspnp/template-building-blocks/wiki/overview",
            "visio_diagram": "https://arch-center.azureedge.net/vm-reference-architectures.vsdx",
            "code_languages": [
                "bash"
            ],
            "name": "n-tier-cassandra",
            "popularity": 162,
            "topic": "Databases"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-oil-and-gas-tank-level-forecasting-'",
                "acom-architecture",
                "ai-gallery",
                "all-items",
                "analytics",
                "artificial-intelligence",
                "azure",
                "data-flow",
                "example-code",
                "github",
                "hpc",
                "solution-architectures",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/oil-and-gas-tank-level-forecasting.md",
            "http_url": "/azure/architecture/solution-ideas/articles/oil-and-gas-tank-level-forecasting",
            "word_count": 537,
            "read_time": "3 min read",
            "Title": "Oil and Gas Tank Level Forecasting",
            "MetaDescription": "Today, most facilities operate reactively to problems in tank levels. This often leads to spills, emergency shutdowns, expensive remediation costs, regulatory issues, costly repairs and fines. Tank level forecasting helps manage and abate these and other problems.",
            "category": [
                "analytics",
                "compute"
            ],
            "image": "/azure/architecture/solution-ideas/media/oil-and-gas-tank-level-forecasting.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\oil-and-gas-tank-level-forecasting.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Today, most facilities operate reactively to problems in tank levels. This often leads to spills, emergency shutdowns, expensive remediation costs, regulatory issues, costly repairs and fines. Tank level forecasting helps manage and abate these and other problems.</p>\n<p>Forecasts are created by harnessing the power of real-time and historical data readily available from sensors, meters and records, which helps to:</p>\n<ul>\n<li>Prevent tank spillage and emergency shutdowns</li>\n<li>Discover hardware malfunction or failure</li>\n<li>Schedule maintenance, shutdowns, and logistics</li>\n<li>Optimize operations and facility efficiency</li>\n<li>Detect pipeline leaks and slugging</li>\n<li>Reduce costs, fines, and downtime</li>\n</ul>\n<p>The tank level forecasting process starts at the well input. Oil is measured as it comes into the facility via meters and is sent to tanks. Levels are monitored and recorded in tanks during the refining process and then oil, gas, and water output are recorded via sensors, meters, and records. Forecasts are then made using data from the facility; for example, forecasts can be made every 15 minutes.</p>\n<p>The Cortana Intelligence Suite is adaptable and can be customized to meet different requirements that facilities and corporations have.</p>",
            "Flow": {
                "FlowStep_A": "The data feeds into the Azure Event Hubs and Azure Synapse Analytics service as data points or events, that will be used in the rest of the solution flow.",
                "FlowStep_B": "Azure Stream Analytics analyze the data to provide near real-time analytics on the input stream from the event hub and directly publish to Power BI for visualization.",
                "FlowStep_C": "Azure Machine Learning is used to make forecast on the tank level of particular region given the inputs received.",
                "FlowStep_D": "Azure Synapse Analytics is used to store the prediction results received from Azure Machine Learning. These results are then consumed in the Power BI dashboard.",
                "FlowStep_E": "Azure Data Factory handles orchestration, and scheduling of the hourly model retraining."
            },
            "sample_code": true,
            "github_url": "https://github.com/Azure/cortana-intelligence-tank-level-forecast",
            "name": "oil-and-gas-tank-level-forecasting",
            "popularity": 23,
            "topic": "Analytics"
        },
        {
            "tags": [
                "all-items",
                "fcp",
                "reference-architecture",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "hybrid/gateway-logic-apps.md",
            "http_url": "/azure/architecture/hybrid/gateway-logic-apps",
            "word_count": 822,
            "read_time": "3 min read",
            "Title": "On-premises data gateway for Azure Logic Apps",
            "MetaDescription": "Using a data gateway to connect on-premises data sources to Azure Logic Apps",
            "category": [
                "hybrid",
                "integration"
            ],
            "image": "/azure/architecture/hybrid/images/gateway-logic-apps.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\hybrid\\images\\gateway-logic-apps.png",
            "publish_date": "7/16/2020",
            "visio_diagram": "https://arch-center.azureedge.net/gateway-logic-apps.vsdx",
            "name": "gateway-logic-apps",
            "popularity": 0,
            "topic": "Integration",
            "hybrid-topic": "Data"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-ops-automation-using-event-grid-'",
                "acom-architecture",
                "all-items",
                "ap-dev",
                "azure",
                "devops",
                "event-grid",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/ops-automation-using-event-grid.md",
            "http_url": "/azure/architecture/solution-ideas/articles/ops-automation-using-event-grid",
            "word_count": 75,
            "read_time": "1 min read",
            "Title": "Ops automation using Event Grid",
            "MetaDescription": "Event Grid allows you to speed automation and simplify policy enforcement. For example, Event Grid can notify Azure Automation when a virtual machine is created, or a SQL Database is spun up. These events can be used to automatically check that service configurations are compliant, put metadata into operations tools, tag virtual machines, or file work items.",
            "category": [
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/ops-automation-using-event-grid.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\ops-automation-using-event-grid.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Event Grid allows you to speed automation and simplify policy enforcement. For example, Event Grid can notify Azure Automation when a virtual machine is created, or a SQL Database is spun up. These events can be used to automatically check that service configurations are compliant, put metadata into operations tools, tag virtual machines, or file work items.</p>",
            "name": "ops-automation-using-event-grid",
            "popularity": 40,
            "topic": "Databases"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-optimize-marketing-with-machine-learning-'",
                "acom-architecture",
                "ai-ml",
                "all-items",
                "machine-learning-in-marketing",
                "machine-learning-marketing",
                "machine-learning-r",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/optimize-marketing-with-machine-learning.md",
            "http_url": "/azure/architecture/solution-ideas/articles/optimize-marketing-with-machine-learning",
            "word_count": 243,
            "read_time": "2 min read",
            "Title": "Optimize Marketing with Machine Learning",
            "MetaDescription": "Learn how to build a machine-learning model with SQL Server 2016 with R Services to optimize and manage marketing campaigns.",
            "category": [
                "ai-machine-learning",
                "analytics"
            ],
            "image": "/azure/architecture/solution-ideas/media/optimize-marketing-with-machine-learning.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\optimize-marketing-with-machine-learning.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/sql/machine-learning/r/sql-server-r-services?view=sql-server-2016\">SQL Server R Services</a>: SQL Server stores the campaign and lead data. R-based analytics provide training and predicted models and predicted results for consumption using R.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/machine-learning-studio\">Machine Learning Studio</a>: Machine Learning helps you easily design, test, operationalize, and manage predictive analytics solutions in the cloud.</p>",
                "<p><a href=\"https://powerbi.microsoft.com\">Power BI</a> provides an interactive dashboard with visualization that uses data stored in SQL Server to drive decisions on the predictions.</p>"
            ],
            "Summary": "<p>Marketing campaigns are about more than the message being delivered; when and how that message is delivered is just as important. Without a data-driven, analytical approach, campaigns can easily miss opportunities or struggle to gain traction.</p>\n<p>Through machine learning informed by historical campaign data, this solution helps predict customer responses and recommends an optimized plan for connecting with your leads-including the best channel to use (by email, SMS, a cold call, etc.), the best day of the week, and the best time of the day.</p>\n<p>Optimizing your campaigns with machine learning helps improve both sales leads and revenue generation and can provide strong ROI for your marketing investment.</p>\n<p>In this solution, SQL Server R Services brings the compute to the data by running R on the computer that hosts the database.</p>",
            "name": "optimize-marketing-with-machine-learning",
            "popularity": 17,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-reference-architecture-for-oracle-database-migration-to-azure-'",
                "acom-architecture",
                "all-items",
                "data",
                "data-flow",
                "interactive-diagram",
                "oracle",
                "oracle-database",
                "oracle-db",
                "oracle-db-architecture",
                "oracle-on-azure",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/reference-architecture-for-oracle-database-migration-to-azure.md",
            "http_url": "/azure/architecture/solution-ideas/articles/reference-architecture-for-oracle-database-migration-to-azure",
            "word_count": 306,
            "read_time": "2 min read",
            "Title": "Oracle Database Migration to Azure",
            "MetaDescription": "Oracle DB migrations can be accomplished in multiple ways. This architecture covers one of these options wherein Oracle Active Data Guard is used to migrate the Database.",
            "category": [
                "databases",
                "migration"
            ],
            "image": "/azure/architecture/solution-ideas/media/reference-architecture-for-oracle-database-migration-to-azure.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\reference-architecture-for-oracle-database-migration-to-azure.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Oracle DB migrations can be accomplished in multiple ways. This architecture covers one of these options wherein Oracle Active Data Guard is used to migrate the Database. It is assumed that Oracle Data Guard (or Active Data Guard) is used for HA/DR purposes. Depending on the application, either the application can be migrated first or the database. In this case, the application is migrated to Azure using Azure Load Balancer. This enables you to split your traffic between on-premises and Azure, allowing you to gradually migrate your application tier. The database migration is performed in multiple steps. As a first step, Oracle Data Guard is used to set up a Secondary/Standby Database in Azure. This allows you to migrate your data to Azure. Once the secondary in Azure is in-sync with the primary, you can flip the database in Azure to be your primary database while maintaining your secondary on-premises. As a next step, you may set up a secondary database in a different Availability Zone (or region) for HA/DR purposes. At this point, you can decommission your on-premises environment. All data traffic between on-premises and Azure flows over Azure ExpressRoute or Site-to-Site VPN connectivity.</p>",
            "Flow": {
                "FlowStep_A": "Connect your Azure environment with your on-premises network via site-to-site VPN or ExpressRoute.",
                "FlowStep_B": "Use Azure Load Balancer to migrate and balance traffic between the on-prem AppServer and your Azure AppServer.",
                "FlowStep_C": "Use DataGuard to mark your OracleDB1 in Azure as your active stand-by."
            },
            "name": "reference-architecture-for-oracle-database-migration-to-azure",
            "popularity": 53,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "example-workload",
                "fcp"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/oracle-migrate/oracle-migration-cross-cloud.md",
            "http_url": "/azure/architecture/example-scenario/oracle-migrate/oracle-migration-cross-cloud",
            "word_count": 242,
            "read_time": "2 min read",
            "Title": "Oracle database migration: Cross-cloud connectivity",
            "MetaDescription": "Create a connection between your existing Oracle Database and your Azure applications.",
            "category": [
                "databases",
                "migration"
            ],
            "image": "/azure/architecture/example-scenario/oracle-migrate/media/cross-cloud-connectivity.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\oracle-migrate\\media\\cross-cloud-connectivity.png",
            "publish_date": "6/23/2020",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/virtual-machines/\">Azure Virtual Machines</a> lets you migrate your business and important workloads to Azure to increase operational efficiencies.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/virtual-network/\">Azure Virtual Network</a> is your private network in your Azure environment.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/vpn-gateway/\">Azure VPN Gateway</a> connects your infrastructure to the cloud.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/expressroute/\">Azure ExpressRoute</a> creates a faster private connection to Azure.</p>"
            ],
            "name": "oracle-migration-cross-cloud",
            "popularity": 0,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "example-workload",
                "fcp"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/oracle-migrate/oracle-migration-lift-shift.md",
            "http_url": "/azure/architecture/example-scenario/oracle-migrate/oracle-migration-lift-shift",
            "word_count": 370,
            "read_time": "2 min read",
            "Title": "Oracle database migration: Lift and shift",
            "MetaDescription": "Lift and shift your Oracle database from an Oracle environment to Azure Virtual Machines.",
            "category": [
                "databases",
                "migration"
            ],
            "image": "/azure/architecture/example-scenario/oracle-migrate/media/lift-shift-azure-vms.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\oracle-migrate\\media\\lift-shift-azure-vms.png",
            "publish_date": "6/23/2020",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/virtual-machines/\">Azure Virtual Machines</a> lets you migrate your business and important workloads to Azure to increase operational efficiencies.</p>"
            ],
            "name": "oracle-migration-lift-shift",
            "popularity": 0,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "example-workload",
                "fcp",
                "github"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/oracle-migrate/oracle-migration-rearchitect.md",
            "http_url": "/azure/architecture/example-scenario/oracle-migrate/oracle-migration-rearchitect",
            "word_count": 738,
            "read_time": "3 min read",
            "Title": "Oracle database migration: Rearchitect",
            "MetaDescription": "Rearchitect your Oracle database with Azure SQL Managed Instance",
            "category": [
                "databases",
                "migration"
            ],
            "image": "/azure/architecture/example-scenario/oracle-migrate/media/rearchitect.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\oracle-migrate\\media\\rearchitect.png",
            "publish_date": "6/23/2020",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/azure-sql/sql-managed-instance/\">Azure SQL Managed Instance</a> is the intelligent, scalable, cloud database service that combines the broadest SQL Server engine compatibility with all the benefits of a fully managed and evergreen platform as a service (PAAS).</p>",
                "<p><a href=\"https://azure.microsoft.com/services/azure-sql/\">Azure SQL</a> gives you a unified experience across your entire SQL portfolio and a full range of deployment options.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/virtual-network/\">Azure Virtual Network</a> is your private network in your Azure environment.</p>"
            ],
            "sample_code": true,
            "github_url": "https://github.com/microsoft/DataMigrationTeam/blob/master/Oracle%20Inventory%20Script%20Artifacts/Oracle%20Inventory%20Script%20Artifacts/Oracle_PreSSMA_Pre_v12.sql",
            "name": "oracle-migration-rearchitect",
            "popularity": 0,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "console",
                "example-code",
                "example-workload",
                "fcp",
                "github"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/oracle-migrate/oracle-migration-refactor.md",
            "http_url": "/azure/architecture/example-scenario/oracle-migrate/oracle-migration-refactor",
            "word_count": 644,
            "read_time": "3 min read",
            "Title": "Oracle database migration: Refactor",
            "MetaDescription": "Refactor your Oracle database with Azure Database Migration Service and move it to PostgreSQL.",
            "category": [
                "databases",
                "migration"
            ],
            "image": "/azure/architecture/example-scenario/oracle-migrate/media/refactor.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\oracle-migrate\\media\\refactor.png",
            "publish_date": "6/23/2020",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/database-migration/\">Azure Database Migration Service</a> is a tool that helps you simplify, guide, and automate your database migration to Azure.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/postgresql/\">Azure Database for PostgreSQL</a> lets you focus on application innovation instead of database management and scale your workload quickly and easily.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/virtual-network/\">Azure Virtual Network</a> is your private network in your Azure environment.</p>"
            ],
            "sample_code": true,
            "github_url": "https://github.com/microsoft/DataMigrationTeam/blob/master/Oracle%20Inventory%20Script%20Artifacts/Oracle%20Inventory%20Script%20Artifacts/Oracle_PreSSMA_Pre_v12.sql",
            "code_languages": [
                "console"
            ],
            "name": "oracle-migration-refactor",
            "popularity": 0,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "data-flow",
                "example-code",
                "example-workload",
                "fcp",
                "github"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/oracle-migrate/oracle-migration-overview.yml",
            "http_url": "/azure/architecture/example-scenario/oracle-migrate/oracle-migration-overview",
            "word_count": 591,
            "read_time": "3 min read",
            "Title": "Overview of Oracle database migration",
            "MetaDescription": "Learn about Oracle database migration paths and the methods you use to migrate your schema to SQL or PostgreSQL.",
            "category": [
                "databases",
                "migration"
            ],
            "image": "/azure/architecture/example-scenario/oracle-migrate/media/oracle-migration-process-to-sql-pg.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\oracle-migrate\\media\\oracle-migration-process-to-sql-pg.png",
            "publish_date": "6/23/2020",
            "Summary": "<p>This series of articles provides a way for you to assess your current Oracle database environment, figure out your best migration path to Azure, and links to documents that help you make your migratory move. Your migration path can be to an Azure Virtual Machine (VM). It might also be to an Azure Managed Database that is running on an Azure VM.</p>\n<p>To migrate an Oracle database to an Azure environment, you have to:</p>\n<ul>\n<li>\n<p>Choose Azure resources as target database.</p>\n</li>\n<li>\n<p>Decide data migration method to evaluate downtime window.</p>\n</li>\n<li>\n<p>Figure out how to archive business continuity and disaster recovery requirements.</p>\n</li>\n</ul>",
            "Flow": {
                "FlowStep_A": "Use Oracle script artifacts to evaluate Oracle database.",
                "FlowStep_B": "Schema conversion is different for both database types:",
                "FlowStep_C": "Data migration is different for both database types:",
                "FlowStep_D": "Test the conversion using functional tests.",
                "FlowStep_E": "Switch the application's connection strings to complete the application cutover."
            },
            "sample_code": true,
            "github_url": "https://github.com/microsoft/DataMigrationTeam/tree/master/Oracle%20Inventory%20Script%20Artifacts",
            "name": "oracle-migration-overview",
            "popularity": 0,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "csharp",
                "example-code",
                "fcp",
                "github",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/event-hubs/partitioning-in-event-hubs-and-kafka.md",
            "http_url": "/azure/architecture/reference-architectures/event-hubs/partitioning-in-event-hubs-and-kafka",
            "word_count": 3439,
            "read_time": "12 min read",
            "Title": "Partitioning in Event Hubs and Kafka",
            "MetaDescription": "Learn about partitioning in Kafka and Event Hubs with Kafka. See how many partitions to use in ingestion pipelines and how to assign events to partitions.",
            "category": [
                "hybrid",
                "analytics"
            ],
            "image": "/azure/architecture/reference-architectures/event-hubs/images/event-processing-service.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\event-hubs\\images\\event-processing-service.png",
            "publish_date": "10/02/2020",
            "Summary": "<p>This reference architecture provides strategies for the <a href=\"https://learn.microsoft.com/azure/event-hubs/event-hubs-scalability#partitions\">partitioning model</a> that event ingestion services use. Because event ingestion services provide solutions for high-scale event streaming, they need to process events in parallel and be able to maintain event order. They also need to balance loads and offer scalability. Partitioning models meet all of these requirements.</p>\n<p>Specifically, this document discusses the following strategies:</p>\n<ul>\n<li>How to assign events to partitions.</li>\n<li>How many partitions to use.</li>\n<li>How to assign partitions to subscribers when rebalancing.</li>\n</ul>\n<p>Many event ingestion technologies exist, including:</p>\n<ul>\n<li><a href=\"https://learn.microsoft.com/azure/event-hubs/event-hubs-about\">Azure Event Hubs</a>: A fully managed big data streaming platform.</li>\n<li><a href=\"https://www.confluent.io/what-is-apache-kafka/\">Apache Kafka</a>: An open-source stream-processing platform.</li>\n<li><a href=\"https://learn.microsoft.com/azure/event-hubs/event-hubs-for-kafka-ecosystem-overview\">Event Hubs with Kafka</a>: An alternative to running your own Kafka cluster. This Event Hubs feature provides an endpoint that is compatible with Kafka APIs.</li>\n</ul>\n<p>Besides offering partitioning strategies, this document also points out differences between partitioning in Event Hubs and Kafka.</p>",
            "sample_code": true,
            "github_url": "https://github.com/Azure/azure-sdk-for-net/tree/master/sdk/eventhub/Azure.Messaging.EventHubs.Processor",
            "code_languages": [
                "csharp"
            ],
            "name": "partitioning-in-event-hubs-and-kafka",
            "popularity": 0,
            "topic": "Analytics",
            "hybrid-topic": "Data"
        },
        {
            "tags": [
                "all-items",
                "cse",
                "example-code",
                "example-workload",
                "fcp",
                "github"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/banking/patterns-and-implementations.md",
            "http_url": "/azure/architecture/example-scenario/banking/patterns-and-implementations",
            "word_count": 879,
            "read_time": "4 min read",
            "Title": "Patterns and implementations",
            "MetaDescription": "Details about the patterns and implementations used when the commercial software engineer team created the banking system cloud transformation solution.",
            "category": [
                "integration"
            ],
            "image": "/azure/architecture/example-scenario/banking/images/orchestration-based-saga-serverless-arch.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\banking\\images\\orchestration-based-saga-serverless-arch.png",
            "publish_date": "8/11/2020",
            "Summary": "<p>This article covers the patterns and implementations the commercial software engineer (CSE) team used when they created the <a >Banking system cloud transformation on Azure</a>.</p>",
            "sample_code": true,
            "github_url": "https://github.com/Azure-Samples/keda-eventhub-kafka-scaler-terraform.git",
            "name": "patterns-and-implementations",
            "popularity": 0,
            "topic": "Integration"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-personalization-using-cosmos-db-'",
                "acom-architecture",
                "ai-ml",
                "all-items",
                "cosmos-db",
                "data",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/personalization-using-cosmos-db.md",
            "http_url": "/azure/architecture/solution-ideas/articles/personalization-using-cosmos-db",
            "word_count": 34,
            "read_time": "1 min read",
            "Title": "Personalization using Azure Cosmos DB",
            "MetaDescription": "Generate personalized recommendations for customers in real time, using low-latency and tunable consistency settings for immediate insights",
            "category": [
                "databases",
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/personalization-using-cosmos-db.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\personalization-using-cosmos-db.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Generate personalized recommendations for customers in real time, using low-latency and tunable consistency settings for immediate insights</p>",
            "name": "personalization-using-cosmos-db",
            "popularity": 49,
            "topic": "Databases"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-personalized-offers-'",
                "acom-architecture",
                "ai-gallery",
                "all-items",
                "artificial-intelligence",
                "azure",
                "data-flow",
                "example-code",
                "github",
                "interactive-diagram",
                "solution-architectures",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/personalized-offers.md",
            "http_url": "/azure/architecture/solution-ideas/articles/personalized-offers",
            "word_count": 633,
            "read_time": "3 min read",
            "Title": "Personalized Offers",
            "MetaDescription": "In today's highly competitive and connected environment, modern businesses can no longer survive with generic, static online content. Furthermore, marketing strategies using traditional tools are often expensive, hard to implement, and do not produce the desired return on investment. These systems often fail to take full advantage of the data collected to create a more personalized experience for the user.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/personalized-offers.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\personalized-offers.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>In today's highly competitive and connected environment, modern businesses can no longer survive with generic, static online content. Furthermore, marketing strategies using traditional tools are often expensive, hard to implement, and do not produce the desired return on investment. These systems often fail to take full advantage of the data collected to create a more personalized experience for the user.</p>\n<p>Surfacing offers that are customized for the user has become essential to building customer loyalty and remaining profitable. On a retail website, customers desire intelligent systems which provide offers and content based on their unique interests and preferences. Today's digital marketing teams can build this intelligence using the data generated from all types of user interactions. By analyzing massive amounts of data, marketers have the unique opportunity to deliver highly relevant and personalized offers to each user. However, building a reliable and scalable big data infrastructure, and developing sophisticated machine learning models that personalize to each user is not trivial.</p>",
            "Flow": {
                "FlowStep_A": "User activity on the website is simulated with an Azure Function and a pair of Azure Storage Queues.",
                "FlowStep_B": "Personalized Offer Functionality is implemented as an Azure Function. This is the key function that ties everything together to produce an offer and record activity. Data is read in from Azure Cache for Redis and Azure DocumentDb, product affinity scores are computed from Azure Machine Learning (if no history for the user exists then pre-computed affinities are read in from Azure Cache for Redis).",
                "FlowStep_C": "Raw user activity data (Product and Offer Clicks), Offers made to users, and performance data (for Azure Functions and Azure Machine Learning) are sent to Azure Event Hub.",
                "FlowStep_D": "The offer is returned to the User. In our simulation this is done by writing to an Azure Storage Queue and picked up by an Azure Function in order to produce the next user action."
            },
            "sample_code": true,
            "github_url": "https://github.com/Azure/cortana-intelligence-personalized-offers/blob/master/Automated%20Deployment%20Guide/Post%20Deployment%20Instructions.md",
            "name": "personalized-offers",
            "popularity": 30,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-personalized-marketing-'",
                "acom-architecture",
                "ai-ml",
                "all-items",
                "marketing-personalization",
                "personalized-marketing",
                "solution-idea",
                "targeted-marketing"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/personalized-marketing.md",
            "http_url": "/azure/architecture/solution-ideas/articles/personalized-marketing",
            "word_count": 396,
            "read_time": "2 min read",
            "Title": "Personalized marketing solutions",
            "MetaDescription": "Find essential technology to market your products with personalized offers. Individualize your marketing for greater customer response using big-data insights.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/personalized-marketing.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\personalized-marketing.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/event-hubs\">Event Hubs</a> ingests raw click-stream data from Functions and passes it on to Stream Analytics.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/stream-analytics\">Azure Stream Analytics</a>: Stream Analytics aggregates clicks in near real-time by product, offer, and user to write to Azure Cosmos DB and also archives raw click-stream data to Azure Storage.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cosmos-db\">Azure Cosmos DB</a> stores aggregated data of clicks by user, product, and offer as well as user-profile information.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage\">Storage Accounts</a>: Azure Storage stores archived raw click-stream data from Stream Analytics.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/functions\">Azure Functions</a> takes in user clickstream data from website and reads existing user history from Azure Cosmos DB. These data are then run through the Machine Learning web service or used along with the cold-start data in Azure Cache for Redis to obtain product-affinity scores. Product-affinity scores are used with the personalized-offer logic to determine the most relevant offer to present to the user.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/machine-learning-studio\">Machine Learning Studio</a>: Machine Learning helps you easily design, test, operationalize, and manage predictive analytics solutions in the cloud.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cache\">Azure Cache for Redis</a> stores pre-computed cold-start product affinity scores for users without history.</p>",
                "<p><a href=\"https://powerbi.microsoft.com\">Power BI</a> Visualizes user activity data as well as offers presented by reading in data from Azure Cosmos DB.</p>"
            ],
            "Summary": "<p>Personalized marketing is essential for building customer loyalty and remaining profitable. Reaching customers and getting them to engage is harder than ever, and generic offers are easily missed or ignored. Current marketing systems fail to take advantage of data that can help solve this problem.</p>\n<p>Marketers using intelligent systems and analyzing massive amounts of data can deliver highly relevant and personalized offers to each user, cutting through the clutter and driving engagement. For example, retailers can provide offers and content based on each customer's unique interests and preferences, putting products in front of the people most likely to buy them.</p>\n<p>By personalizing your offers, you'll deliver an individualized experience for every current or prospective customer, boosting engagement and improving customer conversion, lifetime value, and retention.</p>",
            "name": "personalized-marketing",
            "popularity": 139,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "example-workload",
                "fcp",
                "github",
                "json"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/wsus/index.md",
            "http_url": "/azure/architecture/example-scenario/wsus",
            "word_count": 2403,
            "read_time": "10 min read",
            "Title": "Plan deployment for updating Windows VMs in Azure",
            "MetaDescription": "A discussion of how best to configure your environment for Windows Server Update Services (WSUS).",
            "category": [
                "management-and-governance"
            ],
            "image": "/azure/architecture/example-scenario/wsus/media/wsus-vnet.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\wsus\\media\\wsus-vnet.png",
            "publish_date": "3/15/2020",
            "Summary": "<p>If you've locked down your Azure virtual network from the internet, you can still get Windows updates without jeopardizing security and opening up access to the internet as a whole. This article contains recommendations on how you can set up a perimeter network, also called a DMZ, to host a Windows Server Update Service (WSUS) instance to securely update virtual networks without internet connectivity.</p>\n<p>If you're using Azure Firewall, you can use the Windows Update FQDN tag in application rules to allow the required outbound network traffic through your firewall. For more information, see <a href=\"https://learn.microsoft.com/azure/firewall/fqdn-tags\">FQDN tags overview</a>.</p>\n<p>To implement the recommendations in this article, you should be familiar with Azure services. The following sections describe the recommended deployment design, which uses a hub-and-spoke configuration in a single-region or multiregion configuration.</p>",
            "sample_code": true,
            "github_url": "https://github.com/mspnp/solution-architectures/tree/master/wsus",
            "code_languages": [
                "json"
            ],
            "name": "wsus",
            "popularity": 0,
            "topic": "Management and Governance"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-population-health-management-for-healthcare-'",
                "acom-architecture",
                "ai-gallery",
                "ai-ml",
                "all-items",
                "artificial-intelligence",
                "azure",
                "example-code",
                "github",
                "healthcare",
                "solution-architectures",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/population-health-management-for-healthcare.md",
            "http_url": "/azure/architecture/solution-ideas/articles/population-health-management-for-healthcare",
            "word_count": 591,
            "read_time": "3 min read",
            "Title": "Population Health Management for Healthcare",
            "MetaDescription": "Population Health Management is an important tool that is increasingly being used by health care providers to manage and control the escalating costs. The crux of Population Health Management is to use data to improve health outcomes. Tracking, monitoring, and bench marking are the three bastions of Population Health Management, aimed at improving clinical and health outcomes while managing and reducing cost.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/population-health-management-for-healthcare.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\population-health-management-for-healthcare.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Population Health Management is an important tool that is increasingly being used by health care providers to manage and control the escalating costs. The crux of Population Health Management is to use data to improve health outcomes. Tracking, monitoring, and bench marking are the three bastions of Population Health Management, aimed at improving clinical and health outcomes while managing and reducing cost.</p>\n<p>In this solution, we will be leveraging the clinical and socioeconomic in-patient data generated by hospitals for population health reporting. As an example of a machine learning application with population health management, a model is utilized to predict length of hospital stay. It is geared towards hospitals and health care providers to manage and control the health care expenditure through disease prevention and management. You can learn about the data used and the length of hospital stay model in the manual deployment guide for the solution. Hospitals can use these results to optimize care management systems and focus their clinical resources on patients with more urgent need. Understanding the communities they serve through population health reporting can help hospitals transition from fee-for-service payments to value-based care while reducing costs and providing better care.</p>",
            "sample_code": true,
            "github_url": "https://github.com/Azure/cortana-intelligence-population-health-management/tree/master/Azure%20Data%20Lake/ManualDeploymentGuide/Visualization",
            "name": "population-health-management-for-healthcare",
            "popularity": 31,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-predict-length-of-stay-and-patient-flow-with-healthcare-analytics-'",
                "acom-architecture",
                "ai-ml",
                "all-items",
                "healthcare-analytics",
                "healthcare-machine-learning",
                "hospital-length-of-stay",
                "length-of-stay",
                "patient-flow",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/predict-length-of-stay-and-patient-flow-with-healthcare-analytics.md",
            "http_url": "/azure/architecture/solution-ideas/articles/predict-length-of-stay-and-patient-flow-with-healthcare-analytics",
            "word_count": 268,
            "read_time": "2 min read",
            "Title": "Predict Length of Stay and Patient Flow",
            "MetaDescription": "Learn how to predict capacity and patient flow for your hospital or healthcare facility to enhance the quality of care and improve operational efficiency.",
            "category": [
                "ai-machine-learning",
                "analytics"
            ],
            "image": "/azure/architecture/solution-ideas/media/predict-length-of-stay-and-patient-flow-with-healthcare-analytics.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\predict-length-of-stay-and-patient-flow-with-healthcare-analytics.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/sql/machine-learning/r/sql-server-r-services?view=sql-server-2016\">SQL Server R Services</a>: Stores the patient and hospital data. Provides training and predicted models and predicted results for consumption using R.</p>",
                "<p><a href=\"https://powerbi.microsoft.com\">Power BI</a> provides an interactive dashboard with visualization that uses data stored in SQL Server to drive decisions on the predictions.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/machine-learning-studio\">Machine Learning Studio</a>: Machine Learning helps you easily design, test, operationalize, and manage predictive analytics solutions in the cloud.</p>"
            ],
            "Summary": "<p>For the people running a healthcare facility, length of stay-the number of days from patient admission to discharge-matters. However, that number can vary across facilities and across disease conditions and specialties, even within the same healthcare system, making it harder to track patient flow and plan accordingly.</p>\n<p>This Azure solution helps hospital administrators use the power of machine learning to predict the length of stay for in-hospital admissions, to improve capacity planning and resource utilization. A Chief Medical Information Officer might use a predictive model to determine which facilities are overtaxed and which resources to bolster within those facilities, and a Care Line Manager might use it to determine if there will be adequate staff resources to handle the release of a patient.</p>\n<p>Being able to predict length of stay at the time of admission helps hospitals provide higher quality care and streamline their operational workload. It also helps accurately plan for discharges, lowering other quality measures such as readmissions.</p>",
            "name": "predict-length-of-stay-and-patient-flow-with-healthcare-analytics",
            "popularity": 41,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-predicting-length-of-stay-in-hospitals-'",
                "acom-architecture",
                "ai-gallery",
                "all-items",
                "artificial-intelligence",
                "azure",
                "pricing-guidance",
                "solution-architectures",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/predicting-length-of-stay-in-hospitals.md",
            "http_url": "/azure/architecture/solution-ideas/articles/predicting-length-of-stay-in-hospitals",
            "word_count": 671,
            "read_time": "3 min read",
            "Title": "Predicting Length of Stay in Hospitals",
            "MetaDescription": "This solution enables a predictive model for Length of Stay for in-hospital admissions. Length of Stay (LOS) is defined in number of days from the initial admit date to the date that the patient is discharged from any given hospital facility.",
            "category": [
                "analytics",
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/predicting-length-of-stay-in-hospitals.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\predicting-length-of-stay-in-hospitals.png",
            "publish_date": "12/16/2019",
            "pricing_guidance": "pricing",
            "Summary": "<p>This solution enables a predictive model for Length of Stay for in-hospital admissions. Length of Stay (LOS) is defined in number of days from the initial admit date to the date that the patient is discharged from any given hospital facility.</p>",
            "name": "predicting-length-of-stay-in-hospitals",
            "popularity": 14,
            "topic": "Analytics"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-aircraft-engine-monitoring-for-predictive-maintenance-in-aerospace-'",
                "acom-architecture",
                "aircraft-engine-monitor",
                "aircraft-health-monitoring-systems",
                "all-items",
                "anomaly-detection",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/aircraft-engine-monitoring-for-predictive-maintenance-in-aerospace.md",
            "http_url": "/azure/architecture/solution-ideas/articles/aircraft-engine-monitoring-for-predictive-maintenance-in-aerospace",
            "word_count": 271,
            "read_time": "2 min read",
            "Title": "Predictive Aircraft Engine Monitoring",
            "MetaDescription": "Microsoft Azure's Predictive Maintenance solution demonstrates how to combine real-time aircraft data with analytics to monitor aircraft health.",
            "category": [
                "analytics",
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/aircraft-engine-monitoring-for-predictive-maintenance-in-aerospace.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\aircraft-engine-monitoring-for-predictive-maintenance-in-aerospace.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/stream-analytics\">Azure Stream Analytics</a>: Stream Analytics provides near real-time analytics on the input stream from the Azure Event Hub. Input data is filtered and passed to a Machine Learning endpoint, finally sending the results to the Power BI dashboard.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/event-hubs\">Event Hubs</a> ingests raw assembly-line data and passes it on to Stream Analytics.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/machine-learning-studio\">Machine Learning Studio</a>: Machine Learning predicts potential failures based on real-time assembly-line data from Stream Analytics.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/hdinsight\">HDInsight</a> runs Hive scripts to provide aggregations on the raw events that were archived by Stream Analytics.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/sql-database\">Azure SQL Database</a>: SQL Database stores prediction results received from Machine Learning and publishes data to Power BI.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/data-factory\">Data Factory</a> handles orchestration, scheduling, and monitoring of the batch processing pipeline.</p>",
                "<p><a href=\"https://powerbi.microsoft.com\">Power BI</a> visualizes real-time assembly-line data from Stream Analytics and the predicted failures and alerts from Data Warehouse.</p>"
            ],
            "Summary": "<p>Microsoft Azure's Predictive Maintenance solution demonstrates how to combine real-time aircraft data with analytics to monitor aircraft health.</p>\n<p>This solution is built on the Azure managed services: <a href=\"https://azure.microsoft.com/services/stream-analytics\">Azure Stream Analytics</a>, <a href=\"https://azure.microsoft.com/services/event-hubs\">Event Hubs</a>, <a href=\"https://azure.microsoft.com/services/machine-learning-studio\">Machine Learning Studio</a>, <a href=\"https://azure.microsoft.com/services/hdinsight\">HDInsight</a>, <a href=\"https://azure.microsoft.com/services/sql-database\">Azure SQL Database</a>, <a href=\"https://azure.microsoft.com/services/data-factory\">Data Factory</a> and <a href=\"https://powerbi.microsoft.com\">Power BI</a>. These services run in a high-availability environment, patched and supported, allowing you to focus on your solution instead of the environment they run in.</p>",
            "name": "aircraft-engine-monitoring-for-predictive-maintenance-in-aerospace",
            "popularity": 73,
            "topic": "Analytics"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-predictive-insights-with-vehicle-telematics-'",
                "acom-architecture",
                "ai-ml",
                "all-items",
                "anomaly-detection",
                "automotive-telematics",
                "solution-idea",
                "vehicle-telematics"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/predictive-insights-with-vehicle-telematics.md",
            "http_url": "/azure/architecture/solution-ideas/articles/predictive-insights-with-vehicle-telematics",
            "word_count": 327,
            "read_time": "2 min read",
            "Title": "Predictive Insights with Vehicle Telematics",
            "MetaDescription": "Learn how car dealerships, manufacturers, and insurance companies can use Microsoft Azure to gain predictive insights on vehicle health and driving habits.",
            "category": [
                "ai-machine-learning",
                "storage"
            ],
            "image": "/azure/architecture/solution-ideas/media/predictive-insights-with-vehicle-telematics.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\predictive-insights-with-vehicle-telematics.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/event-hubs\">Event Hubs</a> ingests diagnostic events and passes them on to Stream Analytics and an Azure ML Web Service.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/stream-analytics\">Azure Stream Analytics</a>: Stream Analytics accepts the input stream from Event Hubs, calls an Azure ML Web Service to do predictions, and sends the stream to Azure Storage and Power BI.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/machine-learning-studio\">Machine Learning Studio</a>: Machine Learning helps you easily design, test, operationalize, and manage predictive analytics solutions in the cloud and deploy web services that can be called by Stream Analytics and Azure Data Factory.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage\">Storage Accounts</a>: Azure Storage stores diagnostic events stream data from Stream Analytics.</p>",
                "<p>Azure Data Factory uses <a href=\"https://azure.microsoft.com/services/hdinsight\">HDInsight</a> to run Hive queries to process the data and load it into Azure SQL Database.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/data-factory\">Data Factory</a> uses HDInsight to process data and load it into Azure SQL Database.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/sql-database\">Azure SQL Database</a>: SQL Database is used to store and data processed by Data Factory and HDInsight and is accessed by Power BI for analysis of the telemetry data.</p>",
                "<p>This solution uses <a href=\"https://powerbi.microsoft.com\">Power BI</a>, but others use <a href=\"https://powerbi.microsoft.com\">Power BI</a> Embedded to analyze the telemetry data.</p>"
            ],
            "Summary": "<p>Learn how car dealerships, manufacturers, and insurance companies can use Microsoft Azure to gain predictive insights on vehicle health and driving habits.</p>\n<p>This solution is built on the Azure managed services: <a href=\"https://azure.microsoft.com/services/event-hubs\">Event Hubs</a>, <a href=\"https://azure.microsoft.com/services/stream-analytics\">Azure Stream Analytics</a>, <a href=\"https://azure.microsoft.com/services/machine-learning-studio\">Machine Learning Studio</a>, <a href=\"https://azure.microsoft.com/services/storage\">Storage Accounts</a>, <a href=\"https://azure.microsoft.com/services/hdinsight\">HDInsight</a>, <a href=\"https://azure.microsoft.com/services/data-factory\">Data Factory</a>, <a href=\"https://azure.microsoft.com/services/sql-database\">Azure SQL Database</a> and <a href=\"https://powerbi.microsoft.com\">Power BI</a>. These services run in a high-availability environment, patched and supported, allowing you to focus on your solution instead of the environment they run in.</p>",
            "name": "predictive-insights-with-vehicle-telematics",
            "popularity": 64,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-predictive-maintenance-'",
                "acom-architecture",
                "ai-gallery",
                "all-items",
                "anomaly-detection",
                "artificial-intelligence",
                "azure",
                "data-flow",
                "solution-architectures",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/predictive-maintenance.md",
            "http_url": "/azure/architecture/solution-ideas/articles/predictive-maintenance",
            "word_count": 545,
            "read_time": "3 min read",
            "Title": "Predictive Maintenance",
            "MetaDescription": "This Predictive Maintenance solution monitors aircraft and predicts the remaining useful life of aircraft engine components.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/predictive-maintenance.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\predictive-maintenance.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>This Predictive Maintenance solution monitors aircraft and predicts the remaining useful life of aircraft engine components.</p>",
            "Flow": {
                "FlowStep_A": "The simulation data is streamed by a newly deployed Azure Web Job, AeroDataGenerator.",
                "FlowStep_B": "This synthetic data feeds into the Azure Event Hubs service as data points.",
                "FlowStep_C": "Two Azure Stream Analytics jobs analyze the data to provide near real-time analytics on the input stream from the event hub. One of the Stream Analytics jobs archives all raw incoming events to the Azure Storage service for later processing by the Azure Data Factory service, and the other publishes results onto a Power BI dashboard.",
                "FlowStep_D": "The HDInsight service is used to run Hive scripts (orchestrated by Azure Data Factory) to provide aggregations on the raw events that were archived by the aforementioned Stream Analytics job.",
                "FlowStep_E": "Azure Machine Learning is used (orchestrated by Azure Data Factory) to make predictions on the remaining useful life (RUL) of particular aircraft engine given the inputs received.",
                "FlowStep_F": "Azure SQL Database is used (managed by Azure Data Factory) to store the prediction results received from Azure Machine Learning. These results are then consumed in the Power BI dashboard. A stored procedure is deployed in the SQL Database and later invoked in Azure Data Factory pipeline to store the ML prediction results into the scoring result table.",
                "FlowStep_G": "Azure Data Factory handles orchestration, scheduling, and monitoring of the batch processing pipeline."
            },
            "name": "predictive-maintenance",
            "popularity": 34,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "acom-architecture",
                "all-items",
                "data-flow",
                "example-code",
                "github",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/iot-predictive-maintenance.md",
            "http_url": "/azure/architecture/solution-ideas/articles/iot-predictive-maintenance",
            "word_count": 1149,
            "read_time": "5 min read",
            "Title": "Predictive Maintenance for Industrial IoT",
            "category": [
                "iot",
                "analytics",
                "containers"
            ],
            "image": "/azure/architecture/solution-ideas/media/iot-predictive-maintenance.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\iot-predictive-maintenance.png",
            "publish_date": "8/05/2020",
            "Summary": "<p>This example scenario demonstrates how end manufacturers can connect assets to the cloud using OPC UA (Open Platform Communication Unified Architecture) and the Industrial Components. This will enable the use of Predictive Maintenance to improve the efficiency of your machines, while reducing the costs by optimizing the production. Mitigate disruptions by applying advanced analytics and machine learning to your production to anticipate outages. Ensure production uptime with rich insights and automatic alerts triggered by manufacturing data. OPC UA is a platform-independent and service-oriented interoperability standard for a secure and reliable data exchange. OPC UA is used by various industrial systems and devices such as industry PCs, PLCs, and sensors. It's a standard that is driven by the OPC Foundation.</p>",
            "Flow": {
                "FlowStep_A": "Industrial devices that can natively communicate OPC UA can directly connect to IoT Edge. IoT Edge is the compute power that sits on your on-premises network. It\u2019s the runtime environment of the Industrial Modules (OPC Publisher, OPC Twin, and Discovery Module). Modules are containers that run Azure services, 3rd party services, or your own code. The OPC Publisher module connects to OPC UA servers and publishes OPC UA telemetry data to Azure IoT Hub. OPC Twin creates a digital twin of an OPC UA server in the cloud and provides OPC UA browse/read/write/method call capabilities via a cloud-based REST (Representational State Transfer) interface. The Discovery module provides discovery services on the edge, which include OPC UA server discovery.",
                "FlowStep_B": "Industrial devices that can\u2019t communicate through OPC UA need a 3rd party PLC adapter to connect to IoT Edge. Adapters are obtainable as modules in the [Azure Marketplace](https://azuremarketplace.microsoft.com/marketplace/).",
                "FlowStep_C": "The 3rd party PLC adapters enable a connectivity between the devices and IoT Edge.",
                "FlowStep_D": "For analytical capabilities closer to where the data originates, there are modules like Machine Learning on Edge or Functions obtainable from the Azure Marketplace, allowing low latency and operation in disconnected state.",
                "FlowStep_E": "Azure IoT Hub connects the devices virtually to the cloud for further data processing. It enables a security-enhanced bidirectional communication between IoT applications and devices.",
                "FlowStep_F": "The Industrial Services are made up of several microservices exposing a REST API. All Industrial Services are deployed to an Azure Kubernetes Service cluster. They implement business logic and functionality for discovery, registration, remote control, and post-processing telemetry of industrial devices. The REST APIs can be used in any programming language and framework that can call an HTTP endpoint. There are three predominant use cases in which the data provided by the Industrial Services is used.",
                "FlowStep_G": "Azure Event Hubs transforms and stores the data. It provides a distributed stream processing platform with low latency and seamless integration.",
                "FlowStep_H": "After the Event Hubs process the data, Azure Data Lake stores and analyzes the data further. Azure Data Lake is a massively scalable data lake with enterprise-grade security and auditing, which allows to run batch, stream and interactive analytic programs with simplicity. Azure Data Lake solves many of the productivity and scalability challenges that prevent you from maximizing the value of your data assets.",
                "FlowStep_I": "Azure Databricks provides the latest versions of Apache Spark as an Azure service offering and allows you to seamlessly integrate with open source libraries. It provides a one-click setup, streamlined workflows, and an interactive workspace that enables collaboration.",
                "FlowStep_J": "Explore your data with visual reports and collaborate, publish and share these reports with others. Power BI integrates with other tools, including Microsoft Excel, so you can get up to speed quickly and work seamlessly with your existing solutions."
            },
            "sample_code": true,
            "github_url": "https://github.com/Azure/Industrial-IoT/blob/master/docs/modules/discovery.md",
            "name": "iot-predictive-maintenance",
            "popularity": 0,
            "topic": "Internet of Things"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-predictive-marketing-campaigns-with-machine-learning-and-spark-'",
                "acom-architecture",
                "ai-ml",
                "all-items",
                "analytics",
                "predictive-analytics-marketing",
                "predictive-analytics-software",
                "predictive-marketing",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/predictive-marketing-campaigns-with-machine-learning-and-spark.md",
            "http_url": "/azure/architecture/solution-ideas/articles/predictive-marketing-campaigns-with-machine-learning-and-spark",
            "word_count": 250,
            "read_time": "2 min read",
            "Title": "Predictive Marketing with Machine Learning",
            "MetaDescription": "Learn how to build a machine-learning model with Microsoft R Server on Azure HDInsight Spark clusters to recommend actions to maximize the purchase rate.",
            "category": [
                "ai-machine-learning",
                "analytics"
            ],
            "image": "/azure/architecture/solution-ideas/media/predictive-marketing-campaigns-with-machine-learning-and-spark.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\predictive-marketing-campaigns-with-machine-learning-and-spark.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p>Microsoft R Server on <a href=\"https://azure.microsoft.com/services/hdinsight\">HDInsight</a> Spark clusters provides distributed and scalable machine learning capabilities for big data, combining the power of R Server and Apache Spark.</p>",
                "<p><a href=\"https://powerbi.microsoft.com\">Power BI</a> provides an interactive dashboard with visualization that uses data stored in SQL Server to drive decisions on the predictions.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage\">Storage Accounts</a>: Azure Storage stores campaign and lead data.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/machine-learning-studio\">Machine Learning Studio</a>: Machine Learning helps you easily design, test, operationalize, and manage predictive analytics solutions in the cloud.</p>"
            ],
            "Summary": "<p>Marketing campaigns are about more than the message being delivered; when and how that message is delivered is just as important. Without a data-driven, analytical approach, campaigns can easily miss opportunities or struggle to gain traction.</p>\n<p>Through machine learning informed by historical campaign data, this solution architecture helps predict customer responses and recommends an optimized plan for connecting with your leads-including the best channel to use (by email, SMS, a cold call, etc.), the best day of the week, and the best time of the day.</p>\n<p>Optimizing your campaigns with predictive marketing helps improve both sales leads and revenue generation and can provide strong ROI for your marketing investment.</p>\n<p>This architecture enables efficient handling of big data on Spark with Microsoft R Server.</p>",
            "name": "predictive-marketing-campaigns-with-machine-learning-and-spark",
            "popularity": 138,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "all-items",
                "cse",
                "example-code",
                "example-workload",
                "fcp",
                "github"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/predictive-maintenance/iot-predictive-maintenance.md",
            "http_url": "/azure/architecture/example-scenario/predictive-maintenance/iot-predictive-maintenance",
            "word_count": 1382,
            "read_time": "6 min read",
            "Title": "Predictive maintenance with the intelligent IoT Edge",
            "MetaDescription": "Learn how a railway company implemented predictive safety maintenance using machine learning on the Azure intelligent IoT Edge platform.",
            "category": [
                "iot"
            ],
            "image": "/azure/architecture/example-scenario/predictive-maintenance/media/solution-architecture.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\predictive-maintenance\\media\\solution-architecture.png",
            "publish_date": "7/28/2020",
            "Summary": "<p>The <em>Internet-of-things (IoT) Edge</em> brings data processing and storage close to the data source, enabling fast, consistent responses with reduced dependency on cloud connectivity and resources. Edge computing can incorporate artificial intelligence (AI) and machine learning (ML) models to create <em>intelligent edge</em> devices and networks, which can integrate with the cloud for further processing and security.</p>\n<p>This article describes a collaboration between the Microsoft Commercial Software Engineering (CSE) team and a major railway company to create an <a href=\"https://azure.microsoft.com/overview/future-of-cloud/\">intelligent cloud and intelligent edge</a> train maintenance and safety solution. The railway company wants to improve railroad safety and efficiency by proactively identifying defective components, predictively scheduling maintenance and repair, and continuously improving their findings and predictions. The pilot project for the <em>ML on Edge</em> solution is a train wheel health analysis system.</p>\n<p>Over 4,000 trackside detectors continuously monitor and stream wheel data from all the company's trains. The detectors measure heat and force of equipment on the tracks, listen for invisible wheel bearing defects or wheel cracks, and identify missing or misplaced parts. The ML on Edge system processes and acts on this continuous streaming detector data in near-real time to identify at-risk equipment, determine repair urgency, generate alerts, and send data to the Azure cloud for storage. The IoT Edge modules run on server class hardware in trackside bungalows, allowing for future parallel deployment of other workloads.</p>\n<p>Bringing ML and business logic closer to the data sources lets devices react faster to local changes and critical events. Devices can operate reliably offline or when connectivity is limited. The Edge network can determine which data to send to the cloud, or prioritize urgent and important data first.</p>\n<p>The wheel health analysis system provides early identification of potential equipment failure, helping prevent catastrophic failures that could lead to train derailment. The company can use stored data to spot trends and inform prescriptive maintenance and overhaul schedules.</p>",
            "sample_code": true,
            "github_url": "https://github.com/cloudevents/spec",
            "name": "iot-predictive-maintenance",
            "popularity": 0,
            "topic": "Internet of Things"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "analytics",
                "data",
                "data-flow",
                "example-workload",
                "fasttrack",
                "iot",
                "pricing-calculator",
                "pricing-guidance"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/data/realtime-analytics-vehicle-iot.yml",
            "http_url": "/azure/architecture/example-scenario/data/realtime-analytics-vehicle-iot",
            "word_count": 1598,
            "read_time": "7 min read",
            "Title": "Process real-time vehicle data using IoT",
            "MetaDescription": "This example builds a real-time data ingestion/processing pipeline to ingest and process messages from IoT devices into a big data analytic platform in Azure.",
            "category": [
                "iot",
                "analytics"
            ],
            "image": "/azure/architecture/example-scenario/data/media/architecture-realtime-analytics-vehicle-data-1.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\data\\media\\architecture-realtime-analytics-vehicle-data-1.png",
            "publish_date": "3/10/2020",
            "pricing_calculator": "https://azure.com/e/b798fb70c53e4dd19fdeacea4db78276",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "Flow": {
                "FlowStep_A": "Events generated from the IoT data sources are sent to the stream ingestion layer through Azure IoT Hub as a stream of messages. Azure IoT Hub stores streams of data in partitions for a configurable amount of time.",
                "FlowStep_B": "Azure Databricks picks up the message in real time from IoT Hub, processes the data based on the business logic and sends the data to Serving layer for storage.",
                "FlowStep_C": "Downstream storage services, like Azure Cosmos DB, Azure SQL Data warehouse, or Azure SQL DB, will store the IoT data, plus any transactional data, and be a data source for presentation and action layer.",
                "FlowStep_D": "Business analysts can use Microsoft Power BI to analyze warehoused data.",
                "FlowStep_E": "Web, mobile and other applications can be built on the serving layer as well. For example, we can expose APIs based on the serving layer data for third-party uses."
            },
            "name": "realtime-analytics-vehicle-iot",
            "popularity": 204,
            "topic": "Internet of Things"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-customer-360-'",
                "acom-architecture",
                "ai-gallery",
                "all-items",
                "artificial-intelligence",
                "azure",
                "data-flow",
                "example-code",
                "github",
                "interactive-diagram",
                "solution-architectures",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/product-recommendations.md",
            "http_url": "/azure/architecture/solution-ideas/articles/product-recommendations",
            "word_count": 391,
            "read_time": "2 min read",
            "Title": "Product recommendations for retail using Azure",
            "MetaDescription": "This solution implements a process of aggregating customer data into a complete profile, and uses advanced machine learning models backed by the reliability and processing power of Azure to provide predictive insights on simulated customers.",
            "category": [
                "analytics"
            ],
            "image": "/azure/architecture/solution-ideas/media/product-recommendations.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\product-recommendations.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>A deep understanding between customer interests and purchasing patterns is a critical component of any retail business intelligence operation. This solution implements a process of aggregating customer data into a complete profile, and uses advanced machine learning models backed by the reliability and processing power of Azure to provide predictive insights on simulated customers.</p>",
            "Flow": {
                "FlowStep_A": "A Data Generator pipes simulated customer events to an Event Hub",
                "FlowStep_B": "A Stream Analytics job reads from the EventHub, performs aggregations",
                "FlowStep_C": "Stream Analytics persists time-grouped data to an Azure Storage Blob",
                "FlowStep_D": "A Spark job running in HDInsight merges the latest customer browsing data with historical purchase and demographic data to build a consolidated user profile",
                "FlowStep_E": "A second Spark job scores each customer profile against a machine learning model to predict future purchasing patterns (in other words, is a given customer likely to make a purchase in the next 30 days, and if so, in which product category?)"
            },
            "sample_code": true,
            "github_url": "https://github.com/Azure/cortana-intelligence-customer360",
            "name": "product-recommendations",
            "popularity": 0,
            "topic": "Analytics"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "app-modernization",
                "data-flow",
                "example-code",
                "example-workload",
                "fasttrack",
                "github",
                "pricing-calculator",
                "pricing-guidance",
                "web-apps"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/apps/publish-internal-apis-externally.yml",
            "http_url": "/azure/architecture/example-scenario/apps/publish-internal-apis-externally",
            "word_count": 1857,
            "read_time": "8 min read",
            "Title": "Publishing internal APIs to external users",
            "MetaDescription": "In this scenario, an organization consolidates multiple APIs internally using Azure API Management deployed inside a Virtual Network.",
            "category": [
                "integration",
                "hybrid"
            ],
            "image": "/azure/architecture/example-scenario/apps/media/architecture-publish-internal-apis-externally.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\apps\\media\\architecture-publish-internal-apis-externally.png",
            "publish_date": "3/12/2019",
            "pricing_calculator": "https://azure.com/e/0e916a861fac464db61342d378cc0bd6",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-network/virtual-networks-overview\">Azure Virtual Network</a> enables Azure resources to securely communicate with each other, the internet, and on-premises networks.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/dns/private-dns-overview\">Azure Private DNS</a> allows domain names to be resolved in a virtual network without needing to add a custom DNS solution.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/api-management/api-management-key-concepts\">Azure API Management</a> helps organizations publish APIs to external, partner, and internal developers to use their data and services.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/application-gateway/overview\">Application Gateway</a> is a web traffic load balancer that enables you to manage traffic to your web applications.</p>",
                "<p>Internal Load Balancer <a href=\"https://learn.microsoft.com/azure/app-service/environment/intro\">App Service Environment</a> is an Azure App Service feature that provides a fully isolated and dedicated environment for securely running App Service apps at high scale.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/devops/index?view=azure-devops&amp;viewFallbackFrom=vsts\">Azure DevOps</a> is a service for managing your development lifecycle and includes features for planning and project management, code management, build, and release.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/azure-monitor/app/app-insights-overview\">Application Insights</a> is an extensible Application Performance Management (APM) service for web developers on multiple platforms.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/cosmos-db/introduction\">Azure Cosmos DB</a> is Microsoft's globally distributed, multi-model database service.</p>"
            ],
            "Summary": "<p>In this scenario, an organization has hosted multiple APIs using <a href=\"https://learn.microsoft.com/azure/app-service/environment/intro\">Application Service Environments</a>(ILB ASE) and would like to consolidate these APIs internally using <a href=\"https://learn.microsoft.com/azure/api-management/api-management-key-concepts\">Azure API Management (APIM)</a> deployed inside a Virtual Network. The internal API Management instance could also be exposed to external users to allow for utilization of the full potential of the APIs. This external exposure could be achieved using an <a href=\"https://learn.microsoft.com/azure/application-gateway/overview\">Application Gateways</a> forwarding requests to the internal API Management service, which in turn consumes the APIs deployed in the ASE.</p>",
            "Flow": {
                "FlowStep_A": "Developers check in code to a GitHub repository connected to CI/CD pipeline Agent installed on an Azure VM",
                "FlowStep_B": "The agent pushes the build to the API application hosted on ILB ASE",
                "FlowStep_C": "API Management consumes the above APIs via HOST Headers specified in API Management policy",
                "FlowStep_D": "API Management uses the App Service Environment's DNS name for all the APIs",
                "FlowStep_E": "Application Gateway exposes API Management's developer and API portal",
                "FlowStep_F": "Azure Private DNS is used to route the traffic internally between ASE, API Management, and Application Gateway",
                "FlowStep_G": "External Users uses exposed Dev Portal to consume the APIs via Application Gateway's public IP"
            },
            "sample_code": true,
            "github_url": "https://github.com/ssarwa/API-Management-ASE-AppGateway",
            "name": "publish-internal-apis-externally",
            "popularity": 171,
            "topic": "Integration",
            "hybrid-topic": "Data"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-quality-assurance-'",
                "acom-architecture",
                "ai-gallery",
                "all-items",
                "anomaly-detection",
                "artificial-intelligence",
                "azure",
                "data-flow",
                "solution-architectures",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/quality-assurance.md",
            "http_url": "/azure/architecture/solution-ideas/articles/quality-assurance",
            "word_count": 501,
            "read_time": "3 min read",
            "Title": "Quality Assurance",
            "MetaDescription": "Quality assurance systems allow businesses to prevent defects throughout their processes of delivering goods or services to customers. Building such a system that collects data and identifies potential problems along a pipeline can provide enormous advantages. For example, in digital manufacturing, quality assurance across the assembly line is imperative. Identifying slowdowns and potential failures before they occur rather than after they are detected can help companies reduce costs for scrap and rework while improving productivity.",
            "category": [
                "ai-machine-learning",
                "integration"
            ],
            "image": "/azure/architecture/solution-ideas/media/quality-assurance.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\quality-assurance.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Quality assurance systems allow businesses to prevent defects throughout their processes of delivering goods or services to customers. Building such a system that collects data and identifies potential problems along a pipeline can provide enormous advantages. For example, in digital manufacturing, quality assurance across the assembly line is imperative. Identifying slowdowns and potential failures before they occur rather than after they are detected can help companies reduce costs for scrap and rework while improving productivity.</p>\n<p>This solution shows how to predict failures using the example of manufacturing pipelines (assembly lines). This is done by leveraging test systems already in place and failure data, specifically looking at returns and functional failures at the end of assembly line. By combining these with domain knowledge and root cause analysis within a modular design that encapsulates main processing steps, we provide a generic advanced analytics solution that uses machine learning to predict failures before they happen. Early prediction of future failures allows for less expensive repairs or even discarding, which are usually more cost efficient than going through recall and warranty cost.</p>",
            "Flow": {
                "FlowStep_A": "The Manufacturing Assembly Line simulation data is streamed by the newly deployed Azure Web Jobs.",
                "FlowStep_B": "This synthetic data feeds into the Azure Event Hubs as data points/events, that will be consumed in the rest of the solution flow and stored in Azure Synapse Analytics.",
                "FlowStep_C": "There are 2 Azure Stream Analytics jobs used in this pattern to provide near real-time analytics on the input stream from the Azure Event Hub. Both jobs filter through the input data and pass the data points along to an Azure Machine Learning endpoint sending the results to a Power BI Dashboard."
            },
            "name": "quality-assurance",
            "popularity": 39,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-real-time-analytics-'",
                "acom-architecture",
                "advanced-analytics",
                "advanced-analytics-architecture",
                "all-items",
                "data-flow",
                "deep-learning-analytics",
                "interactive-diagram",
                "pricing-calculator",
                "pricing-guidance",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/real-time-analytics.md",
            "http_url": "/azure/architecture/solution-ideas/articles/real-time-analytics",
            "word_count": 491,
            "read_time": "2 min read",
            "Title": "Real Time Analytics on Big Data Architecture",
            "MetaDescription": "Get deep learning analytics and insights live from streaming data. Review logs from website clickstream in near real-time for advanced analytics processing.",
            "category": [
                "analytics",
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/real-time-analytics.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\real-time-analytics.png",
            "publish_date": "12/16/2019",
            "pricing_calculator": "https://azure.com/e/f8f5bc2de0b64aa0ae2dd154e7b6b462",
            "pricing_guidance": "pricing-calculator",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/synapse-analytics\">Azure Synapse Analytics</a> is the fast, flexible and trusted cloud data warehouse that lets you scale, compute and store elastically and independently, with a massively parallel processing architecture.</p>",
                "<p>Azure <a href=\"https://azure.microsoft.com/services/data-factory\">Data Factory</a> is a hybrid data integration service that allows you to create, schedule and orchestrate your ETL/ELT workflows.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage/data-lake-storage\">Azure Data Lake Storage</a>: Massively scalable, secure data lake functionality built on Azure Blob Storage</p>",
                "<p><a href=\"https://azure.microsoft.com/services/databricks\">Azure Databricks</a> is a fast, easy, and collaborative Apache Spark-based analytics platform.</p>",
                "<p>Azure <a href=\"https://azure.microsoft.com/services/hdinsight\">HDInsight</a> is a fully managed, full spectrum open-source analytics service for popular open-source frameworks such as Hadoop, Spark, Hive, LLAP, Kafka, Storm, R &amp; more.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cosmos-db\">Azure Cosmos DB</a> is a globally distributed, multi-model database service. Then learn how to replicate your data across any number of Azure regions and scale your throughput independent from your storage.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/analysis-services\">Azure Analysis Services</a> is an enterprise grade analytics as a service that lets you govern, deploy, test, and deliver your BI solution with confidence.</p>",
                "<p><a href=\"https://powerbi.microsoft.com\">Power BI</a> is a suite of business analytics tools that deliver insights throughout your organization. Connect to hundreds of data sources, simplify data prep, and drive ad hoc analysis. Produce beautiful reports, then publish them for your organization to consume on the web and across mobile devices.</p>"
            ],
            "Summary": "<p>Get insights from live streaming data with ease. Capture data continuously from any IoT device, or logs from website clickstreams, and process it in near-real time.</p>",
            "Flow": {
                "FlowStep_A": "Easily ingest live streaming data for an application using Apache Kafka cluster in Azure HDInsight.",
                "FlowStep_B": "Bring together all your structured data using Azure Data Factory to Azure Blob Storage.",
                "FlowStep_C": "Take advantage of Azure Databricks to clean, transform, and analyze the streaming data, and combine it with structured data from operational databases or data warehouses.",
                "FlowStep_D": "Use scalable machine learning/deep learning techniques, to derive deeper insights from this data using Python, R or Scala, with inbuilt notebook experiences in Azure Databricks.",
                "FlowStep_E": "Leverage native connectors between Azure Databricks and Azure Synapse Analytics to access and move data at scale.",
                "FlowStep_F": "Build analytical dashboards and embedded reports on top of Azure Data Warehouse to share insights within your organization and use Azure Analysis Services to serve this data to thousands of users.",
                "FlowStep_G": "Power users take advantage of the inbuilt capabilities of Azure Databricks and Azure HDInsight to perform root cause determination and raw data analysis.",
                "FlowStep_H": "Take the insights from Azure Databricks to Azure Cosmos DB to make them accessible through real time apps."
            },
            "name": "real-time-analytics",
            "popularity": 181,
            "topic": "Analytics"
        },
        {
            "tags": [
                "ai-ml",
                "all-items",
                "alternative-choices",
                "data-flow",
                "example-workload",
                "pricing-calculator",
                "pricing-guidance"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/data/fraud-detection.yml",
            "http_url": "/azure/architecture/example-scenario/data/fraud-detection",
            "word_count": 957,
            "read_time": "4 min read",
            "Title": "Real-time fraud detection",
            "MetaDescription": "Detect fraudulent activity in real-time using Azure Event Hubs and Stream Analytics.",
            "category": [
                "security",
                "analytics"
            ],
            "image": "/azure/architecture/example-scenario/data/media/architecture-fraud-detection.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\data\\media\\architecture-fraud-detection.png",
            "publish_date": "7/05/2018",
            "pricing_calculator": "https://azure.com/e/74149ec312c049ccba79bfb3cfa67606",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/event-hubs/event-hubs-what-is-event-hubs\">Azure Event Hubs</a> is a real-time streaming platform and event ingestion service, capable of receiving and processing millions of events per second. Event Hubs can process and store events, data, or telemetry produced by distributed software and devices. In this scenario, Event Hubs receives all phone call metadata to be analyzed for fraudulent activity.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/stream-analytics/stream-analytics-introduction\">Azure Stream Analytics</a> is an event-processing engine that can analyze high volumes of data streaming from devices and other data sources. It also supports extracting information from data streams to identify patterns and relationships. These patterns can trigger other downstream actions. In this scenario, Stream Analytics transforms the input stream from Event Hubs to identify fraudulent calls.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/storage/blobs/storage-blobs-introduction\">Blob storage</a> is used in this scenario to store the results of the Stream Analytics job.</p>"
            ],
            "Flow": {
                "FlowStep_A": "Mobile phone call metadata is sent from the source system to an Azure Event Hubs instance.",
                "FlowStep_B": "A Stream Analytics job is started, which receives data via the event hub source.",
                "FlowStep_C": "The Stream Analytics job runs a predefined query to transform the input stream and analyze it based on a fraudulent-transaction algorithm. This query uses a tumbling window to segment the stream into distinct temporal units.",
                "FlowStep_D": "The Stream Analytics job writes the transformed stream representing detected fraudulent calls to an output sink in Azure Blob storage."
            },
            "name": "fraud-detection",
            "popularity": 146,
            "topic": "Security"
        },
        {
            "tags": [
                "all-items",
                "azcat-ai",
                "data-flow",
                "example-code",
                "github",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/ai/real-time-scoring-machine-learning-models.md",
            "http_url": "/azure/architecture/reference-architectures/ai/real-time-scoring-machine-learning-models",
            "word_count": 1980,
            "read_time": "8 min read",
            "Title": "Real-time scoring of Python models",
            "MetaDescription": "This reference architecture shows how to deploy Python models as web services on Azure to make real-time predictions.",
            "category": [
                "ai-machine-learning",
                "developer-tools"
            ],
            "image": "/azure/architecture/reference-architectures/ai/_images/python-model-architecture.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\ai\\_images\\python-model-architecture.png",
            "publish_date": "1/28/2019",
            "Flow": {
                "FlowStep_A": "The trained model is registered to the machine learning model registry.",
                "FlowStep_B": "Machine Learning creates a Docker image that includes the model and scoring script.",
                "FlowStep_C": "Azure Machine Learning deploys the scoring image on Azure Kubernetes Service (AKS) as a web service.",
                "FlowStep_D": "The client sends an HTTP POST request with the encoded question data.",
                "FlowStep_E": "The web service created by Azure Machine Learning extracts the question from the request.",
                "FlowStep_F": "The question is sent to the Scikit-learn pipeline model for featurization and scoring.",
                "FlowStep_G": "The matching FAQ questions with their scores are returned to the client.",
                "FlowStep_H": "The deep learning model is registered to the machine learning model registry.",
                "FlowStep_I": "Azure Machine Learning creates a docker image including the model and scoring script.",
                "FlowStep_J": "Azure Machine Learning deploys the scoring image on Azure Kubernetes Service (AKS) as a web service.",
                "FlowStep_K": "The client sends an HTTP POST request with the encoded image data.",
                "FlowStep_L": "The web service created by Azure Machine Learning preprocesses the image data and sends it to the model for scoring.",
                "FlowStep_M": "The predicted categories with their scores are returned to the client."
            },
            "sample_code": true,
            "github_url": "https://github.com/Microsoft/MLAKSDeployAML",
            "name": "real-time-scoring-machine-learning-models",
            "popularity": 148,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "all-items",
                "azcat-ai",
                "example-code",
                "github",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/ai/realtime-scoring-r.md",
            "http_url": "/azure/architecture/reference-architectures/ai/realtime-scoring-r",
            "word_count": 1138,
            "read_time": "5 min read",
            "Title": "Real-time scoring of R machine learning models",
            "MetaDescription": "Implement a real-time prediction service in R using Machine Learning Server running in Azure Kubernetes Service (AKS).",
            "category": [
                "ai-machine-learning",
                "developer-tools",
                "containers"
            ],
            "image": "/azure/architecture/reference-architectures/ai/_images/realtime-scoring-r.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\ai\\_images\\realtime-scoring-r.png",
            "publish_date": "12/10/2019",
            "sample_code": true,
            "github_url": "https://github.com/microsoft/AMLSDKRModelsOperationalization",
            "name": "realtime-scoring-r",
            "popularity": 50,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-remote-patient-monitoring-'",
                "acom-architecture",
                "ai-ml",
                "all-items",
                "data-flow",
                "healthcare",
                "interactive-diagram",
                "medical-data-analysis",
                "remote-patient-monitoring",
                "remote-patient-monitoring-solutions",
                "remote-patient-monitoring-system",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/remote-patient-monitoring.md",
            "http_url": "/azure/architecture/solution-ideas/articles/remote-patient-monitoring",
            "word_count": 309,
            "read_time": "2 min read",
            "Title": "Remote Patient Monitoring Solutions",
            "MetaDescription": "Provide a high level of preventative medical care with remote patient monitoring from Azure. Analyze large amounts of medical data in a secure environment.",
            "category": [
                "ai-machine-learning",
                "integration"
            ],
            "image": "/azure/architecture/solution-ideas/media/remote-patient-monitoring.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\remote-patient-monitoring.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/iot-hub\">Azure IoT Hub</a>: Connect, monitor and manage billions of IoT assets</p>",
                "<p><a href=\"https://azure.microsoft.com/services/security-center\">Security Center</a>: Unify security management and enable advanced threat protection across hybrid cloud workloads</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cognitive-services\">Cognitive Services</a>: Get started with quickstarts, samples, and tutorials</p>",
                "<p><a href=\"https://azure.microsoft.com/services/key-vault\">Key Vault</a>: Safeguard and maintain control of keys and other secrets</p>",
                "<p><a href=\"https://azure.microsoft.com/services/logic-apps\">Logic Apps</a>: Automate the access and use of data across clouds without writing code</p>",
                "<p><a href=\"https://azure.microsoft.com/services/power-bi-embedded\">Power BI Embedded</a>: Embed fully interactive, stunning data visualizations in your applications</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cosmos-db\">Azure Cosmos DB</a>: Globally distributed, multi-model database for any scale</p>",
                "<p>Application Insights: Detect, triage, and diagnose issues in your web apps and services</p>",
                "<p><a href=\"https://azure.microsoft.com/services/machine-learning-studio\">Machine Learning Studio</a>: Easily build, deploy, and manage predictive analytics solutions</p>",
                "<p><a href=\"https://azure.microsoft.com/services/monitor\">Azure Monitor</a>: Full observability into your applications, infrastructure, and network</p>"
            ],
            "Summary": "<p>Predict and prevent future incidents by combining IoT and intelligence to optimize treatments, using Azure to remotely monitor patients and analyze the massive amounts of data generated by medical devices.</p>",
            "Flow": {
                "FlowStep_A": "Securely ingest medical sensor and device data using Azure IoT Hub.",
                "FlowStep_B": "Securely store sensor and device data in Azure Cosmos DB.",
                "FlowStep_C": "Analyze sensor and device data using a pre-trained Cognitive Services API or a custom developed Machine Learning model.",
                "FlowStep_D": "Store Artificial Intelligence (AI) and Machine Learning results in Azure Cosmos DB.",
                "FlowStep_E": "Interact AI and Machine Learning results using Power BI, while preserving Role-Based Access Control (RBAC).",
                "FlowStep_F": "Integrate data insights with backend systems and processes using Logic Apps."
            },
            "name": "remote-patient-monitoring",
            "popularity": 72,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "all-items",
                "data-flow",
                "example-workload",
                "fcp"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/iot/vertical-buy-online-pickup-in-store.md",
            "http_url": "/azure/architecture/example-scenario/iot/vertical-buy-online-pickup-in-store",
            "word_count": 1511,
            "read_time": "6 min read",
            "Title": "Retail - Buy online, pickup in store (BOPIS)",
            "MetaDescription": "Learn about how Azure IoT can help a retail solution for stores implementing buy online, pickup in store scenarios.",
            "category": [
                "iot"
            ],
            "image": "/azure/architecture/example-scenario/iot/media/bopis.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\iot\\media\\bopis.png",
            "publish_date": "10/01/2020",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/iot-edge/\">Azure IoT Edge</a> runs analytics, applications on-premise to ensure</p>",
                "<p><a href=\"https://azure.microsoft.com/services/media-services/live-video-analytics/\">Live Video Analytics</a> on IoT Edge offers the</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cognitive-services/\">Azure Cognitive Services</a> allows the AI model to run on the</p>",
                "<p><a href=\"https://azure.microsoft.com/services/iot-central/\">Azure IoT Central</a> is a fully managed application platform that reduces the burden and cost of developing, managing, and maintaining enterprise-grade IoT solutions. </p>",
                "<p><a href=\"https://azure.microsoft.com/services/event-hubs/\">Event Hubs</a> are used to queue the events sent to the curbside pickup</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage/\">Azure Storage</a> is used to store raw data for analysis. Contoso has decided to use this service as they are storing the objects in flat namespace.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/functions/\">Azure Functions</a> is a serverless service used to process the events</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cosmos-db/\">Azure Cosmos DB</a> provides a low-latency database with guaranteed availability and automatic scalability. Contoso requires low latency reads and write for seamless user experience. The curbside pickup application uses NoSQL document to store the data because of the variety in order SKU. As the application is available throughout Europe, Contoso wants a turn key database that provides multi-master read and write. </p>",
                "<p><a href=\"https://azure.microsoft.com/services/kubernetes-service/\">Azure Kubernetes Service</a>.  The curbside pickup application is based on a microservice design. </p>",
                "<p><a href=\"https://azure.microsoft.com/services/azure-maps/\">Azure Maps</a> provides geofencing as a service required to</p>",
                "<p><a href=\"https://azure.microsoft.com/en-us/services/notification-hubs/\">Azure Notification Hubs</a> is a massively scalable mobile push notification engine for quickly sending millions of notifications to iOS, Android, Windows. Using this service, Contoso can easily broadcast notifications to their customers. </p>"
            ],
            "Summary": "<p>Contoso is a European retailer operating mid-sized supermarkets. They\nhave grown through the years and are now one of the largest retailers, with more\nthan 1000 stores located in both cities and suburbs.</p>",
            "Flow": {
                "FlowStep_A": " Video feed is obtained as cars come into the parking area. The IP",
                "FlowStep_B": " Azure IoT Central is used because it is a fully managed application platform. It allows Contoso to extend it easily and focus on features that directly impacts business. ",
                "FlowStep_C": " License plate details are queued in Event hub which routes it to an Azure",
                "FlowStep_D": " The license plate details are sent to the curbside pickup",
                "FlowStep_E": " The license plate details are cross-referenced with the",
                "FlowStep_F": " The curbside pickup application also uses Azure Maps geofence",
                "FlowStep_G": "Once the store associate begins on the task, the application will",
                "FlowStep_H": "Order pickup details are written back into storage so that"
            },
            "name": "vertical-buy-online-pickup-in-store",
            "popularity": 0,
            "topic": "Internet of Things"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-retail-assistant-or-vacation-planner-with-visual-capabilities-'",
                "acom-architecture",
                "ai-ml",
                "all-items",
                "chatbot",
                "cognitive-services",
                "data-flow",
                "ecommerce",
                "interactive-diagram",
                "retail-assistant",
                "solution-idea",
                "vacation-planner",
                "visual-capabilities"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/retail-assistant-or-vacation-planner-with-visual-capabilities.md",
            "http_url": "/azure/architecture/solution-ideas/articles/retail-assistant-or-vacation-planner-with-visual-capabilities",
            "word_count": 91,
            "read_time": "1 min read",
            "Title": "Retail Assistant with Visual Capabilities",
            "MetaDescription": "The retail assistant or vacation planner can help your customers have interactions with your business bot and provide suggestions based on the visual information.",
            "category": [
                "ai-machine-learning",
                "web"
            ],
            "image": "/azure/architecture/solution-ideas/media/retail-assistant-or-vacation-planner-with-visual-capabilities.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\retail-assistant-or-vacation-planner-with-visual-capabilities.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>The retail assistant or vacation planner can help your customers have interactions with your business bot and provide suggestions based on the visual information.</p>",
            "Flow": {
                "FlowStep_A": "Users interact with your business assistant",
                "FlowStep_B": "Assistant understands context from LUIS",
                "FlowStep_C": "Assistant passes visual context to the Bing Visual Search API"
            },
            "name": "retail-assistant-or-vacation-planner-with-visual-capabilities",
            "popularity": 11,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-retail-and-ecommerce-using-azure-database-for-mysql-'",
                "acom-architecture",
                "all-items",
                "azure",
                "ecommerce",
                "mysql",
                "solution-idea",
                "solutions",
                "use-cases",
                "web-app"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/retail-and-ecommerce-using-azure-database-for-mysql.md",
            "http_url": "/azure/architecture/solution-ideas/articles/retail-and-ecommerce-using-azure-database-for-mysql",
            "word_count": 55,
            "read_time": "1 min read",
            "Title": "Retail and e-commerce using Azure MySQL",
            "MetaDescription": "Build secure and scalable e-commerce solutions that meet the demands of both customers and business using Azure Database for MySQL.",
            "category": [
                "databases",
                "web"
            ],
            "image": "/azure/architecture/solution-ideas/media/retail-and-ecommerce-using-azure-database-for-mysql.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\retail-and-ecommerce-using-azure-database-for-mysql.png",
            "publish_date": "12/16/2019",
            "name": "retail-and-ecommerce-using-azure-database-for-mysql",
            "popularity": 44,
            "topic": "Databases"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-retail-and-ecommerce-using-azure-database-for-postgresql-'",
                "acom-architecture",
                "all-items",
                "azure",
                "ecommerce",
                "postgresql",
                "solution-idea",
                "solutions",
                "use-cases",
                "web-app"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/retail-and-ecommerce-using-azure-database-for-postgresql.md",
            "http_url": "/azure/architecture/solution-ideas/articles/retail-and-ecommerce-using-azure-database-for-postgresql",
            "word_count": 49,
            "read_time": "1 min read",
            "Title": "Retail and e-commerce using Azure PostgreSQL",
            "MetaDescription": "Build secure and scalable e-commerce solutions that meet the demands of both customers and business using Azure Database for PostgreSQL.",
            "category": [
                "databases",
                "web"
            ],
            "image": "/azure/architecture/solution-ideas/media/retail-and-ecommerce-using-azure-database-for-postgresql.svg",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\retail-and-ecommerce-using-azure-database-for-postgresql.svg",
            "publish_date": "12/16/2019",
            "name": "retail-and-ecommerce-using-azure-database-for-postgresql",
            "popularity": 35,
            "topic": "Databases"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-retail-and-e-commerce-using-cosmos-db-'",
                "acom-architecture",
                "all-items",
                "cosmos-db",
                "ecommerce",
                "solution-idea",
                "web-apps"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/retail-and-e-commerce-using-cosmos-db.md",
            "http_url": "/azure/architecture/solution-ideas/articles/retail-and-e-commerce-using-cosmos-db",
            "word_count": 32,
            "read_time": "1 min read",
            "Title": "Retail and e-commerce using Azure Cosmos DB",
            "MetaDescription": "Support in-depth queries over diverse product catalogs, traffic spikes, and rapidly changing inventory.",
            "category": [
                "databases",
                "web"
            ],
            "image": "/azure/architecture/solution-ideas/media/retail-and-e-commerce-using-cosmos-db.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\retail-and-e-commerce-using-cosmos-db.png",
            "publish_date": "12/16/2019",
            "name": "retail-and-e-commerce-using-cosmos-db",
            "popularity": 125,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "example-code",
                "fcp",
                "github",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/sap/run-sap-bw4hana-with-linux-virtual-machines.yml",
            "http_url": "/azure/architecture/reference-architectures/sap/run-sap-bw4hana-with-linux-virtual-machines",
            "word_count": 2716,
            "read_time": "11 min read",
            "Title": "Run SAP BW/4HANA with Linux virtual machines on Azure",
            "MetaDescription": "This example focuses specifically on the SAP BW/4HANA application tier and is suitable for a small-scale production environment of SAP BW/4HANA on Azure where high availability is a priority.",
            "category": [
                "databases",
                "compute"
            ],
            "image": "/azure/architecture/reference-architectures/sap/images/sap-bw4hana.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\sap\\images\\sap-bw4hana.png",
            "publish_date": "6/10/2020",
            "alternative_choices": "alternatives",
            "sample_code": true,
            "github_url": "https://github.com/msftphleiten/proximity-placement-groups",
            "name": "run-sap-bw4hana-with-linux-virtual-machines",
            "popularity": 0,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "fcp",
                "github",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/sap/run-sap-hana-for-linux-virtual-machines.yml",
            "http_url": "/azure/architecture/reference-architectures/sap/run-sap-hana-for-linux-virtual-machines",
            "word_count": 2300,
            "read_time": "10 min read",
            "Title": "Run SAP HANA for Linux virtual machines in a scale-up architecture on Azure",
            "MetaDescription": "Proven practices for running SAP HANA in a high-availability, scale-up environment that supports disaster recovery on Azure.",
            "category": [
                "databases",
                "compute"
            ],
            "image": "/azure/architecture/reference-architectures/sap/images/sap-hana-scaleup.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\sap\\images\\sap-hana-scaleup.png",
            "publish_date": "6/10/2020",
            "sample_code": true,
            "github_url": "https://github.com/msftphleiten/proximity-placement-groups",
            "name": "run-sap-hana-for-linux-virtual-machines",
            "popularity": 0,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "github",
                "reference-architecture",
                "sap",
                "seodec18",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/sap/hana-large-instances.yml",
            "http_url": "/azure/architecture/reference-architectures/sap/hana-large-instances",
            "word_count": 2914,
            "read_time": "11 min read",
            "Title": "Run SAP HANA on Azure (Large Instances)",
            "MetaDescription": "Proven practices for running SAP HANA in a high availability environment on Azure Large Instances.",
            "category": [
                "databases",
                "compute"
            ],
            "image": "/azure/architecture/reference-architectures/sap/images/sap-hana-large-instances.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\sap\\images\\sap-hana-large-instances.png",
            "publish_date": "4/02/2020",
            "sample_code": true,
            "github_url": "https://github.com/Azure/hana-large-instances-self-service-scripts",
            "visio_diagram": "https://arch-center.azureedge.net/sap-reference-architectures.vsdx",
            "name": "hana-large-instances",
            "popularity": 180,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "fcp",
                "github",
                "reference-architecture",
                "sap",
                "seodec18",
                "visio-diagram",
                "windows"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/sap/sap-netweaver.yml",
            "http_url": "/azure/architecture/reference-architectures/sap/sap-netweaver",
            "word_count": 5422,
            "read_time": "21 min read",
            "Title": "Run SAP NetWeaver in Windows on Azure",
            "MetaDescription": "Proven practices for running SAP NetWeaver in a Windows environment on Azure with high availability.",
            "category": [
                "databases",
                "management-and-governance"
            ],
            "image": "/azure/architecture/reference-architectures/sap/images/sap-netweaver.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\sap\\images\\sap-netweaver.png",
            "publish_date": "2/19/2020",
            "sample_code": true,
            "github_url": "https://github.com/Azure/SAP-on-Azure-Scripts-and-Utilities",
            "visio_diagram": "https://arch-center.azureedge.net/sap-netweaver.vsdx",
            "name": "sap-netweaver",
            "popularity": 176,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "devops",
                "example-code",
                "example-workload",
                "github",
                "seodec18",
                "visio-diagram"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/apps/jenkins.yml",
            "http_url": "/azure/architecture/example-scenario/apps/jenkins",
            "word_count": 2671,
            "read_time": "10 min read",
            "Title": "Run a Jenkins server on Azure",
            "MetaDescription": "Recommended architecture that shows how to deploy and operate a scalable, enterprise-grade Jenkins server on Azure secured with single sign-on (SSO).",
            "category": [
                "devops"
            ],
            "image": "/azure/architecture/example-scenario/apps/media/architecture-jenkins.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\apps\\media\\architecture-jenkins.png",
            "publish_date": "4/30/2018",
            "Summary": "<p>This scenario shows how to deploy and operate a scalable, enterprise-grade Jenkins server on Azure secured with single sign-on (SSO). The architecture also uses Azure Monitor to monitor the state of the Jenkins server. <a href=\"#deploy-the-solution\"><strong>Deploy this solution</strong></a>.</p>\n<p><img alt=\"Jenkins server running on Azure\" src=\"https://learn.microsoft.com/azure/architecture/example-scenario/apps/media/architecture-jenkins.png\" /></p>\n<p><em>Download a <a href=\"https://arch-center.azureedge.net/Jenkins-architecture.vsdx\">Visio file</a> that contains this architecture diagram.</em></p>\n<p>This architecture supports disaster recovery with Azure services but does not cover more advanced scale-out scenarios involving multiple primaries or high availability (HA) with no downtime. For general insights about the various Azure components, including a step-by-step tutorial about building out a CI/CD pipeline on Azure, see <a href=\"https://learn.microsoft.com/azure/jenkins\">Jenkins on Azure</a>.</p>\n<p>The focus of this document is on the core Azure operations needed to support Jenkins, including the use of Azure Storage to maintain build artifacts, the security items needed for SSO, other services that can be integrated, and scalability for the pipeline. The architecture is designed to work with an existing source control repository. For example, a common scenario is to start Jenkins jobs based on GitHub commits.</p>",
            "sample_code": true,
            "github_url": "https://github.com/Azure/jenkins/tree/master/disaster_recovery",
            "visio_diagram": "https://arch-center.azureedge.net/Jenkins-architecture.vsdx",
            "name": "jenkins",
            "popularity": 175,
            "topic": "DevOps"
        },
        {
            "tags": [
                "all-items",
                "azurecli",
                "example-code",
                "reference-architecture",
                "seodec18"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/n-tier/linux-vm.yml",
            "http_url": "/azure/architecture/reference-architectures/n-tier/linux-vm",
            "word_count": 2103,
            "read_time": "8 min read",
            "Title": "Run a Linux VM on Azure",
            "MetaDescription": "Learn the best practices for running a Linux virtual machine on Azure, which requires some additional components, including networking and storage resources.",
            "category": [
                "compute"
            ],
            "image": "/azure/architecture/reference-architectures/n-tier/images/single-vm-diagram.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\n-tier\\images\\single-vm-diagram.png",
            "publish_date": "12/13/2018",
            "Summary": "<p>Provisioning a virtual machine (VM) in Azure requires some additional components besides the VM itself, including networking and storage resources. This article shows best practices for running a Linux VM on Azure.</p>\n<p><img alt=\"Linux VM in Azure\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/n-tier/images/single-vm-diagram.png\" /></p>",
            "code_languages": [
                "azurecli"
            ],
            "sample_code": true,
            "name": "linux-vm",
            "popularity": 177,
            "topic": "Compute"
        },
        {
            "tags": [
                "all-items",
                "azurecli",
                "example-code",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/n-tier/windows-vm.yml",
            "http_url": "/azure/architecture/reference-architectures/n-tier/windows-vm",
            "word_count": 1858,
            "read_time": "7 min read",
            "Title": "Run a Windows VM on Azure",
            "MetaDescription": "Learn the best practices for running a Windows virtual machine on Azure, which requires some additional components, including networking and storage resources.",
            "category": [
                "compute"
            ],
            "image": "/azure/architecture/reference-architectures/n-tier/images/single-vm-diagram.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\n-tier\\images\\single-vm-diagram.png",
            "publish_date": "12/13/2018",
            "Summary": "<p>Provisioning a virtual machine (VM) in Azure requires some additional components besides the VM itself, including networking and storage resources. This article shows best practices for running a Windows VM on Azure.</p>\n<p><img alt=\"Windows VM in Azure\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/n-tier/images/single-vm-diagram.png\" /></p>",
            "code_languages": [
                "azurecli"
            ],
            "sample_code": true,
            "name": "windows-vm",
            "popularity": 207,
            "topic": "Compute"
        },
        {
            "tags": [
                "all-items",
                "bash",
                "example-code",
                "github",
                "reference-architecture",
                "seodec18",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/sharepoint/index.md",
            "http_url": "/azure/architecture/reference-architectures/sharepoint",
            "word_count": 3435,
            "read_time": "13 min read",
            "Title": "Run a highly available SharePoint Server 2016 farm in Azure",
            "MetaDescription": "Recommended architecture for deploying a high availability SharePoint Server 2016 farm in Azure.",
            "category": [
                "management-and-governance",
                "web"
            ],
            "image": "/azure/architecture/reference-architectures/sharepoint/images/sharepoint-ha.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\sharepoint\\images\\sharepoint-ha.png",
            "publish_date": "7/26/2018",
            "Summary": "<p>This reference architecture shows proven practices for deploying a highly available SharePoint Server 2016 farm on Azure, using MinRole topology and SQL Server Always On availability groups. The SharePoint farm is deployed in a secured virtual network with no Internet-facing endpoint or presence. <a href=\"#deploy-the-solution\"><strong>Deploy this solution</strong></a>.</p>\n<p><img alt=\"Reference architecture for a highly available SharePoint Server 2016 farm in Azure\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/images/sharepoint-ha.png\" /></p>\n<p><em>Download a <a href=\"https://arch-center.azureedge.net/Sharepoint-2016.vsdx\">Visio file</a> of this architecture.</em></p>",
            "sample_code": true,
            "github_url": "https://github.com/mspnp/template-building-blocks/wiki/Install-Azure-Building-Blocks",
            "visio_diagram": "https://arch-center.azureedge.net/Sharepoint-2016.vsdx",
            "code_languages": [
                "bash"
            ],
            "name": "sharepoint",
            "popularity": 135,
            "topic": "Management and Governance"
        },
        {
            "tags": [
                "all-items",
                "fcp",
                "reference-architecture",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "hybrid/hybrid-containers.md",
            "http_url": "/azure/architecture/hybrid/hybrid-containers",
            "word_count": 1707,
            "read_time": "6 min read",
            "Title": "Run containers in a hybrid environment",
            "MetaDescription": "Run containers from an enterprise container registry on-premises and in Azure",
            "category": [
                "hybrid",
                "devops"
            ],
            "image": "/azure/architecture/hybrid/images/hybrid-containers.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\hybrid\\images\\hybrid-containers.png",
            "publish_date": "6/29/2020",
            "Summary": "<p>This reference architecture illustrates how developers can create, manage, and monitor deployed containers in the public cloud, across multiple clouds, and on-premises.</p>\n<p><img alt=\"The diagram illustrates a developer team that deploys its container images to a Microsoft Azure Container Registry. Subsequently, the container images are pulled and deployed to either an on-premises or cloud-based Kubernetes cluster. The containers are monitored using Azure Monitor and the container images are scanned and monitored using Azure Container Registry.\" src=\"https://learn.microsoft.com/azure/architecture/hybrid/images/hybrid-containers.png\" /></p>\n<p><em>Download a <a href=\"https://arch-center.azureedge.net/hybrid-containers.vsdx\">Visio file</a> of this architecture.</em></p>\n<p>Typical uses for this architecture include:</p>\n<ul>\n<li>Web applications with internal and external components that deploy both to the public cloud and on-premises by using shared container images.</li>\n<li>Modern deployment testing cycles with quality analysis, testing, development, or staging that's hosted on-premises and in the public cloud.</li>\n</ul>",
            "visio_diagram": "https://arch-center.azureedge.net/hybrid-containers.vsdx",
            "name": "hybrid-containers",
            "popularity": 0,
            "topic": "DevOps",
            "hybrid-topic": "Apps"
        },
        {
            "tags": [
                "all-items",
                "data-flow",
                "example-code",
                "example-workload",
                "fcp",
                "github"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/infrastructure/reservoir-simulation.md",
            "http_url": "/azure/architecture/example-scenario/infrastructure/reservoir-simulation",
            "word_count": 1127,
            "read_time": "5 min read",
            "Title": "Run reservoir simulation software on Azure",
            "MetaDescription": "Run OPM Flow reservoir simulation software and OPM ResInsight visualization software on an Azure HPC compute cluster and visualization VM.",
            "category": [
                "compute"
            ],
            "image": "/azure/architecture/example-scenario/infrastructure/media/architecture-hpc-reservoir-simulation.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\infrastructure\\media\\architecture-hpc-reservoir-simulation.png",
            "publish_date": "3/16/2020",
            "Summary": "<p><em>Reservoir simulation</em> uses data-intensive computer models to predict complex flows of fluids such as oil, water, and gas beneath the earth's surface. This example sets up reservoir simulation software on an Azure high-performance computing (HPC) infrastructure. Azure makes it possible to run this type of workload with maximum performance, scalability, and cost efficiency.</p>\n<p>The architecture in this example supports OPM Flow, a popular open-source oil and gas reservoir simulation package from the Open Porous Media (OPM) initiative. The OPM Flow software runs on Azure HPC virtual machines (VMs) that deliver performance near or better than current on-premises infrastructures.</p>\n<p>Users connect to a Linux head node VM to submit models to the HPC resources through PBS Pro 19.1 job-scheduling software. The HPC resources run OPM Flow and send calculated results to a file share. In this example, the file share is a 4-terabyte (TB) network file system (NFS) space on the head node VM. Depending on your model and your input and output (I/O) requirements, you can use other <a href=\"#storage\">storage</a> options.</p>\n<p>A Windows Azure VM running OPM ResInsight, an open-source visualization tool, accesses the file share to <a href=\"https://techcommunity.microsoft.com/t5/azurecat/remote-visualization-in-azure/ba-p/745184\">model and visualize</a> the calculated results. Users can connect to the VM via remote desktop protocol (RDP) to view the visualizations.</p>\n<p>Using an Azure VM spares the expense of a high-end visualization workstation. The OPM applications benefit from HPC hardware and a shared storage location for the input and output files.</p>",
            "Flow": {
                "FlowStep_A": "Users sign in to the head node via SSH to prepare their models for the compute resources.",
                "FlowStep_B": "PBS Pro 19.1 runs on the head node and schedules the jobs on the compute nodes.",
                "FlowStep_C": "OPM Flow runs on the compute nodes. The compute VMs are deployed as a [virtual machine scale set][vmss], a group of identical VMs that scale to meet the demands of the compute tasks.",
                "FlowStep_D": "OPM Flow sends calculated results to a file share on the head node. A [premium disk][disk] is connected to the head node and set up as an NFS server for the compute nodes and the visualization VM.",
                "FlowStep_E": "OPM ResInsight running on a Standard-NV6 Windows VM displays 3D visualizations of results. Users can access the visualization VM through RDP."
            },
            "sample_code": true,
            "github_url": "https://github.com/Azure/azurehpc/tree/master/examples",
            "name": "reservoir-simulation",
            "popularity": 0,
            "topic": "Compute"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "example-code",
                "example-workload",
                "fasttrack",
                "github",
                "hpc",
                "is-deployable",
                "pricing-calculator",
                "pricing-guidance"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/infrastructure/hpc-cfd.yml",
            "http_url": "/azure/architecture/example-scenario/infrastructure/hpc-cfd",
            "word_count": 1084,
            "read_time": "5 min read",
            "Title": "Running CFD simulations",
            "MetaDescription": "Learn about running Computational Fluid Dynamics simulations using Azure. Create, manage, and optimize clusters using Azure CycleCloud.",
            "category": [
                "compute",
                "storage"
            ],
            "image": "/azure/architecture/example-scenario/infrastructure/media/architecture-hpc-cfd.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\infrastructure\\media\\architecture-hpc-cfd.png",
            "publish_date": "9/20/2018",
            "deployable": "https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2FCycleCloudCommunity%2Fcyclecloud_arm%2Fmaster%2Fazuredeploy.json",
            "pricing_calculator": "https://azure.com/e/53030a04a2ab47a289156e2377a4247a",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/cyclecloud\">Azure CycleCloud</a> a tool for creating, managing, operating, and optimizing HPC and Big Compute clusters in Azure.</p>",
                "<p><a >Avere vFXT on Azure</a> is used to provide an enterprise-scale clustered file system built for the cloud.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-machines\">Azure Virtual Machines (VMs)</a> are used to create a static set of compute instances.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-machine-scale-sets/overview\">Virtual machine scale sets</a> provide a group of identical VMs capable of being scaled up or down by Azure CycleCloud.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/storage/common/storage-introduction\">Azure Storage accounts</a> are used for synchronization and data retention.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-network/virtual-networks-overview\">Virtual Networks</a> enable many types of Azure resources, such as Azure Virtual Machines (VMs), to securely communicate with each other, the internet, and on-premises networks.</p>"
            ],
            "sample_code": true,
            "github_url": "https://github.com/Azure/Avere/blob/master/README.md",
            "name": "hpc-cfd",
            "popularity": 134,
            "topic": "Compute"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-reference-architecture-for-oracle-database-on-azure-'",
                "acom-architecture",
                "all-items",
                "data",
                "data-flow",
                "interactive-diagram",
                "oracle",
                "oracle-database",
                "oracle-db",
                "oracle-db-architecture",
                "oracle-on-azure",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/reference-architecture-for-oracle-database-on-azure.md",
            "http_url": "/azure/architecture/solution-ideas/articles/reference-architecture-for-oracle-database-on-azure",
            "word_count": 222,
            "read_time": "2 min read",
            "Title": "Running Oracle Databases on Azure",
            "MetaDescription": "This solution architecture illustrates a canonical architecture to achieve high availability for your Oracle Database Enterprise Edition in Azure.",
            "category": [
                "databases",
                "management-and-governance"
            ],
            "image": "/azure/architecture/solution-ideas/media/reference-architecture-for-oracle-database-on-azure.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\reference-architecture-for-oracle-database-on-azure.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>This solution architecture illustrates a canonical architecture to achieve high availability for your Oracle Database Enterprise Edition in Azure. High availability for your front-end as well as the middle tier can be obtained by using Azure Load Balancers or Application Gateways. An uptime availability of 99.99% for your database tier can be achieved using a combination of Azure Availability Zones and Oracle Active DataGuard with FSFO. For additional availability and/or Disaster Recovery, consider deploying another Database VM in a different Azure region and schedule frequent RMAN backups.</p>",
            "Flow": {
                "FlowStep_A": "The client system accesses a custom application with Oracle DB backend via the web.",
                "FlowStep_B": "Web front end is configured in a load balancer.",
                "FlowStep_C": "Web front end makes a call to the appropriate Application Server to handle the work.",
                "FlowStep_D": "Application server queries primary Oracle Database.",
                "FlowStep_E": "Oracle Database has been configured using a HyperThreaded Virtual Machine with multiple Premium storage-based Managed Disks for performance and availability.",
                "FlowStep_F": "Oracle databases are replicated with Oracle DataGuard (or Active DataGuard) or Oracle GoldenGate for HA and DR purposes."
            },
            "name": "reference-architecture-for-oracle-database-on-azure",
            "popularity": 32,
            "topic": "Databases"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-sap-netweaver-on-sql-server-'",
                "acom-architecture",
                "all-items",
                "azure-sql-server",
                "azure-virtual-machine",
                "data-flow",
                "interactive-diagram",
                "sap",
                "sap-netweaver",
                "sap-on-azure",
                "solution-idea",
                "sql-server"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/sap-netweaver-on-sql-server.yml",
            "http_url": "/azure/architecture/solution-ideas/articles/sap-netweaver-on-sql-server",
            "word_count": 392,
            "read_time": "2 min read",
            "Title": "SAP NetWeaver on SQL Server",
            "MetaDescription": "The NetWeaver on SQL Server application solution illustrates how a user request flows through an SAP landscape built on NetWeaver by utilizing Azure Virtual Machines to host SAP applications and a SQL Server database.",
            "category": [
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/sap-netweaver-on-sql-server.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\sap-netweaver-on-sql-server.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p>Information on <a href=\"https://azure.microsoft.com/services/virtual-machines\">Virtual Machines</a> for SAP application servers.</p>",
                "<p>Microsoft Azure <a href=\"https://azure.microsoft.com/services/storage/disks\">Premium Storage</a> provides improved throughput and less variability in I/O latencies. For improved performance, <a href=\"https://azure.microsoft.com/services/storage/disks\">Premium Storage</a> uses solid state disk (SSD) in Azure Storage nodes, and read cache that's backed by the local SSD of an Azure compute node.</p>"
            ],
            "Summary": "<p>This NetWeaver on SQL Server application solution illustrates how a user request flows through an SAP landscape built on NetWeaver using Azure Virtual Machines to host SAP applications and a SQL Server database. This system takes advantage of OS clustering for high availability, premium storage for faster storage performance and scalability, SQL Server AlwaysOn capability for replication, and a full disaster recovery (DR) configuration for 99.95 percent system availability.</p>",
            "Flow": {
                "FlowStep_A": "Using Azure Active Directory synchronized with on-premises Active Directory, SAP application user authenticates from on-premises to SAP landscape on Azure with single sign-on credentials.",
                "FlowStep_B": "Azure high-speed ExpressRoute Gateway connects on-premises network to Azure virtual machines and other resources securely.",
                "FlowStep_C": "Sales order request flows into highly available SAP ABAP SAP Central Services (ASCS), and then through SAP application servers running on Azure Virtual Machines scale out file server in an Azure VM",
                "FlowStep_D": "The request moves from the SAP app server to SQL Server running on a primary high-performance Azure VM.",
                "FlowStep_E": "Primary (active) and secondary (standby) servers running on SAP certified virtual machines are clustered at OS level for 99.95 percent availability.  Data replication is handled through SQL Server AlwaysOn in synchronous mode from primary to secondary, enabling zero Recovery Point Objective (RPO).",
                "FlowStep_F": "SQL Server data is persisted to high-performance Azure Premium Storage.",
                "FlowStep_G": "SQL Server data is replicated Disaster recovery virtual machine in another Azure region through Azure's high speed backbone network and using SQL Server's AlwaysOn replication in asynchronous mode. The disaster recovery VM can be smaller than the production VM to save costs.",
                "FlowStep_H": "VMs on the disaster recovery region can be used for nonproduction work to save costs.",
                "FlowStep_I": "SAP app server with ASCS on disaster recovery side can be in standby shutdown mode, and can be started when needed to save costs."
            },
            "name": "sap-netweaver-on-sql-server",
            "popularity": 46,
            "topic": "Databases"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-sap-s4-hana-on-hli-with-ha-and-dr-'",
                "acom-architecture",
                "all-items",
                "azure-hana-large-instances",
                "data-flow",
                "interactive-diagram",
                "sap",
                "sap-hana-large-instances",
                "sap-hana-on-azure-large-instances",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/sap-s4-hana-on-hli-with-ha-and-dr.md",
            "http_url": "/azure/architecture/solution-ideas/articles/sap-s4-hana-on-hli-with-ha-and-dr",
            "word_count": 552,
            "read_time": "3 min read",
            "Title": "SAP S/4 HANA for Large Instances",
            "MetaDescription": "Learn more about SAP HANA on Azure for large instances that includes high reliability and disaster recovery. Find out how NFS storage is used for large instances of SAP HANA.",
            "category": [
                "web",
                "storage",
                "compute"
            ],
            "image": "/azure/architecture/solution-ideas/media/sap-s4-hana-on-hli-with-ha-and-dr.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\sap-s4-hana-on-hli-with-ha-and-dr.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/virtual-machines/sap-hana\">SAP HANA on Azure large instances</a>: SAP HANA on Azure (large instances) run on dedicated blade servers located in a Microsoft Azure Datacenter. This is specific to the database server.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage/files\">NFS storage for Azure HANA large instances</a>: The Azure high performance NFS storage system offers the unmatched capability to perform snapshot backups, and replication to secondary storage.  In addition, HANA Large Instance is the only cloud infrastructure to provide storage volume encryption.</p>",
                "<p>SAP on Azure requires that you run your SAP workloads on certified Microsoft Azure <a href=\"https://azure.microsoft.com/services/virtual-machines\">Virtual Machines</a>. SAP requires at least two vCPUs and a ratio of 6:1 between memory and vCPU.</p>",
                "<p>Microsoft Azure <a href=\"https://azure.microsoft.com/services/storage/disks\">Premium Storage</a> provides improved throughput and less variability in I/O latencies. For improved performance, <a href=\"https://azure.microsoft.com/services/storage/disks\">Premium Storage</a> uses solid state disk (SSD) in Azure Storage nodes and read cache that's backed by the local SSD of an Azure compute node.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/expressroute\">ExpressRoute (front end)</a>: Azure ExpressRoute used on the front end (see diagram) provides secure, high-bandwidth connectivity to establish reliable connections between your network and the Microsoft Azure network.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/expressroute\">ExpressRoute (back end)</a>: Azure ExpressRoute used on the back end (see diagram) enables you to communicate between your Azure components in the Azure Datacenter and your SAP HANA on Azure (large instance) systems. The cost of the back end ExpressRoute is included in your SAP HANA on Azure (large instance).</p>"
            ],
            "Flow": {
                "FlowStep_A": "In this example, an on-premises SAP user executes a sales order via Fiori interface, custom interface, or other.",
                "FlowStep_B": "Azure high-speed ExpressRoute gateway is used to connect to Azure Virtual Machines.",
                "FlowStep_C": "Request flows into highly available ABAP SAP Central Services (ASCS) and then through application servers running on Azure Virtual Machines in an availability set offering a 99.95 percent uptime SLA.",
                "FlowStep_D": "Request is sent from App Server to SAP HANA running on primary large instance blades.",
                "FlowStep_E": "Primary and secondary blades are clustered at OS level for 99.99 percent availability, and data replication is handled through HANA System Replication in synchronous mode (HSR) from primary to secondary enabling zero RPO.",
                "FlowStep_F": "In-memory data of SAP HANA is persisted to high-performance NFS storage.",
                "FlowStep_G": "Data from NFS storage is periodically backed up in seconds, using built-in storage snapshots on the local storage, with no impact to database performance.",
                "FlowStep_H": "Persistent data volume on secondary storage is replicated to dedicated DR system through a dedicated backbone network for HANA storage replication.",
                "FlowStep_I": "Large instance on DR side can be used for nonproduction to save costs by mounting both the QA storage and DR replicated volume (read-only)."
            },
            "name": "sap-s4-hana-on-hli-with-ha-and-dr",
            "popularity": 58,
            "topic": "Web"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "fcp",
                "github",
                "linux",
                "reference-architecture",
                "sap",
                "seodec18",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/sap/sap-s4hana.yml",
            "http_url": "/azure/architecture/reference-architectures/sap/sap-s4hana",
            "word_count": 5618,
            "read_time": "22 min read",
            "Title": "SAP S/4HANA in Linux on Azure",
            "MetaDescription": "Proven practices for running SAP S/4HANA in a Linux environment on Azure with high availability.",
            "category": [
                "databases",
                "management-and-governance"
            ],
            "image": "/azure/architecture/reference-architectures/sap/images/sap-s4hana.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\sap\\images\\sap-s4hana.png",
            "publish_date": "2/19/2020",
            "sample_code": true,
            "github_url": "https://github.com/msftphleiten/proximity-placement-groups",
            "visio_diagram": "https://arch-center.azureedge.net/sap-s4hana.vsdx",
            "name": "sap-s4hana",
            "popularity": 187,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "azure",
                "data-flow",
                "example-workload",
                "fasttrack",
                "is-deployable",
                "linux",
                "oracle",
                "pricing-calculator",
                "pricing-guidance",
                "sap",
                "windows"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/apps/sap-production.yml",
            "http_url": "/azure/architecture/example-scenario/apps/sap-production",
            "word_count": 1109,
            "read_time": "5 min read",
            "Title": "SAP deployment on Azure using an Oracle DB",
            "MetaDescription": "This example demonstrates a SAP deployment on virtual machines on Azure, along with a High Availability Oracle database.",
            "category": [
                "databases"
            ],
            "image": "/azure/architecture/example-scenario/apps/media/architecture-sap-production.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\apps\\media\\architecture-sap-production.png",
            "publish_date": "9/12/2018",
            "deployable": "https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2Fmspnp%2Fsolution-architectures%2Fmaster%2Fapps%2Fsap-3tier-distributed-ora%2Fazuredeploy.json",
            "pricing_calculator": "https://azure.com/e/45880ba0bfdf47d497851a7cf2650c7c",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-network/virtual-networks-overview\">Virtual Networks</a> are used in this scenario to create a virtual hub-and-spoke topology in Azure.</p>"
            ],
            "Summary": "<p>SAP systems are used to run mission-critical business applications. Any outage disrupts key processes and can cause increased expenses or lost revenue. Avoiding these outcomes requires an SAP infrastructure that is highly available and resilient when failures occur.</p>\n<p>Building a highly available SAP environment requires eliminating single points of failures in your system architecture and processes. Single points of failure can be caused by site failures, errors in system components, or even human error.</p>\n<p>This example scenario demonstrates an SAP deployment on Windows or Linux virtual machines (VMs) on Azure, along with a High Availability (HA) Oracle database. For your SAP deployment, you can use VMs of different sizes based on your requirements.</p>",
            "Flow": {
                "FlowStep_A": "Users access the SAP system via the SAP user interface, a web browser, or other client tools like Microsoft Excel. An ExpressRoute connection provides access from the organization's on-premises network to resources running in Azure.",
                "FlowStep_B": "The ExpressRoute terminates in Azure at the ExpressRoute virtual network (VNet) gateway. Network traffic is routed to a gateway subnet through the ExpressRoute gateway created in the hub VNet.",
                "FlowStep_C": "The hub VNet is peered to a spoke VNet. The application tier subnet hosts the virtual machines running SAP in an availability set.",
                "FlowStep_D": "The identity management servers provide authentication services for the solution.",
                "FlowStep_E": "The jump box is used by system administrators to securely manage resources deployed in Azure."
            },
            "name": "sap-production",
            "popularity": 108,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "fcp",
                "github",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/sap/sap-overview.yml",
            "http_url": "/azure/architecture/reference-architectures/sap/sap-overview",
            "word_count": 2576,
            "read_time": "11 min read",
            "Title": "SAP on Azure Architecture Guide",
            "MetaDescription": "This guide is based on the Microsoft Azure Well-Architected Framework, but the recommendations are specific to deployments of SAP solutions.",
            "category": [
                "databases",
                "compute"
            ],
            "image": "/azure/architecture/reference-architectures/sap/images/sap-overview-architecture-diagram.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\sap\\images\\sap-overview-architecture-diagram.png",
            "publish_date": "6/10/2020",
            "Summary": "<p>The SAP on Azure Architecture Guide describes a set of guiding tenets that are used to help ensure the quality of SAP workloads running on Azure. This guide is based on the <a >Microsoft Azure Well-Architected Framework</a>, but the recommendations are specific to deployments of SAP solutions. A solid architectural foundation starts with five pillars of excellence: cost, DevOps, resiliency, scalability, and security.</p>\n<p>Microsoft and SAP work in <a href=\"https://blogs.microsoft.com/blog/2019/05/09/microsoft-partners-with-sap-as-the-first-global-cloud-provider-to-launch-project-embrace/\">partnership</a> to provide a clear roadmap for organizations that want to innovate in the cloud. Azure supports SAP applications on Linux and Windows across development, test, and production environments. Our customers run SAP deployments of all sizes on Azure\u2014including SAP NetWeaver, SAP S/4HANA, SAP BW/4HANA, SAP BI, and SAP HANA in scale-up and scale-out scenarios.</p>\n<p>One way to get started is to run through the <a href=\"https://learn.microsoft.com/assessments/?id=azure-architecture-review&amp;mode=pre-assessment\">Azure Well-Architected Review</a>.</p>",
            "sample_code": true,
            "github_url": "https://github.com/Azure/sap-hana",
            "name": "sap-overview",
            "popularity": 0,
            "topic": "Databases"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-disaster-recovery-smb-azure-site-recovery-'",
                "acom-architecture",
                "all-items",
                "bcdr",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/disaster-recovery-smb-azure-site-recovery.md",
            "http_url": "/azure/architecture/solution-ideas/articles/disaster-recovery-smb-azure-site-recovery",
            "word_count": 192,
            "read_time": "1 min read",
            "Title": "SMB disaster recovery with Azure Site Recovery",
            "MetaDescription": "Small and medium businesses can inexpensively implement disaster recovery to the cloud by using Azure Site Recovery or a partner solution like Double-Take DR.",
            "category": [
                "management-and-governance",
                "hybrid"
            ],
            "image": "/azure/architecture/solution-ideas/media/disaster-recovery-smb-azure-site-recovery.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\disaster-recovery-smb-azure-site-recovery.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p>DNS traffic is routed via <a href=\"https://azure.microsoft.com/services/traffic-manager\">Traffic Manager</a> which can easily move traffic from one site to another based on policies defined by your organization.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/site-recovery\">Azure Site Recovery</a> orchestrates the replication of machines and manages the configuration of the failback procedures.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/virtual-network\">Virtual Network</a>: The virtual network is where the failover site will be created when a disaster occurs.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage/blobs\">Blob storage</a> stores the replica images of all machines that are protected by Site Recovery.</p>"
            ],
            "Summary": "<p>Small and medium businesses can inexpensively implement disaster recovery to the cloud by using Azure Site Recovery or a partner solution like Double-Take DR.</p>\n<p>This solution is built on the Azure managed services: <a href=\"https://azure.microsoft.com/services/traffic-manager\">Traffic Manager</a>, <a href=\"https://azure.microsoft.com/services/site-recovery\">Azure Site Recovery</a> and <a href=\"https://azure.microsoft.com/services/virtual-network\">Virtual Network</a>. These services run in a high-availability environment, patched and supported, allowing you to focus on your solution instead of the environment they run in.</p>",
            "name": "disaster-recovery-smb-azure-site-recovery",
            "popularity": 159,
            "topic": "Management and Governance",
            "hybrid-topic": "Management"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-disaster-recovery-smb-double-take-dr-'",
                "acom-architecture",
                "all-items",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/disaster-recovery-smb-double-take-dr.md",
            "http_url": "/azure/architecture/solution-ideas/articles/disaster-recovery-smb-double-take-dr",
            "word_count": 172,
            "read_time": "1 min read",
            "Title": "SMB disaster recovery with Double-Take DR",
            "MetaDescription": "Small and medium businesses can inexpensively implement disaster recovery to the cloud by using a partner solution like Double-Take DR.",
            "category": [
                "management-and-governance"
            ],
            "image": "/azure/architecture/solution-ideas/media/disaster-recovery-smb-double-take-dr.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\disaster-recovery-smb-double-take-dr.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p>DNS traffic is routed via <a href=\"https://azure.microsoft.com/services/traffic-manager\">Traffic Manager</a> which can easily move traffic from one site to another based on policies defined by your organization.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/vpn-gateway\">VPN Gateway</a>: The VPN gateway maintains the communication between the on-premises network and the cloud network securely and privately.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/virtual-network\">Virtual Network</a>: The virtual network is where the failover site will be created when a disaster occurs.</p>"
            ],
            "name": "disaster-recovery-smb-double-take-dr",
            "popularity": 65,
            "topic": "Management and Governance"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "fcp",
                "github",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/saga/saga.md",
            "http_url": "/azure/architecture/reference-architectures/saga/saga",
            "word_count": 1473,
            "read_time": "6 min read",
            "Title": "Saga distributed transactions",
            "MetaDescription": "Understand and use the saga design pattern to ensure data consistency on distributed transactions in microservices architectures.",
            "category": [
                "databases",
                "event-driven",
                "transactions",
                "microservices"
            ],
            "image": "/azure/architecture/reference-architectures/saga/images/saga-overview.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\saga\\images\\saga-overview.png",
            "publish_date": "7/21/2020",
            "Summary": "<p>The <em>saga</em> design pattern is a way to manage data consistency across microservices in distributed transaction scenarios. A saga is a sequence of transactions that updates each service and publishes a message or event to trigger the next transaction step. If a step fails, the saga executes compensating transactions that counteract the preceding transactions.</p>",
            "sample_code": true,
            "github_url": "https://github.com/Azure-Samples/saga-orchestration-serverless",
            "name": "saga",
            "popularity": 0,
            "topic": "Databases"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-digital-marketing-episerver-'",
                "acom-architecture",
                "all-items",
                "solution-idea",
                "web-apps"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/digital-marketing-episerver.md",
            "http_url": "/azure/architecture/solution-ideas/articles/digital-marketing-episerver",
            "word_count": 326,
            "read_time": "2 min read",
            "Title": "Scalable Episerver marketing website",
            "MetaDescription": "Let your business run multi-channel digital marketing websites on one platform and spin up and spin down campaigns on demand. Take advantage of the comprehensive capabilities of Episerver to manage every aspect of your site and campaign performance.",
            "category": [
                "web"
            ],
            "image": "/azure/architecture/solution-ideas/media/digital-marketing-episerver.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\digital-marketing-episerver.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p>App Service <a href=\"https://azure.microsoft.com/services/app-service/web\">Web Apps</a> runs in multiple regions, accessible to web and mobile browsers, and is scaled out across multiple server instances.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/traffic-manager\">Traffic Manager</a> determines which web app is geographically best placed to handle each request.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/cdn/cdn-add-to-web-app\">Content Delivery Network</a>: A content delivery network serves static content such as images, script, and CSS, and reduces the load on the Web App servers.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/sql-database\">Azure SQL Database</a>: A SQL Database stores and serves data about the site.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cache\">Azure Cache for Redis</a> enables very fast queries, and improves scalability by reducing the load on the main database.</p>",
                "<p>Azure <a href=\"https://azure.microsoft.com/services/storage/blobs\">Blob storage</a> provides high-performance, high-scale storage.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/monitor\">Azure Monitor</a>: Application Insights provides service health, performance monitoring, and diagnostics.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/app-service/app-service-authentication-overview\">Identity provider</a>: An identity provider such as Azure Active Directory or Facebook handles authentication to the app.</p>"
            ],
            "Summary": "<p>Let your business run multi-channel digital marketing websites on one platform and spin up and spin down campaigns on demand. Take advantage of the comprehensive capabilities of Episerver to manage every aspect of your site and campaign performance.</p>\n<p>This solution is built on the Azure managed services: <a href=\"https://azure.microsoft.com/services/traffic-manager\">Traffic Manager</a>, <a href=\"https://azure.microsoft.com/services/cdn\">Content Delivery Network</a>, <a href=\"https://azure.microsoft.com/services/sql-database\">Azure SQL Database</a>, <a href=\"https://azure.microsoft.com/services/cache\">Azure Cache for Redis</a> and <a href=\"https://azure.microsoft.com/services/monitor\">Azure Monitor</a>. These services run in a high-availability environment, patched and supported, allowing you to focus on your solution instead of the environment they run in.</p>",
            "name": "digital-marketing-episerver",
            "popularity": 83,
            "topic": "Web"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-digital-marketing-sitecore-'",
                "acom-architecture",
                "all-items",
                "solution-idea",
                "web-apps"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/digital-marketing-sitecore.md",
            "http_url": "/azure/architecture/solution-ideas/articles/digital-marketing-sitecore",
            "word_count": 293,
            "read_time": "2 min read",
            "Title": "Scalable Sitecore marketing website",
            "MetaDescription": "With the Sitecore Experience Platform (xP), you have at your fingertips the complete data, integrated tools, and automation capabilities to engage your customers throughout an iterative life cycle-the technology foundation necessary to win customers for life.",
            "category": [
                "web"
            ],
            "image": "/azure/architecture/solution-ideas/media/digital-marketing-sitecore.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\digital-marketing-sitecore.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p>App Service <a href=\"https://azure.microsoft.com/services/app-service/web\">Web Apps</a> runs in multiple regions, accessible to web and mobile browsers, and is scaled out across multiple server instances. Used by Sitecore to host its content delivery, content management, reporting, and processing roles.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/sql-database\">Azure SQL Database</a>: A SQL Database stores and serves data about the site.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cache\">Azure Cache for Redis</a> enables very fast queries, and improves scalability by reducing the load on the main database. Sitecore's Session State session state is managed by <a href=\"https://azure.microsoft.com/services/cache\">Azure Cache for Redis</a>.</p>",
                "<p>An <a href=\"https://azure.microsoft.com/services/search\">Azure Cognitive Search</a> service used for quick look up of data. All Sitecore search indexes are stored in <a href=\"https://azure.microsoft.com/services/search\">Azure Cognitive Search</a> for quick look up and scalability.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/monitor\">Azure Monitor</a> provides service health and performance monitoring, and diagnostics. <a href=\"https://azure.microsoft.com/services/monitor\">Azure Monitor</a> provides Sitecore with a solution for its health and performance monitoring needs.</p>"
            ],
            "Summary": "<p>With the Sitecore Experience Platform (xP), you have at your fingertips the complete data, integrated tools, and automation capabilities to engage your customers throughout an iterative life cycle-the technology foundation necessary to win customers for life.</p>\n<p>This solution is built on the Azure managed services: <a href=\"https://azure.microsoft.com/services/sql-database\">Azure SQL Database</a>, <a href=\"https://azure.microsoft.com/services/cache\">Azure Cache for Redis</a>, <a href=\"https://azure.microsoft.com/services/search\">Azure Cognitive Search</a> and <a href=\"https://azure.microsoft.com/services/monitor\">Azure Monitor</a>. These services run in a high-availability environment, patched and supported, allowing you to focus on your solution instead of the environment they run in.</p>",
            "name": "digital-marketing-sitecore",
            "popularity": 98,
            "topic": "Web"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-medium-umbraco-web-app-'",
                "acom-architecture",
                "all-items",
                "app-dev",
                "is-deployable",
                "solution-idea",
                "web-apps"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/medium-umbraco-web-app.md",
            "http_url": "/azure/architecture/solution-ideas/articles/medium-umbraco-web-app",
            "word_count": 317,
            "read_time": "2 min read",
            "Title": "Scalable Umbraco CMS web app",
            "MetaDescription": "Medium Umbraco CMS web app configured to scale and optimal for high-traffic sites. It uses two web apps, one for your front-end app and the other for your back-office app, deployed in a single region with autoscaling enabled.",
            "category": [
                "web",
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/medium-umbraco-web-app.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\medium-umbraco-web-app.png",
            "publish_date": "12/16/2019",
            "deployable": "https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2FAzure%2Fazure-quickstart-templates%2Fmaster%2Fumbraco-cms-webapp-redis-cache%2Fazuredeploy.json",
            "components": [
                "<p>Run an Umbraco CMS on the <a href=\"https://azure.microsoft.com/services/app-service/web\">Web Apps</a> feature of Azure App Service with the front-end and back-office apps running on the same app.</p>",
                "<p>Store your site's content in <a href=\"https://azure.microsoft.com/services/sql-database\">Azure SQL Database</a>. The back-office web app and front-end web app use the same database. Use <a href=\"https://azure.microsoft.com/services/sql-database\">Azure SQL Database</a>'s features such as backup and high availability.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage\">Storage Accounts</a>: Store all your media in Azure Storage, so you can reduce I/O operation on the web app file server and improve performance.</p>",
                "<p>Application Insights: Detect issues, diagnose crashes, and track usage in your web app with Application Insights. Make informed decisions throughout the development lifecycle.</p>",
                "<p>Store session state and output cache on <a href=\"https://azure.microsoft.com/services/cache\">Azure Cache for Redis</a> to improve performance and reduce the load on your web front ends.</p>"
            ],
            "Summary": "<p>Medium Umbraco CMS web app configured to scale and optimal for high-traffic sites. It uses two web apps, one for your front-end app and the other for your back-office app, deployed in a single region with autoscaling enabled.</p>\n<p>This solution is built on the Azure managed services: <a href=\"https://azure.microsoft.com/services/sql-database\">Azure SQL Database</a>, <a href=\"https://azure.microsoft.com/services/storage\">Storage Accounts</a>, Application Insights and <a href=\"https://azure.microsoft.com/services/cache\">Azure Cache for Redis</a>. These services run in a high-availability environment, patched and supported, allowing you to focus on your solution instead of the environment they run in.</p>",
            "name": "medium-umbraco-web-app",
            "popularity": 56,
            "topic": "Web"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-scalable-web-apps-'",
                "acom-architecture",
                "all-items",
                "scalability",
                "solution-idea",
                "web-app"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/scalable-web-apps.md",
            "http_url": "/azure/architecture/solution-ideas/articles/scalable-web-apps",
            "word_count": 50,
            "read_time": "1 min read",
            "Title": "Scalable Web Apps",
            "MetaDescription": "scalable web apps, azure redis cache, session data cache, user cookie cache, azure cache for redis",
            "category": [
                "web"
            ],
            "image": "/azure/architecture/solution-ideas/media/scalable-web-apps.svg",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\scalable-web-apps.svg",
            "publish_date": "12/16/2019",
            "Summary": "<p>Quickly save, retrieve, and update web session data such as user cookies and output pages. Azure Cache for Redis improves the performance of your application by increasing its responsiveness and enabling it to handle increasing loads with less web-compute resources.</p>",
            "name": "scalable-web-apps",
            "popularity": 152,
            "topic": "Web"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "data-flow",
                "example-workload",
                "pricing-calculator",
                "pricing-guidance",
                "scalability",
                "web-apps"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/infrastructure/wordpress.yml",
            "http_url": "/azure/architecture/example-scenario/infrastructure/wordpress",
            "word_count": 1213,
            "read_time": "5 min read",
            "Title": "Scalable and secure WordPress on Azure",
            "MetaDescription": "This example shows a highly scalable and secure installation of WordPress. The scenario was used for a large convention and scaled to meet spike traffic.",
            "category": [
                "web"
            ],
            "image": "/azure/architecture/example-scenario/infrastructure/media/secure-scalable-wordpress.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\infrastructure\\media\\secure-scalable-wordpress.png",
            "publish_date": "9/18/2018",
            "pricing_calculator": "https://azure.com/e/a8c4809dab444c1ca4870c489fbb196b",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/cdn/cdn-overview\">Azure Content Delivery Network (CDN)</a> is a distributed network of servers that efficiently delivers web content to users. CDNs minimize latency by storing cached content on edge servers in point-of-presence locations near to end users.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-network/virtual-networks-overview\">Virtual networks</a> allow resources such as VMs to securely communicate with each other, the Internet, and on-premises networks. Virtual networks provide isolation and segmentation, filter and route traffic, and allow connection between locations. The two networks are connected via Vnet peering.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-network/security-overview\">Network security groups</a> contain a list of security rules that allow or deny inbound or outbound network traffic based on source or destination IP address, port, and protocol. The virtual networks in this scenario are secured with network security group rules that restrict the flow of traffic between the application components.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/load-balancer/load-balancer-overview\">Load balancers</a> distribute inbound traffic according to rules and health probes. A load balancer provides low latency and high throughput, and scales up to millions of flows for all TCP and UDP applications. A load balancer is used in this scenario to distribute traffic from the content deliver network to the front-end web servers.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-machine-scale-sets/overview\">Virtual machine scale sets</a> let you create and manage a group of identical load-balanced VMs. The number of VM instances can automatically increase or decrease in response to demand or a defined schedule. Two separate virtual machine scale sets are used in this scenario - one for the front-end web-servers serving content, and one for the front-end web servers used to author new content.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/storage/files/storage-files-introduction\">Azure Files</a> provides a fully managed file share in the cloud that hosts all of the WordPress content in this scenario, so that all of the VMs have access to the data.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/key-vault/key-vault-overview\">Azure Key Vault</a> is used to store and tightly control access to passwords, certificates, and keys.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/active-directory/fundamentals/active-directory-whatis\">Azure Active Directory (Azure AD)</a> is a multitenant, cloud-based directory and identity management service. In this scenario, Azure AD provides authentication services for the website and the VPN tunnels.</p>"
            ],
            "Summary": "<p>This example scenario is applicable to companies that need a highly scalable and secure installation of WordPress. This scenario is based on a deployment that was used for a large convention and was successfully able to scale to meet the spike traffic that sessions drove to the site.</p>",
            "Flow": {
                "FlowStep_A": "Users access the front-end website through a CDN.",
                "FlowStep_B": "The CDN uses an Azure load balancer as the origin, and pulls any data that isn't cached from there.",
                "FlowStep_C": "The Azure load balancer distributes requests to the virtual machine scale sets of web servers.",
                "FlowStep_D": "The WordPress application pulls any dynamic information out of the Maria DB clusters, all static content is hosted in Azure Files.",
                "FlowStep_E": "SSL keys are stored Azure Key Vault.",
                "FlowStep_F": "Authors connect securely to the public VPN gateway.",
                "FlowStep_G": "VPN authentication information is stored in Azure Active Directory.",
                "FlowStep_H": "A connection is then established to the Admin jump boxes.",
                "FlowStep_I": "From the admin jump box, the author is then able to connect to the Azure load balancer for the authoring cluster.",
                "FlowStep_J": "The Azure load balancer distributes traffic to the virtual machine scale sets of web servers that have write access to the Maria DB cluster.",
                "FlowStep_K": "New static content is uploaded to Azure files and dynamic content is written into the Maria DB cluster.",
                "FlowStep_L": "These changes are then replicated to the alternate region via rsync or primary/secondary replication."
            },
            "name": "wordpress",
            "popularity": 163,
            "topic": "Web"
        },
        {
            "tags": [
                "all-items",
                "data-flow",
                "example-workload",
                "fasttrack",
                "pricing-calculator",
                "pricing-guidance",
                "web-apps"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/data/ecommerce-order-processing.md",
            "http_url": "/azure/architecture/example-scenario/data/ecommerce-order-processing",
            "word_count": 1340,
            "read_time": "6 min read",
            "Title": "Scalable order processing",
            "MetaDescription": "This example demonstrates a highly scalable, resilient architecture for online order processing, using managed Azure services such as Azure Cosmos DB and HDInsight.",
            "category": [
                "web",
                "databases"
            ],
            "image": "/azure/architecture/example-scenario/data/media/architecture-ecommerce-order-processing.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\data\\media\\architecture-ecommerce-order-processing.png",
            "publish_date": "7/10/2018",
            "pricing_calculator": "https://azure.com/e/3d43949ffbb945a88cc0a126dc3a0e6e",
            "pricing_guidance": "pricing",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/cosmos-db/introduction\">Azure Cosmos DB</a> is Microsoft's globally distributed, multi-model database that enables your solutions to elastically and independently scale throughput and storage across any number of geographic regions. It offers throughput, latency, availability, and consistency guarantees with comprehensive service level agreements (SLAs). This scenario uses Azure Cosmos DB for event stream storage and snapshot storage, and leverages <a href=\"https://learn.microsoft.com/azure/cosmos-db/change-feed\">Azure Cosmos DB change feed</a> features to provide data consistency and fault recovery.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/hdinsight/kafka/apache-kafka-introduction\">Apache Kafka on HDInsight</a> is a managed service implementation of Apache Kafka, an open-source distributed streaming platform for building real-time streaming data pipelines and applications. Kafka also provides message broker functionality similar to a message queue, for publishing and subscribing to named data streams. This scenario uses Kafka to process incoming as well as downstream events in the order processing pipeline.</p>"
            ],
            "Summary": "<p>This example scenario is relevant to organizations that need a highly scalable and resilient architecture for online order processing. Potential applications include e-commerce and retail point-of-sale, order fulfillment, and inventory reservation and tracking.</p>\n<p>This scenario takes an event sourcing approach, using a functional programming model implemented via <a href=\"https://azure.com/microservices\">microservices</a>. Each microservice is treated as a stream processor, and all business logic is implemented via microservices. This approach enables high availability and resiliency, geo-replication, and fast performance.</p>\n<p>Using managed Azure services such as Azure Cosmos DB and HDInsight can help reduce costs by leveraging Microsoft's expertise in globally distributed cloud-scale data storage and retrieval. This scenario specifically addresses an e-commerce or retail scenario; if you have other needs for data services, you should review the list of available <a href=\"https://azure.microsoft.com/product-categories/databases\">fully managed intelligent database services in Azure</a>.</p>",
            "Flow": {
                "FlowStep_A": "Event messages enter the system via customer-facing applications (synchronously over HTTP) and various back-end systems (asynchronously via Apache Kafka). These messages are passed into a command processing pipeline.",
                "FlowStep_B": "Each event message is ingested and mapped to one of a defined set of commands by a command processor microservice. The command processor retrieves any current state relevant to executing the command from an event stream snapshot database. The command is then executed, and the output of the command is emitted as a new event.",
                "FlowStep_C": "Each event emitted as the output of a command is committed to an event stream database using Azure Cosmos DB.",
                "FlowStep_D": "For each database insert or update committed to the event stream database, an event is raised by the Azure Cosmos DB change feed. Downstream systems can subscribe to any event topics that are relevant to that system.",
                "FlowStep_E": "All events from the Azure Cosmos DB change feed are also sent to a snapshot event stream microservice, which calculates any state changes caused by events that have occurred. The new state is then committed to the event stream snapshot database stored in Azure Cosmos DB. The snapshot database provides a globally distributed, low latency data source for the current state of all data elements. The event stream database provides a complete record of all event messages that have passed through the architecture, which enables robust testing, troubleshooting, and disaster recovery scenarios."
            },
            "name": "ecommerce-order-processing",
            "popularity": 82,
            "topic": "Web"
        },
        {
            "tags": [
                "ai",
                "all-items",
                "azcat-ai",
                "example-code",
                "example-workload",
                "github",
                "pricing-calculator",
                "pricing-guidance"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/ai/scalable-personalization-with-content-based-recommendation-system.md",
            "http_url": "/azure/architecture/example-scenario/ai/scalable-personalization-with-content-based-recommendation-system",
            "word_count": 1584,
            "read_time": "6 min read",
            "Title": "Scalable personalization on Azure",
            "MetaDescription": "Use machine learning to automate content-based personalization for customers.",
            "category": [
                "ai-machine-learning",
                "featured"
            ],
            "image": "/azure/architecture/example-scenario/ai/media/architecture-scalable-personalization.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\ai\\media\\architecture-scalable-personalization.png",
            "publish_date": "5/31/2019",
            "pricing_calculator": "https://azure.com/e/ce86a34735d64f1280812233b0071c4e",
            "pricing_guidance": "pricing",
            "Summary": "<p>Recommendations are a main revenue driver for many businesses and are used in different kinds of industries, including retail, news, and media. With the availability of large amounts of data, you can now provide highly relevant recommendations using machine learning.</p>\n<p>There are two main types of recommendation systems: collaborative filtering and content-based. Collaborative filtering identifies similar patterns in customer behavior and recommends items that other similar customers have interacted with. Content-based recommendation uses information about the items to learn customer preferences and recommends items that share properties with items that a customer has previously interacted with. The approach described in this document focuses on the content-based recommendation system.</p>\n<p>This example scenario shows how your business can use machine learning to automate content-based personalization for your customers. At a high level, we use <a href=\"https://azure.microsoft.com/services/databricks\">Azure Databricks</a> to train a model that predicts the probability a user will engage with an item. That model is deployed to production as a prediction service using <a href=\"https://azure.microsoft.com/services/kubernetes-service\">Azure Kubernetes Service</a>. In turn, you can use this prediction to create personalized recommendations by ranking items based on the content that a user is most likely to consume.</p>",
            "sample_code": true,
            "github_url": "https://github.com/Microsoft/Recommenders/blob/master/SETUP.md#setup-guide-for-azure-databricks",
            "name": "scalable-personalization-with-content-based-recommendation-system",
            "popularity": 38,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-scalable-web-and-mobile-applications-using-azure-database-for-mysql-'",
                "acom-architecture",
                "all-items",
                "azure",
                "mysql",
                "scalability",
                "solution-idea",
                "solutions",
                "use-cases",
                "web-app"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/scalable-web-and-mobile-applications-using-azure-database-for-mysql.md",
            "http_url": "/azure/architecture/solution-ideas/articles/scalable-web-and-mobile-applications-using-azure-database-for-mysql",
            "word_count": 39,
            "read_time": "1 min read",
            "Title": "Scalable web and mobile applications using Azure Database for MySQL",
            "MetaDescription": "Use Azure Database for MySQL to rapidly build engaging, performant, and scalable cross-platform and native apps for iOS, Android, Windows, or Mac.",
            "category": [
                "mobile",
                "web",
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/scalable-web-and-mobile-applications-using-azure-database-for-mysql.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\scalable-web-and-mobile-applications-using-azure-database-for-mysql.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Rapidly build engaging, performant and scalable cross-platform and native apps for iOS, Android, Windows, or Mac.</p>",
            "name": "scalable-web-and-mobile-applications-using-azure-database-for-mysql",
            "popularity": 70,
            "topic": "Mobile"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-scalable-web-and-mobile-applications-using-azure-database-for-postgresql-'",
                "acom-architecture",
                "all-items",
                "azure",
                "postgresql",
                "scalability",
                "solution-idea",
                "solutions",
                "use-cases",
                "web-app"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/scalable-web-and-mobile-applications-using-azure-database-for-postgresql.md",
            "http_url": "/azure/architecture/solution-ideas/articles/scalable-web-and-mobile-applications-using-azure-database-for-postgresql",
            "word_count": 66,
            "read_time": "1 min read",
            "Title": "Scalable web and mobile applications using Azure Database for PostgreSQL",
            "MetaDescription": "Use Azure Database for PostgreSQL to rapidly build engaging, performant, and scalable cross-platform and native apps for iOS, Android, Windows, or Mac.",
            "category": [
                "mobile",
                "web",
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/scalable-web-and-mobile-applications-using-azure-database-for-postgresql.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\scalable-web-and-mobile-applications-using-azure-database-for-postgresql.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Rapidly build engaging, performant and scalable cross-platform and native apps for iOS, Android, Windows, or Mac.</p>",
            "name": "scalable-web-and-mobile-applications-using-azure-database-for-postgresql",
            "popularity": 62,
            "topic": "Mobile"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "github",
                "reference-architecture",
                "seodec18",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/app-service-web-app/scalable-web-app.yml",
            "http_url": "/azure/architecture/reference-architectures/app-service-web-app/scalable-web-app",
            "word_count": 1659,
            "read_time": "7 min read",
            "Title": "Scalable web application",
            "MetaDescription": "Use the proven practices in this reference architecture to improve scalability and performance in an Azure App Service web application..",
            "category": [
                "web"
            ],
            "image": "/azure/architecture/reference-architectures/app-service-web-app/images/scalable-web-app.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\app-service-web-app\\images\\scalable-web-app.png",
            "publish_date": "10/03/2019",
            "Summary": "<p>This reference architecture shows proven practices for improving scalability and performance in an Azure App Service web application.</p>\n<p><img alt=\"GitHub logo\" src=\"https://learn.microsoft.com/azure/architecture/_images/github.png\" /> A reference implementation for this architecture is available on <a href=\"https://github.com/mspnp/reference-architectures/tree/master/web-app\">GitHub</a>.</p>\n<p><img alt=\"Web application in Azure with improved scalability\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/app-service-web-app/images/scalable-web-app.png\" /></p>\n<p><em>Download a <a href=\"https://arch-center.azureedge.net/app-service-reference-architectures.vsdx\">Visio file</a> of this architecture.</em></p>",
            "sample_code": true,
            "github_url": "https://github.com/mspnp/reference-architectures/tree/master/web-app",
            "visio_diagram": "https://arch-center.azureedge.net/app-service-reference-architectures.vsdx",
            "name": "scalable-web-app",
            "popularity": 225,
            "topic": "Web"
        },
        {
            "tags": [
                "all-items",
                "example-workload",
                "fcp"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/iot/application-stamps.md",
            "http_url": "/azure/architecture/example-scenario/iot/application-stamps",
            "word_count": 937,
            "read_time": "4 min read",
            "Title": "Scale IoT solutions with application stamps",
            "MetaDescription": "Learn about scaling up IoT device populations with application stamps, and strategies for moving devices and applications between stamps.",
            "category": [
                "iot"
            ],
            "image": "/azure/architecture/example-scenario/iot/media/application-stamping.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\iot\\media\\application-stamping.png",
            "publish_date": "8/10/2020",
            "Summary": "<p>The <em>application stamping</em> strategy in an Internet-of-Things (IoT) solution supports scaling up the numbers of connected IoT devices by replicating <em>stamps</em>. Stamps are discrete units of core solution components that optimally support a defined number of devices.</p>\n<p>This article describes application stamping benefits and considerations, and how to move devices and applications between stamps.</p>\n<p><img alt=\"A diagram showing an application stamping strategy for use in Azure IoT\" src=\"media/application-stamping.png\" /></p>\n<p>The application stamping strategy is to build atomic stamps that consist of an <a href=\"https://learn.microsoft.com/azure/iot-hub/about-iot-hub\">Azure IoT Hub</a>, routing endpoints like <a href=\"https://learn.microsoft.com/azure/event-hubs/event-hubs-about\">Azure Event Hubs</a>, and processing components. The stamps optimally support a defined device population, from 1 thousand to 1 million devices. As the incoming device population grows, stamp instances are added to accommodate the growth, rather than independently scaling up different parts of the solution.</p>\n<p>Stamps should always be designed to support explicit capacities. To determine the\u00a0right-sized population, consider how much communication traffic to expect from targeted device populations.</p>",
            "name": "application-stamps",
            "popularity": 0,
            "topic": "Internet of Things"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-secure-devops-for-kubernetes-'",
                "acom-architecture",
                "all-items",
                "data-flow",
                "devops",
                "fcp",
                "interactive-diagram",
                "signalr-service",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/secure-devops-for-kubernetes.md",
            "http_url": "/azure/architecture/solution-ideas/articles/secure-devops-for-kubernetes",
            "word_count": 245,
            "read_time": "2 min read",
            "Title": "Secure DevOps for AKS",
            "MetaDescription": "Implementing secure DevOps with Kubernetes on Azure, you can achieve the balance between speed and security and deliver code faster at scale.",
            "category": [
                "containers",
                "devops"
            ],
            "image": "/azure/architecture/solution-ideas/media/secure-devops-for-kubernetes.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\secure-devops-for-kubernetes.png",
            "publish_date": "9/10/2020",
            "Summary": "<p>DevOps and Kubernetes are better together. Implementing secure DevOps together with Kubernetes on Azure, you can achieve the balance between speed and security and deliver code faster at scale. Put guardrails around the development processes using CI/CD with dynamic policy controls and accelerate feedback loop with constant monitoring. Use Azure Pipelines to deliver fast while ensuring enforcement of critical policies with Azure Policy. Azure provides you real-time observability for your build and release pipelines, and the ability to apply compliance audit and reconfigurations easily.</p>",
            "Flow": {
                "FlowStep_A": "Developers rapidly iterate, test, and debug different parts of an application together in the same Kubernetes cluster.",
                "FlowStep_B": "Code is merged into a GitHub repository, after which automated builds and tests are run by Azure Pipelines.",
                "FlowStep_C": "Release pipeline automatically executes pre-defined deployment strategy with each code change.",
                "FlowStep_D": "Kubernetes clusters are provisioned using tools like Helm charts that define the desired state of app resources and configurations.",
                "FlowStep_E": "Container image is pushed to Azure Container Registry.",
                "FlowStep_F": "Cluster operators define policies in Azure Policy to govern deployments to the AKS cluster.",
                "FlowStep_G": "Azure Policy audits requests from the pipeline at the AKS control plane level.",
                "FlowStep_H": "App telemetry, container health monitoring, and real-time log analytics are obtained using Azure Monitor.",
                "FlowStep_I": "Insights used to address issues and fed into next sprint plans."
            },
            "name": "secure-devops-for-kubernetes",
            "popularity": 141,
            "topic": "Containers"
        },
        {
            "tags": [
                "all-items",
                "azurecli",
                "example-code",
                "example-workload",
                "fcp"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/secrets/secure-refresh-tokens.md",
            "http_url": "/azure/architecture/example-scenario/secrets/secure-refresh-tokens",
            "word_count": 1050,
            "read_time": "5 min read",
            "Title": "Secure OAuth 2.0 On-Behalf-Of refresh tokens for web services",
            "MetaDescription": "Store OAuth 2.0 On-Behalf-Of (OBO) refresh tokens securely using Azure Key Vault and Azure Functions managed identity for key rotation and token refresh.",
            "category": [
                "security"
            ],
            "image": "/azure/architecture/example-scenario/secrets/media/refresh-diagram.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\secrets\\media\\refresh-diagram.png",
            "publish_date": "7/15/2020",
            "code_languages": [
                "azurecli"
            ],
            "sample_code": true,
            "name": "secure-refresh-tokens",
            "popularity": 0,
            "topic": "Security"
        },
        {
            "tags": [
                "all-items",
                "data-flow",
                "networking",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/hybrid-networking/network-level-segmentation.yml",
            "http_url": "/azure/architecture/reference-architectures/hybrid-networking/network-level-segmentation",
            "word_count": 1444,
            "read_time": "7 min read",
            "Title": "Secure and govern workloads with network level segmentation",
            "MetaDescription": "Using network level segmentation to secure virtual networks.",
            "category": [
                "hybrid",
                "networking"
            ],
            "image": "/azure/architecture/reference-architectures/hybrid-networking/images/resource-flowchart.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\hybrid-networking\\images\\resource-flowchart.png",
            "publish_date": "4/30/2020",
            "Summary": "<p>Segmentation is a model in which you take your networking footprint and create software defined perimeters using the different tools available as part of Azure's offerings. You then set rules that govern the traffic from/to these perimeters so that you can have different security postures for various parts your network. Where this becomes useful is when you place different applications (or parts of a given application) into these perimeters so that you govern the communication between these segmented entities. Another advantage of this model is that if a part of your application stack is compromised, you will be able to better contain the impact of this security breach and prevent it from laterally spreading through the rest of your network. This is a key principle associated with the <a href=\"https://www.microsoft.com/security/blog/2019/10/23/perimeter-based-network-defense-transform-zero-trust-model/\">Zero Trust model published by Microsoft</a> that aims to bring world class security thinking to your organization</p>",
            "Flow": {
                "FlowStep_A": "[Subscription](/azure/cost-management-billing/manage/create-subscription) : Subscriptions are a high-level construct, which provides platform powered separation between entities. It is intended to carve out boundaries between large organizations within a company and communication between resources in different subscriptions needs to be explicitly provisioned.",
                "FlowStep_B": "[Virtual Network](/azure/virtual-network/virtual-networks-overview) : Virtual networks are created within a subscription in private address spaces and provide network level containment of resources with no traffic allowed by default between any two virtual networks. Like subscriptions, any communication between virtual networks needs to be explicitly provisioned.",
                "FlowStep_C": "[Network Security Groups (NSG)](/azure/virtual-network/security-overview) : NSGs are access control mechanisms for controlling traffic between resources within a virtual network and also with external networks (for example, the internet, other virtual networks etc.). NSGs can take your segmentation strategy to a granular level by creating perimeters for a subnet, group of VMs or even a single virtual machine.  ",
                "FlowStep_D": "[Application Security Groups (ASGs)](/azure/virtual-network/application-security-groups): ASGs provide control mechanisms similar to NSGs but are referenced with an application context. It allows you to group a set of VMs under an application tag and define traffic rules that are then applied to each of the underlying VMs.  ",
                "FlowStep_E": "[Azure Firewall](/azure/firewall/): Azure Firewall is a cloud native stateful Firewall as a service, which can be deployed in your virtual networks or in [Azure Virtual WAN](/azure/virtual-wan/virtual-wan-about) hub deployments for filtering traffic flowing between cloud resources, the Internet, and on-premise. You create rules or policies (using Azure Firewall or [Azure Firewall Manager](/azure/firewall-manager/overview)) specifying allow/deny traffic using layer 3 to layer 7 controls. You can also filter traffic going to the internet using both Azure Firewall and third parties by directing some or all traffic through third-party security providers for advanced filtering & user protection.  "
            },
            "name": "network-level-segmentation",
            "popularity": 0,
            "topic": "Networking",
            "hybrid-topic": "Networking"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "example-workload",
                "fcp",
                "github"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/iot-aad/iot-aad.md",
            "http_url": "/azure/architecture/example-scenario/iot-aad/iot-aad",
            "word_count": 3088,
            "read_time": "13 min read",
            "Title": "Secure your IoT SaaS app with the Microsoft identity platform",
            "MetaDescription": "How a developer can use Azure Active Directory and the Microsoft identity platform to implement secure authentication and authorization for SaaS apps that manage cloud-connected IoT devices.",
            "category": [
                "iot",
                "security"
            ],
            "image": "/azure/architecture/example-scenario/iot-aad/media/multi-tenant-iot.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\iot-aad\\media\\multi-tenant-iot.png",
            "publish_date": "3/12/2020",
            "Summary": "<p>IoT device manufacturers are creating custom apps and services to better serve their customers\u2019 device management needs. Developers building IoT apps and services want to provide secure, frictionless access to cloud-connected devices and the telemetry data sent by these devices to the cloud.</p>\n<p>In this article we explain how a developer can take advantage of <a href=\"https://learn.microsoft.com/azure/active-directory/fundamentals/active-directory-whatis\">Azure Active Directory</a> and the <a href=\"https://learn.microsoft.com/azure/active-directory/develop/v2-overview\">Microsoft identity platform</a> to create a secure <a href=\"https://azure.microsoft.com/overview/what-is-saas/\">SaaS app</a>. We'll cover the basic how-tos and benefits of integrating your app with Azure AD , as well as two common customer scenarios IoT developers may encounter.</p>\n<p>By integrating with the Microsoft identity platform and configuring the app to be <a href=\"https://learn.microsoft.com/azure/active-directory/develop/single-and-multi-tenant-apps\">multi-tenant</a>, developers can:</p>\n<ul>\n<li>Ensure isolation of customer resources and data.</li>\n<li>Enable access control by enforcing organizational policies and conditions based on time, location, and more.</li>\n<li>Support auditing and reporting of access.</li>\n<li>Allow users to sign in with existing work and social accounts, which in turn allows a <a href=\"https://learn.microsoft.com/azure/active-directory/manage-apps/what-is-single-sign-on\">single sign-on</a> experience so that users sign in once and are able to access other corporate resources and apps without signing in again.</li>\n</ul>\n<p>To learn more about the topics covered in this article, check out the <a href=\"https://learn.microsoft.com/azure/active-directory/develop\">Microsoft identity platform homepage</a>. The quickstart guides there will help you get set up quickly to integrate your app with our platform.</p>\n<blockquote>\n<p>[!NOTE]\nPlease leave feedback on the document whether you found it helpful or not! Your input matters in helping us to create useful content.</p>\n</blockquote>",
            "sample_code": true,
            "github_url": "https://github.com/Azure-Samples/active-directory-aspnetcore-webapp-openidconnect-v2/blob/master/2-WebApp-graph-user/2-3-Multi-Tenant/README.md",
            "name": "iot-aad",
            "popularity": 0,
            "topic": "Internet of Things"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "data-flow",
                "example-code",
                "example-workload",
                "fasttrack",
                "github",
                "pricing-calculator",
                "pricing-guidance",
                "security",
                "web-apps"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/apps/fully-managed-secure-apps.yml",
            "http_url": "/azure/architecture/example-scenario/apps/fully-managed-secure-apps",
            "word_count": 2023,
            "read_time": "8 min read",
            "Title": "Securely managed web applications",
            "MetaDescription": "Learn about deploying secure applications using the Azure App Service Environment, the Azure Application Gateway service, and Web Application Firewall.",
            "category": [
                "security",
                "web"
            ],
            "image": "/azure/architecture/example-scenario/apps/media/ilb-ase-architecture.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\apps\\media\\ilb-ase-architecture.png",
            "publish_date": "5/09/2019",
            "pricing_calculator": "https://azure.com/e/22e2c9d300ee425a89a001726221c7b2",
            "pricing_guidance": "pricing",
            "alternative_choices": "alternatives",
            "components": [
                "<p>The <a href=\"https://learn.microsoft.com/azure/app-service/environment/intro\">App Service Environment</a> provides a fully isolated, dedicated environment for securely running the application at high scale. In addition, since ASE and the workloads that run on it are behind a virtual network, it also provides an additional layer of security and isolation. The requirement of high scale and isolation drove the selection of ILB ASE.</p>",
                "<p>This workload is using the <a href=\"https://azure.microsoft.com/pricing/details/app-service/windows\">isolated App Service pricing tier</a>, so the application is running in a private dedicated environment in an Azure datacenter using Dv2-series VMs with faster processors, SSD storage, and double the memory-to-core ratio compared to Standard.</p>",
                "<p>Azure App Services <a href=\"https://learn.microsoft.com/azure/app-service/app-service-web-overview\">Web App</a> and <a href=\"https://learn.microsoft.com/azure/app-service/app-service-web-tutorial-rest-api\">API App</a> host web applications and RESTful APIs. These are hosted on the Isolated Pricing Tier plan that also offers autoscaling, custom domains, and so on, but in a dedicated tier.</p>",
                "<p>Azure <a href=\"https://learn.microsoft.com/azure/application-gateway/overview\">Application Gateway</a> is a web traffic load balancer operating at Layer 7 that manages traffic to the web application. It offers SSL offloading, which removes additional overhead from the web servers hosting the web app to decrypt traffic again.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/application-gateway/waf-overview\">Web Application Firewall</a> (WAF) is a feature of Application Gateway. Enabling the WAF in the Application Gateway further enhances security. The WAF uses OWASP rules to protect the web application against attacks such as cross-site scripting, session hijacks, and SQL injection.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/sql-database/sql-database-technical-overview\">Azure SQL Database</a> was selected because the majority of the data in this application is relational data, with some data as documents and Blobs.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/virtual-network/virtual-networks-overview\">Azure Networking</a> provides a variety of networking capabilities in Azure, and the networks can be peered with other virtual networks in Azure Connectivity can also be established with on-premises datacenters via ExpressRoute or site-to-site. In this case, a <a href=\"https://learn.microsoft.com/azure/sql-database/sql-database-vnet-service-endpoint-rule-overview\">service endpoint</a> is enabled on the virtual network to ensure the data is flowing only between the Azure virtual network and the SQL Database instance.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/devops/?view=vsts\">Azure DevOps</a> is used to help teams collaborate during many sprints, using features of Azure DevOps that support Agile Development, and to create build and release pipelines.</p>",
                "<p>An Azure build <a href=\"https://learn.microsoft.com/azure/virtual-machines/windows/overview\">VM</a> was created so that the installed agent can pull down the respective build, and deploy the web app to the ASE environment.</p>"
            ],
            "Summary": "<p>This scenario provides an overview of deploying secure applications using the <a href=\"https://learn.microsoft.com/azure/app-service/environment/intro\">Azure App Service Environment (ASE)</a>. To restrict application access from the Internet, the Azure Application Gateway service and Web Application Firewall are used. This article also provides guidance about continuous integration and continuous deployment (CI/CD) for App Service Environments using Azure DevOps.</p>\n<p>This scenario is commonly deployed in industries such as banking and insurance where customers are conscious of platform-level security in addition to application level security. To demonstrate these concepts, we'll use an application that allows users to submit expense reports.</p>",
            "Flow": {
                "FlowStep_A": "HTTP/HTTPS requests first hit the Application Gateway.",
                "FlowStep_B": "Optionally (not shown in the diagram), you can have Azure Active Directory (Azure AD) authentication enabled for the Web App. After the traffic first hits the Application Gateway, the user is then prompted to supply credentials to authenticate with the application.",
                "FlowStep_C": "User requests flow through the internal load balancer (ILB) of the ASE, which in turn routes the traffic to the Expenses Web App.",
                "FlowStep_D": "The user then proceeds to create an expense report.",
                "FlowStep_E": "As part of creating the expense report, the deployed API App is invoked to retrieve the user's manager name and email.",
                "FlowStep_F": "The created expense report is stored in Azure SQL Database.",
                "FlowStep_G": "To facilitate continuous deployment, code is checked into the Azure DevOps instance.",
                "FlowStep_H": "The build VM has the Azure DevOps Agent installed, allowing the build VM to pull the bits for the Web App to deploy to the ASE (since the Build VM is deployed in a subnet inside the same virtual network)."
            },
            "sample_code": true,
            "github_url": "https://github.com/Azure/fta-internalbusinessapps/blob/master/appmodernization/app-service-environment/ase-walkthrough.md",
            "name": "fully-managed-secure-apps",
            "popularity": 179,
            "topic": "Security"
        },
        {
            "tags": [
                "all-items",
                "fcp",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/n-tier/high-security-iaas.md",
            "http_url": "/azure/architecture/reference-architectures/n-tier/high-security-iaas",
            "word_count": 3505,
            "read_time": "14 min read",
            "Title": "Security considerations for highly sensitive IaaS apps in Azure",
            "MetaDescription": "Learn about VM security, encryption, NSGs, DMZs, access control, and other security considerations for highly sensitive IaaS and hybrid apps.",
            "category": [
                "security",
                "compute"
            ],
            "image": "/azure/architecture/reference-architectures/n-tier/images/dedicated-hosts.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\n-tier\\images\\dedicated-hosts.png",
            "publish_date": "4/15/2020",
            "Summary": "<p>There are many security considerations for deploying <em>infrastructure-as-a-service (IaaS)</em> apps to Azure. This article builds on reference architectures for virtual machine-based workloads and hybrid network infrastructures to focus on security for highly sensitive IaaS workloads in Azure, based on <a href=\"https://learn.microsoft.com/azure/security/fundamentals/\">Azure security fundamentals</a>.</p>\n<p>Also see <a href=\"https://learn.microsoft.com/azure/security/fundamentals/virtual-machines-overview\">Azure virtual machines security overview</a> and <a href=\"https://learn.microsoft.com/azure/security/fundamentals/iaas\">Security best practices for IaaS workloads in Azure</a>.</p>",
            "name": "high-security-iaas",
            "popularity": 0,
            "topic": "Security"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-onboarding-customers-with-a-cloud-native-serverless-architecture-'",
                "acom-architecture",
                "all-items",
                "cloud-innovation",
                "cloud-migration",
                "data-flow",
                "interactive-diagram",
                "lift-and-shift-cloud-strategy",
                "lift-and-shift-solution",
                "lift-and-shift-strategy",
                "line-of-business-app",
                "lob-app",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/onboarding-customers-with-a-cloud-native-serverless-architecture.md",
            "http_url": "/azure/architecture/solution-ideas/articles/onboarding-customers-with-a-cloud-native-serverless-architecture",
            "word_count": 169,
            "read_time": "1 min read",
            "Title": "Serverless Computing Solution for LOB Apps",
            "MetaDescription": "The solution demonstrates a business process for customer onboarding. This serverless architecture enables you to build and run applications without having to worry about the underlying infrastructure and the associated management and maintenance. By using it, you can dramatically improve developer productivity.",
            "category": [
                "migration",
                "developer-tools"
            ],
            "image": "/azure/architecture/solution-ideas/media/onboarding-customers-with-a-cloud-native-serverless-architecture.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\onboarding-customers-with-a-cloud-native-serverless-architecture.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>This serverless architecture enables you to build and run applications without having to worry about the underlying infrastructure and the associated management and maintenance. By using it, you can dramatically improve developer productivity.</p>",
            "Flow": {
                "FlowStep_A": "Information about the new customer is posted to a web endpoint.",
                "FlowStep_B": "The customer's photo is posted to [Cognitive Services Face API](/azure/cognitive-services/face/). Face API associates the customer's photo and name.",
                "FlowStep_C": "The customer information is recorded in [Dynamics 365](/dynamics365/) or other CRM.",
                "FlowStep_D": "The information about a new customer is sent to [Power BI](/power-bi/).",
                "FlowStep_E": "The customer information is added to the mailing list ([MailChimp](https://mailchimp.com/)).",
                "FlowStep_F": "The solution creates a record of the member in [Azure Cosmos DB](/azure/cosmos-db/)."
            },
            "name": "onboarding-customers-with-a-cloud-native-serverless-architecture",
            "popularity": 112,
            "topic": "Migration"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-serverless-application-architectures-using-event-grid-'",
                "acom-architecture",
                "all-items",
                "azure",
                "event-grid",
                "serverless",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/serverless-application-architectures-using-event-grid.md",
            "http_url": "/azure/architecture/solution-ideas/articles/serverless-application-architectures-using-event-grid",
            "word_count": 54,
            "read_time": "1 min read",
            "Title": "Serverless application architectures using Event Grid",
            "MetaDescription": "Event Grid connects data sources and event handlers. For example, use Event Grid to instantly trigger a serverless function to run image analysis each time a new photo is added to a blob storage container.",
            "category": [
                "developer-tools"
            ],
            "image": "/azure/architecture/solution-ideas/media/serverless-application-architectures-using-event-grid.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\serverless-application-architectures-using-event-grid.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Event Grid connects data sources and event handlers. For example, use Event Grid to instantly trigger a serverless function to run image analysis each time a new photo is added to a blob storage container.</p>",
            "name": "serverless-application-architectures-using-event-grid",
            "popularity": 51,
            "topic": "Developer Tools"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-serverless-apps-using-cosmos-db-'",
                "acom-architecture",
                "all-items",
                "cosmos-db",
                "serverless",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/serverless-apps-using-cosmos-db.md",
            "http_url": "/azure/architecture/solution-ideas/articles/serverless-apps-using-cosmos-db",
            "word_count": 32,
            "read_time": "1 min read",
            "Title": "Serverless apps using Azure Cosmos DB",
            "MetaDescription": "Use Azure Functions and Azure Cosmos DB to build globally distributed, scalable serverless applications.",
            "category": [
                "databases",
                "developer-tools"
            ],
            "image": "/azure/architecture/solution-ideas/media/serverless-apps-using-cosmos-db.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\serverless-apps-using-cosmos-db.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Use Azure Functions and Azure Cosmos DB to build globally distributed, scalable serverless applications.</p>",
            "name": "serverless-apps-using-cosmos-db",
            "popularity": 67,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "example-code",
                "fcp",
                "github",
                "solution-idea",
                "visio-diagram"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/durable-functions-containers.md",
            "http_url": "/azure/architecture/solution-ideas/articles/durable-functions-containers",
            "word_count": 663,
            "read_time": "3 min read",
            "Title": "Serverless batch processing with Durable Functions in Azure Container Instances",
            "MetaDescription": "Use Azure Functions Durable Functions to orchestrate, deploy, and run serverless batch processing jobs in Azure Container Instances (ACI) containers.",
            "category": [
                "compute",
                "containers"
            ],
            "image": "/azure/architecture/solution-ideas/media/durable-function-aci.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\durable-function-aci.png",
            "publish_date": "5/19/2020",
            "alternative_choices": "alternatives",
            "Summary": "<p>This article describes how you can use Azure Functions <a href=\"https://learn.microsoft.com/azure/azure-functions/durable/durable-functions-overview\">Durable Functions</a> to schedule, manage, and deploy serverless batch processing jobs in <a href=\"https://learn.microsoft.com/azure/container-instances/container-instances-overview\">Azure Container Instances</a> (ACI) containers.</p>\n<p>Containers are popular for packaging, deploying, and managing microservices-based architectures. <em>Orchestration</em> is the task of automating and managing containers and their interactions. Popular container orchestrator platforms like <a href=\"https://azure.microsoft.com/services/kubernetes-service/\">Azure Kubernetes Service</a> (AKS) and <a href=\"https://azure.microsoft.com/services/service-fabric/\">Azure Service Fabric</a> can manage complex, multi-container tasks and interactions.</p>\n<p>You don't always need full-fledged container orchestrators to provision and manage simple apps and jobs in isolated containers. ACI is the fastest and simplest way to run containers in Azure, and Durable Functions can orchestrate container deployment.</p>",
            "sample_code": true,
            "github_url": "https://github.com/Azure/azure-libraries-for-net",
            "visio_diagram": "https://arch-center.azureedge.net/Durable_Func_ACI.vsdx",
            "name": "durable-functions-containers",
            "popularity": 0,
            "topic": "Compute"
        },
        {
            "tags": [
                "all-items",
                "csharp",
                "example-code",
                "github",
                "reference-architecture",
                "seodec18",
                "serverless"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/serverless/event-processing.yml",
            "http_url": "/azure/architecture/reference-architectures/serverless/event-processing",
            "word_count": 1721,
            "read_time": "7 min read",
            "Title": "Serverless event processing",
            "MetaDescription": "Reference architecture for serverless event ingestion and processing using Azure Functions.",
            "category": [
                "developer-tools",
                "analytics"
            ],
            "image": "/azure/architecture/reference-architectures/serverless/_images/serverless-event-processing.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\serverless\\_images\\serverless-event-processing.png",
            "publish_date": "10/16/2018",
            "Summary": "<p>This reference architecture shows a <a href=\"https://azure.microsoft.com/solutions/serverless/\">serverless</a>, event-driven architecture that ingests a stream of data, processes the data, and writes the results to a back-end database.</p>\n<p><img alt=\"GitHub logo\" src=\"https://learn.microsoft.com/azure/architecture/_images/github.png\" /> A reference implementation for this architecture is available on <a href=\"https://github.com/mspnp/serverless-reference-implementation/tree/v0.1.0\">GitHub</a>.</p>\n<p><img alt=\"Reference architecture for serverless event processing using Azure Functions\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/serverless/_images/serverless-event-processing.png\" /></p>",
            "sample_code": true,
            "github_url": "https://github.com/mspnp/serverless-reference-implementation/tree/v0.1.0",
            "code_languages": [
                "csharp"
            ],
            "name": "event-processing",
            "popularity": 194,
            "topic": "Developer Tools"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "csharp",
                "data-flow",
                "example-code",
                "github",
                "reference-architecture",
                "seodec18",
                "serverless"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/serverless/web-app.yml",
            "http_url": "/azure/architecture/reference-architectures/serverless/web-app",
            "word_count": 4014,
            "read_time": "16 min read",
            "Title": "Serverless web application",
            "MetaDescription": "This reference architecture shows a serverless web application, which serves static content from Azure Blob Storage and implements an API using Azure Functions.",
            "category": [
                "web",
                "developer-tools"
            ],
            "image": "/azure/architecture/reference-architectures/serverless/_images/serverless-web-app.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\serverless\\_images\\serverless-web-app.png",
            "publish_date": "5/28/2019",
            "alternative_choices": "alternatively,-you-can-store-application-secrets-in-key-vault.-this-allows-you-to-centralize-the-storage-of-secrets,-control-their-distribution,-and-monitor-how-and-when-secrets-are-being-accessed.-for-more-information,-see-[configure-an-azure-web-application-to-read-a-secret-from-key-vault][key-vault-web-app].-however,-note-that-functions-triggers-and-bindings-load-their-configuration-settings-from-app-settings.-there-is-no-built-in-way-to-configure-the-triggers-and-bindings-to-use-key-vault-secrets.",
            "Summary": "<p>This reference architecture shows a <a href=\"https://azure.microsoft.com/solutions/serverless/\">serverless</a> web application. The application serves static content from Azure Blob Storage, and implements an API using Azure Functions. The API reads data from Azure Cosmos DB and returns the results to the web app.</p>\n<p><img alt=\"GitHub logo\" src=\"https://learn.microsoft.com/azure/architecture/_images/github.png\" /> A reference implementation for this architecture is available on <a href=\"https://github.com/mspnp/serverless-reference-implementation/tree/v0.1.0-update\">GitHub</a>.</p>\n<p><img alt=\"Reference architecture for a serverless web application\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/serverless/_images/serverless-web-app.png\" />\n<em>Download an <a href=\"https://learn.microsoft.com/azure/architecture/reference-architectures/serverless/_images/serverless-web-app.svg\">SVG</a> of this architecture.</em></p>\n<p>The term serverless has two distinct but related meanings:</p>\n<ul>\n<li><strong>Backend as a service</strong> (BaaS). Back-end cloud services, such as databases and storage, provide APIs that enable client applications to connect directly to these services.</li>\n<li><strong>Functions as a service</strong> (FaaS). In this model, a \"function\" is a piece of code that is deployed to the cloud and runs inside a hosting environment that completely abstracts the servers that run the code.</li>\n</ul>\n<p>Both definitions have in common the idea that developers and DevOps personnel don't need to deploy, configure, or manage servers. This reference architecture focuses on FaaS using Azure Functions, although serving web content from Azure Blob Storage could be an example of BaaS. Some important characteristics of FaaS are:</p>\n<ol>\n<li>Compute resources are allocated dynamically as needed by the platform.</li>\n<li>Consumption-based pricing: You are charged only for the compute resources used to execute your code.</li>\n<li>The compute resources scale on demand based on traffic, without the developer needing to do any configuration.</li>\n</ol>\n<p>Functions are executed when an external trigger occurs, such as an HTTP request or a message arriving on a queue. This makes an <a >event-driven architecture style</a> natural for serverless architectures. To coordinate work between components in the architecture, consider using message brokers or pub/sub patterns. For help with choosing between messaging technologies in Azure, see <a href=\"https://learn.microsoft.com/azure/event-grid/compare-messaging-services\">Choose between Azure services that deliver messages</a>.</p>",
            "Flow": {
                "FlowStep_A": "The user clicks the \"Sign in\" link in the web application.",
                "FlowStep_B": "The browser is redirected the Azure AD sign in page.",
                "FlowStep_C": "The user signs in.",
                "FlowStep_D": "Azure AD redirects back to the client application, including an access token in the URL fragment.",
                "FlowStep_E": "When the web application calls the API, it includes the access token in the Authentication header. The application ID is sent as the audience ('aud') claim in the access token.",
                "FlowStep_F": "The back-end API validates the access token."
            },
            "sample_code": true,
            "github_url": "https://github.com/mspnp/serverless-reference-implementation/tree/v0.1.0-update",
            "code_languages": [
                "csharp"
            ],
            "name": "web-app",
            "popularity": 223,
            "topic": "Web"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-sharepoint-farm-devtest-'",
                "acom-architecture",
                "all-items",
                "azure-sharepoint-development-environment",
                "data-flow",
                "interactive-diagram",
                "lob-app",
                "sharepoint-agile",
                "sharepoint-dev",
                "sharepoint-dev-environment",
                "sharepoint-farm-solution",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/sharepoint-farm-devtest.md",
            "http_url": "/azure/architecture/solution-ideas/articles/sharepoint-farm-devtest",
            "word_count": 399,
            "read_time": "2 min read",
            "Title": "SharePoint Farm for Development Testing",
            "MetaDescription": "Learn how to deploy a SharePoint farm for use as a development testing environment with a step-by-step flowchart from Azure.",
            "category": [
                "devops",
                "web"
            ],
            "image": "/azure/architecture/solution-ideas/media/sharepoint-farm-devtest.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\sharepoint-farm-devtest.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/features/resource-manager\">Azure Resource Group</a>: Container that holds related resources for an Azure solution</p>",
                "<p><a href=\"https://azure.microsoft.com/services/virtual-network\">Virtual Network</a>: Provision private networks, optionally connect to on-premises datacenters</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage\">Storage Accounts</a>: Durable, highly available, and massively scalable cloud storage</p>",
                "<p><a href=\"https://azure.microsoft.com/services/active-directory\">Azure Active Directory</a>: Synchronize on-premises directories and enable single sign-on</p>",
                "<p>SharePoint Server: Microsoft's collaboration server product</p>",
                "<p>Host enterprise <a href=\"https://azure.microsoft.com/services/virtual-machines/sql-server\">SQL Server</a> apps in the cloud</p>",
                "<p><a href=\"https://azure.microsoft.com/services/load-balancer\">Load Balancer</a>: Deliver high availability and network performance to your applications</p>",
                "<p><a href=\"https://azure.microsoft.com/services/expressroute\">Azure ExpressRoute</a>: Dedicated private network fiber connections to Azure</p>",
                "<p><a href=\"https://azure.microsoft.com/services/vpn-gateway\">VPN Gateway</a>: Establish secure, cross-premises connectivity</p>"
            ],
            "Summary": "<p>This solution provides a small scale deployment of SharePoint using a single Azure Active Directory (Azure AD), SQL, and SharePoint resources. It address the capability to deliver agile development architecture to teams within your business using the latest and greatest support platforms.</p>",
            "Flow": {
                "FlowStep_A": "Create resource group for the storage, network, and virtual machine, plus other dependent elements.",
                "FlowStep_B": "Create Virtual Network to host the Virtual Machines and Load Balancers for the deployment. Ensure the network has appropriate Network Security Groups implement to protect network traffic flow.",
                "FlowStep_C": "Create the storage accounts that will host the virtual machine images (VHDs).",
                "FlowStep_D": "Create the Active Directory Installation. Either utilizing a new Virtual Machine or using Azure Active Directory Domain Services. If using Azure Active Directory, you also need to consider synchronizing identities to Azure AD with Azure AD Connect.",
                "FlowStep_E": "Install a supported version of SQL Server on an Azure VM or deploy a pay as you go instance of SQL Server.",
                "FlowStep_F": "Deploy SharePoint onto an Azure VM or use a trial image from the gallery which already have SharePoint Server installed.",
                "FlowStep_G": "Create the SharePoint farm.",
                "FlowStep_H": "Set up an Azure external load balancer to direct incoming HTTPS traffic to the SharePoint server.",
                "FlowStep_I": "Use ExpressRoute or VPN Gateway for management access to resource group.",
                "FlowStep_J": "On Premises users can access the SharePoint sites via the internet or ExpressRoute or VPN Gateway.",
                "FlowStep_K": "External users can be granted access as required to the SharePoint sites for testing."
            },
            "name": "sharepoint-farm-devtest",
            "popularity": 37,
            "topic": "DevOps"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "example-code",
                "example-workload",
                "fcp",
                "github",
                "pricing-guidance"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/signalr/index.md",
            "http_url": "/azure/architecture/example-scenario/signalr",
            "word_count": 1435,
            "read_time": "6 min read",
            "Title": "Sharing location in real time using low-cost serverless Azure services",
            "MetaDescription": "SignalR configured in server-less mode to work with Azure Function triggered by Service Bus. All of it using .NET Core. This scenario is best used for real time messaging applications where users require a low-cost but robust messaging service.",
            "category": [
                "devops",
                "integration",
                "developer-tools",
                "hybrid"
            ],
            "image": "/azure/architecture/_images/reference-architectures.svg",
            "publish_date": "12/09/2019",
            "pricing_guidance": "pricing-this-scenario",
            "alternative_choices": "alternatives",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/service-bus\">Service Bus</a>, a highly reliable cloud messaging service between applications and services, even when one or more is offline.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/signalr-service\">SignalR</a> makes it easy to add real-time communications to your web application.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/functions\">Azure Functions</a>, an event-driven serverless compute platform that can also solve complex orchestration problems.</p>"
            ],
            "sample_code": true,
            "github_url": "https://github.com/mspnp/solution-architectures/tree/master/signalr",
            "name": "signalr",
            "popularity": 47,
            "topic": "DevOps",
            "hybrid-topic": "Apps"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-simple-branded-website-'",
                "acom-architecture",
                "all-items",
                "content-delivery",
                "data-flow",
                "easy-deploy",
                "interactive-diagram",
                "solution-idea",
                "web-app",
                "web-applications"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/simple-branded-website.md",
            "http_url": "/azure/architecture/solution-ideas/articles/simple-branded-website",
            "word_count": 225,
            "read_time": "2 min read",
            "Title": "Simple branded website",
            "MetaDescription": "Quickly build and launch digital campaigns that automatically scale based on customer demand.",
            "category": [
                "web"
            ],
            "image": "/azure/architecture/solution-ideas/media/simple-branded-website.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\simple-branded-website.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/app-service/web\">Web Apps</a>: Build and deploy web apps faster at scale</p>",
                "<p><a href=\"https://azure.microsoft.com/services/sql-database\">Azure SQL Database</a>: Managed, intelligent SQL in the cloud</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cdn\">Content Delivery Network</a>: Ensure secure, reliable content delivery with broad global reach</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cache\">Azure Cache for Redis</a>: Power applications with high-throughput, low-latency data access</p>",
                "<p>Application Insights: Detect, triage, and diagnose issues in your web apps and services</p>"
            ],
            "Summary": "<p>Quickly build and launch digital campaigns that automatically scale based on customer demand. Start simple with the content management system that enables you to easily maintain the messaging on your website in real time, from a browser, with no coding required.</p>",
            "Flow": {
                "FlowStep_A": "User accesses Web Apps from Azure App Service in a browser.",
                "FlowStep_B": "Application Insights detects issues and analyzes usage for your web apps.",
                "FlowStep_C": "Web App connects to SQL Database and Azure Cache for Redis for better performance.",
                "FlowStep_D": "Browser pulls static resources such as video from Azure Content Delivery Network to reduce load time."
            },
            "name": "simple-branded-website",
            "popularity": 96,
            "topic": "Web"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-digital-marketing-smb-'",
                "acom-architecture",
                "all-items",
                "solution-idea",
                "web-apps"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/digital-marketing-smb.md",
            "http_url": "/azure/architecture/solution-ideas/articles/digital-marketing-smb",
            "word_count": 257,
            "read_time": "2 min read",
            "Title": "Simple digital marketing website",
            "MetaDescription": "Start simple with the content management system that enables you to easily maintain the messaging on your website in real-time, from a browser, with no coding skills.",
            "category": [
                "web"
            ],
            "image": "/azure/architecture/solution-ideas/media/digital-marketing-smb.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\digital-marketing-smb.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/app-service/web\">Web Apps</a>: An App Service Web App runs in a single region, accessible to web and mobile browsers. A content management system like Orchard or Umbraco provides service to manage and deploy content to the website.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/sql-database\">Azure SQL Database</a>: A SQL Database stores and serves data about the site.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/monitor\">Azure Monitor</a>: Application Insights, provides health and performance monitoring, and diagnostics.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cdn\">Content Delivery Network</a>: A content delivery network serves static content such as images, script, and CSS, and reduces the load on the web app servers.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cache\">Azure Cache for Redis</a> enables very fast queries, and improves scalability by reducing the load on the main database.</p>"
            ],
            "Summary": "<p>Start simple with the content management system that enables you to easily maintain the messaging on your website in real-time, from a browser, with no coding skills.</p>\n<p>This solution is built on the Azure managed services: <a href=\"https://azure.microsoft.com/services/sql-database\">Azure SQL Database</a>, <a href=\"https://azure.microsoft.com/services/monitor\">Azure Monitor</a>, <a href=\"https://azure.microsoft.com/services/cdn\">Content Delivery Network</a> and <a href=\"https://azure.microsoft.com/services/cache\">Azure Cache for Redis</a>. These services run in a high-availability environment, patched and supported, allowing you to focus on your solution instead of the environment they run in.</p>",
            "name": "digital-marketing-smb",
            "popularity": 105,
            "topic": "Web"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-social-mobile-and-web-app-with-authentication-'",
                "acom-architecture",
                "all-items",
                "companion-web-app",
                "data-flow",
                "identity",
                "image-processing-app",
                "image-share-app",
                "interactive-diagram",
                "social-image-sharing",
                "solution-idea",
                "web-app"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/social-mobile-and-web-app-with-authentication.md",
            "http_url": "/azure/architecture/solution-ideas/articles/social-mobile-and-web-app-with-authentication",
            "word_count": 585,
            "read_time": "3 min read",
            "Title": "Social App for Mobile and Web with Authentication",
            "MetaDescription": "View a detailed, step-by-step diagram depicting the build process and implementation of the mobile client app architecture that offers social image sharing with a companion web app and authentication abilities, even while offline.",
            "category": [
                "mobile",
                "web",
                "identity"
            ],
            "image": "/azure/architecture/solution-ideas/media/social-mobile-and-web-app-with-authentication.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\social-mobile-and-web-app-with-authentication.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>This mobile client app offers social image sharing with a companion web app. The app back end service does background image processing using an Azure Function and can notify users of progress via a notification hub. Non-image data is stored in Azure Cosmos DB. The web app accesses the back end service data and images via Traffic Manager.</p>\n<p>The mobile client app works in offline mode, allowing you to view and upload images even when you don't have a network connection.</p>\n<p>The links to the right provide documentation on deploying and managing the Azure products listed in the solution architecture above.</p>\n<p><a href=\"https://azure.microsoft.com/services/visual-studio-team-services\">Visual Studio Team Services</a></p>\n<p><a href=\"https://www.visualstudio.com/vs\">Visual Studio</a></p>\n<p><a href=\"https://www.visualstudio.com/xamarin\">Visual Studio Tools for Xamarin</a></p>\n<p><a href=\"https://azure.microsoft.com/services/application-insights\">Application Insights</a></p>\n<p><a href=\"https://www.visualstudio.com/app-center\">Visual Studio App Center</a></p>\n<p><a href=\"https://azure.microsoft.com/services/app-service/mobile\">App Service Mobile Apps</a></p>",
            "Flow": {
                "FlowStep_A": "Create the app using Visual Studio and Xamarin.",
                "FlowStep_B": "Add the Azure App Service Mobile Apps back end service to the app solution.",
                "FlowStep_C": "Implement authentication through social identity providers.",
                "FlowStep_D": "Store non-image data in Azure Cosmos DB and cache it in Azure Cache for Redis.",
                "FlowStep_E": "Store uploaded images in Azure Blob Storage.",
                "FlowStep_F": "Queue messages about newly uploaded images.",
                "FlowStep_G": "Use Azure Functions to dequeue messages and process images retrieved from blob storage.",
                "FlowStep_H": "Send push notifications to users through a notification hub.",
                "FlowStep_I": "Build and test the app through Visual Studio App Center and publish it.",
                "FlowStep_J": "Control the distribution of user traffic to service endpoints in different datacenters.",
                "FlowStep_K": "Use Application Insights to monitor the app service."
            },
            "name": "social-mobile-and-web-app-with-authentication",
            "popularity": 80,
            "topic": "Mobile"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-speech-services-'",
                "acom-architecture",
                "all-items",
                "data-flow",
                "interactive-diagram",
                "services",
                "solution-idea",
                "speech",
                "speech-service"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/speech-services.md",
            "http_url": "/azure/architecture/solution-ideas/articles/speech-services",
            "word_count": 159,
            "read_time": "1 min read",
            "Title": "Speech Services",
            "MetaDescription": "A custom acoustic model helps Speech Services understand speakers even with background noise or poor phone connections.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/speech-services.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\speech-services.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>With Speech Services, it's easy to transcribe every call. Index the transcription for <a href=\"https://learn.microsoft.com/azure/search/search-what-is-azure-search\">full-text search</a>, or apply <a href=\"https://learn.microsoft.com/azure/cognitive-services/Text-Analytics\">Text Analytics</a> to detect sentiment, language, and key phrases for insights. If your call center recordings involve specialized terminology, such as product names or IT jargon, create a custom <a href=\"https://learn.microsoft.com/azure/cognitive-services/speech-service/how-to-customize-language-model\">language model</a> to teach Speech Services the vocabulary. A custom <a href=\"https://learn.microsoft.com/azure/cognitive-services/speech-service/how-to-customize-acoustic-models\">acoustic model</a> helps Speech Services understand speakers even with background noise or poor phone connections.</p>\n<p>For more information, read how <a href=\"https://learn.microsoft.com/azure/cognitive-services/speech-service/batch-transcription\">batch transcription</a> works with Speech Services.</p>",
            "Flow": {
                "FlowStep_A": "Adapt a model for your domain and deploy that model",
                "FlowStep_B": "Upload your recordings to a blob container",
                "FlowStep_C": "Create a POST request to batch transcription",
                "FlowStep_D": "Speech Services schedules the transcription job",
                "FlowStep_E": "Stereo files are split into two channels",
                "FlowStep_F": "Mono files undergo diarization to distinguish between speakers"
            },
            "name": "speech-services",
            "popularity": 22,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "github",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/ai/speech-to-text-transcription-pipeline.md",
            "http_url": "/azure/architecture/reference-architectures/ai/speech-to-text-transcription-pipeline",
            "word_count": 1651,
            "read_time": "7 min read",
            "Title": "Speech-to-text conversion",
            "MetaDescription": "This article describes the recommended way to upload audio files and process the speech content to text.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/reference-architectures/ai/_images/speech-to-text-audio-files-upload.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\ai\\_images\\speech-to-text-audio-files-upload.png",
            "publish_date": "3/25/2020",
            "Summary": "<p>Customer care centers are an integral part of the success of many businesses. You can improve the efficiency of your call centers by using speech AI. Speech recognition and the analysis of high volumes of recorded customer calls can provide your business with valuable information about current trends, product shortcomings, and successes. Enterprise solutions that use the Speech APIs of Azure Cognitive Services can be implemented to consume and process such high volumes of discrete data.</p>\n<p>The reference architecture described in this article shows how to build an audio ingestion and speech-to-text transcription pipeline for customer care centers. This pipeline processes batches of recorded audio files and stores the transcribed text files in Azure Blob storage. This architecture doesn't implement real-time speech processing.</p>\n<p>This pipeline can later feed into the next phase of your speech AI implementation. In that phase, you can process transcribed text to recognize and remove sensitive information, perform sentiment analysis, and so on.</p>\n<p>The reference implementation for this architecture is available on <a href=\"https://github.com/mspnp/cognitive-services-reference-implementation\">GitHub</a>.</p>",
            "sample_code": true,
            "github_url": "https://github.com/mspnp/cognitive-services-reference-implementation",
            "name": "speech-to-text-transcription-pipeline",
            "popularity": 0,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "all-items",
                "csharp",
                "example-code",
                "github",
                "reference-architecture",
                "seodec18"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/data/stream-processing-databricks.yml",
            "http_url": "/azure/architecture/reference-architectures/data/stream-processing-databricks",
            "word_count": 2696,
            "read_time": "11 min read",
            "Title": "Stream processing with Azure Databricks",
            "MetaDescription": "Create an end-to-end stream processing pipeline in Azure using Azure Databricks.",
            "category": [
                "analytics",
                "databases"
            ],
            "image": "/azure/architecture/reference-architectures/data/images/stream-processing-databricks.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\data\\images\\stream-processing-databricks.png",
            "publish_date": "11/30/2018",
            "Summary": "<p>This reference architecture shows an end-to-end <a >stream processing</a> pipeline. This type of pipeline has four stages: ingest, process, store, and analysis and reporting. For this reference architecture, the pipeline ingests data from two sources, performs a join on related records from each stream, enriches the result, and calculates an average in real time. The results are stored for further analysis.</p>\n<p><img alt=\"GitHub logo\" src=\"https://learn.microsoft.com/azure/architecture/_images/github.png\" /> A reference implementation for this architecture is available on <a href=\"https://github.com/mspnp/azure-databricks-streaming-analytics\">GitHub</a>.</p>\n<p><img alt=\"Reference architecture for stream processing with Azure Databricks\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/data/images/stream-processing-databricks.png\" /></p>\n<p><strong>Scenario</strong>: A taxi company collects data about each taxi trip. For this scenario, we assume there are two separate devices sending data. The taxi has a meter that sends information about each ride &mdash; the duration, distance, and pickup and drop-off locations. A separate device accepts payments from customers and sends data about fares. To spot ridership trends, the taxi company wants to calculate the average tip per mile driven, in real time, for each neighborhood.</p>",
            "sample_code": true,
            "github_url": "https://github.com/mspnp/azure-databricks-streaming-analytics",
            "code_languages": [
                "csharp"
            ],
            "name": "stream-processing-databricks",
            "popularity": 211,
            "topic": "Analytics"
        },
        {
            "tags": [
                "all-items",
                "csharp",
                "example-code",
                "github",
                "reference-architecture",
                "seodec18"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/data/stream-processing-stream-analytics.md",
            "http_url": "/azure/architecture/reference-architectures/data/stream-processing-stream-analytics",
            "word_count": 2271,
            "read_time": "10 min read",
            "Title": "Stream processing with Azure Stream Analytics",
            "MetaDescription": "This reference architecture shows an end-to-end stream processing pipeline, which ingests data, correlates records, and calculates a rolling average.",
            "category": [
                "analytics",
                "databases"
            ],
            "image": "/azure/architecture/reference-architectures/data/images/stream-processing-asa/stream-processing-asa.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\data\\images\\stream-processing-asa\\stream-processing-asa.png",
            "publish_date": "11/06/2018",
            "Summary": "<p>This reference architecture shows an end-to-end <a >stream processing</a> pipeline. The pipeline ingests data from two sources, correlates records in the two streams, and calculates a rolling average across a time window. The results are stored for further analysis.</p>\n<p><img alt=\"GitHub logo\" src=\"https://learn.microsoft.com/azure/architecture/_images/github.png\" /> A reference implementation for this architecture is available on <a href=\"https://github.com/mspnp/azure-stream-analytics-data-pipeline\">GitHub</a>.</p>\n<p><img alt=\"Reference architecture for creating a stream processing pipeline with Azure Stream Analytics\" src=\"https://learn.microsoft.com/azure/architecture/reference-architectures/data/images/stream-processing-asa/stream-processing-asa.png\" /></p>\n<p><strong>Scenario</strong>: A taxi company collects data about each taxi trip. For this scenario, we assume there are two separate devices sending data. The taxi has a meter that sends information about each ride &mdash; the duration, distance, and pickup and dropoff locations. A separate device accepts payments from customers and sends data about fares. The taxi company wants to calculate the average tip per mile driven, in real time, in order to spot trends.</p>",
            "sample_code": true,
            "github_url": "https://github.com/mspnp/azure-stream-analytics-data-pipeline",
            "code_languages": [
                "csharp"
            ],
            "name": "stream-processing-stream-analytics",
            "popularity": 199,
            "topic": "Analytics"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-streaming-using-hdinsight-'",
                "acom-architecture",
                "all-items",
                "data",
                "data-lake-storage",
                "hdinsight",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/streaming-using-hdinsight.md",
            "http_url": "/azure/architecture/solution-ideas/articles/streaming-using-hdinsight",
            "word_count": 34,
            "read_time": "1 min read",
            "Title": "Streaming using HDInsight",
            "MetaDescription": "Ingest and process millions of streaming events per second with Apache Kafka, Apache Storm, and Apache Spark Streaming.",
            "category": [
                "databases",
                "developer-tools"
            ],
            "image": "/azure/architecture/solution-ideas/media/streaming-using-hdinsight.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\streaming-using-hdinsight.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Ingest and process millions of streaming events per second with Apache Kafka, Apache Storm, and Apache Spark Streaming.</p>",
            "name": "streaming-using-hdinsight",
            "popularity": 42,
            "topic": "Databases"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-supply-chain-track-and-trace-'",
                "acom-architecture",
                "all-items",
                "azure-blockchain-workbench",
                "blockchain-and-iot",
                "blockchain-pattern",
                "blockchain-workbench",
                "data-flow",
                "interactive-diagram",
                "is-deployable",
                "manufacturing",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/supply-chain-track-and-trace.md",
            "http_url": "/azure/architecture/solution-ideas/articles/supply-chain-track-and-trace",
            "word_count": 726,
            "read_time": "3 min read",
            "Title": "Supply Chain Track and Trace",
            "MetaDescription": "Learn how to use the Azure Blockchain Workbench. Build an asset tracking application for supply chain with a step-by-step flowchart.",
            "category": [
                "blockchain",
                "iot"
            ],
            "image": "/azure/architecture/solution-ideas/media/supply-chain-track-and-trace.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\supply-chain-track-and-trace.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p>Application Insights: Detect issues, diagnose crashes, and track usage in your web app with Application Insights. Make informed decisions throughout the development lifecycle.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/app-service/web\">Web Apps</a>: Quickly create and deploy mission critical web apps at scale</p>",
                "<p><a href=\"https://azure.microsoft.com/services/storage\">Storage Accounts</a>: Durable, highly available, and massively scalable cloud storage</p>",
                "<p><a href=\"https://azure.microsoft.com/services/virtual-machines\">Virtual Machines</a>: Provision virtual machines for Ubuntu, Red Hat, and more</p>",
                "<p><a href=\"https://azure.microsoft.com/services/active-directory\">Azure Active Directory</a>: Synchronize on-premises directories and enable single sign-on</p>",
                "<p><a href=\"https://azure.microsoft.com/services/sql-database\">Azure SQL Database</a> is a relational database service that lets you rapidly create, extend, and scale relational applications into the cloud.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/monitor\">Azure Monitor</a>: Highly granular and real-time monitoring data for any Azure resource.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/service-bus\">Service Bus</a>: Connect across private and public cloud environments</p>",
                "<p><a href=\"https://azure.microsoft.com/services/event-grid\">Event Grid</a>: Get reliable event delivery at massive scale</p>"
            ],
            "Summary": "<p>A common blockchain pattern is IoT-enabled monitoring of an asset as it moves along a multi-party supply chain. A great example of this pattern is the refrigerated transportation of perishable goods like food or pharmaceuticals where certain compliance rules must be met throughout the duration of the transportation process. In this scenario, an initiating counterparty (such as a retailer) specifies contractual conditions, such as a required humidity and temperature range, that the custodians on the supply chain must adhere to. At any point, if the device takes a temperature or humidity measurement that is out of range, the smart contract state will be updated to indicate that it's out of compliance, recording a transaction on the blockchain and triggering remediating events downstream.</p>",
            "Flow": {
                "FlowStep_A": "IoT devices communicate with IoT Hub. IoT Hub as a route configured that will send specific messages to a Service Bus associated with that route. The message is still in the native format for the device and needs to be translated to the format used by Azure Blockchain Workbench.",
                "FlowStep_B": "DLT Consumer fetches the data from the message broker (Service Bus) and sends data to Transaction Builder - Signer.",
                "FlowStep_C": "Transaction Builder builds and signs the transaction.",
                "FlowStep_D": "The signed transaction gets routed to the Blockchain (Private Ethereum Consortium Network).",
                "FlowStep_E": "DLT Watcher gets confirmation of the transaction commitment to the Blockchain and sends the confirmation to the message broker (Service Bus).",
                "FlowStep_F": "DB consumers send confirmed blockchain transactions to off-chain databases (Azure SQL Database).",
                "FlowStep_G": "Information analyzed and visualized using tools such as Power BI by connecting to off-chain database (Azure SQL Database).",
                "FlowStep_H": "Events from the ledger are delivered to Event Grid and Service Bus for use by downstream consumers. Examples of \"downstream consumers\" include logic apps, functions or other code that is designed to take action on the events. For example, an Azure Function could receive an event and then place that in a datastore such as SQL Server."
            },
            "name": "supply-chain-track-and-trace",
            "popularity": 127,
            "topic": "Blockchain"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-task-based-consumer-mobile-app-'",
                "acom-architecture",
                "all-items",
                "app-dev",
                "consumer-mobile-app",
                "data-flow",
                "interactive-diagram",
                "mobile-app-authentication",
                "offline-mobile-app",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/task-based-consumer-mobile-app.md",
            "http_url": "/azure/architecture/solution-ideas/articles/task-based-consumer-mobile-app",
            "word_count": 517,
            "read_time": "3 min read",
            "Title": "Task-Based Consumer Mobile App",
            "MetaDescription": "Learn how the task-based consumer mobile app architecture is created with a step-by-step flow chart that shows the integration with Azure App Service Mobile Apps, Visual Studio, and Xamarin to simplify the build process.",
            "category": [
                "mobile",
                "developer-tools"
            ],
            "image": "/azure/architecture/solution-ideas/media/task-based-consumer-mobile-app.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\task-based-consumer-mobile-app.png",
            "publish_date": "12/16/2019",
            "Flow": {
                "FlowStep_A": "Create the mobile app using Visual Studio and Xamarin.",
                "FlowStep_B": "Create and configure a new Mobile Apps back end on the Azure portal, or through Visual Studio, and configure the solution in Visual Studio to communicate with the back end.",
                "FlowStep_C": "Implement authentication through social identity providers.",
                "FlowStep_D": "Create a model-driven data structure through the App Service APIs and SDK.",
                "FlowStep_E": "Implement offline sync to make the mobile app functional without a network connection.",
                "FlowStep_F": "If you created the back end in Visual Studio, you can publish the app service directly from Visual Studio (PC or Mac).",
                "FlowStep_G": "Store the solution source code with your source control provider of choice.",
                "FlowStep_H": "Build and test the app through Visual Studio App Center and publish it.",
                "FlowStep_I": "Use Application Insights to monitor the App Service."
            },
            "name": "task-based-consumer-mobile-app",
            "popularity": 75,
            "topic": "Mobile"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "example-code",
                "example-workload",
                "fcp",
                "github",
                "json"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/data/sentinel-threat-intelligence.md",
            "http_url": "/azure/architecture/example-scenario/data/sentinel-threat-intelligence",
            "word_count": 3126,
            "read_time": "13 min read",
            "Title": "Threat indicators for cyber threat intelligence in Azure Sentinel",
            "MetaDescription": "Import threat indicators, view logs, create rules to generate security alerts and incidents, and visualize threat intelligence data with Azure Sentinel.",
            "category": [
                "security"
            ],
            "image": "/azure/architecture/example-scenario/data/media/sentinel-threat-intelligence/sentinel-data-flow.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\data\\media\\sentinel-threat-intelligence\\sentinel-data-flow.png",
            "publish_date": "4/13/2020",
            "alternative_choices": "alternatives",
            "Summary": "<p>This article describes how a cloud-based <em>Security Information and Event Management (SIEM)</em> solution like <a href=\"https://learn.microsoft.com/azure/sentinel/overview\">Azure Sentinel</a> can use <em>threat indicators</em> to detect, provide context, and inform responses to existing or potential cyber threats. </p>\n<p><em>Cyber threat intelligence (CTI)</em> can come from many sources, such as open-source data feeds, threat intelligence sharing communities, paid intelligence feeds, and security investigations within organizations. CTI can range from written reports on a threat actor's motivations, infrastructure, and techniques, to specific observations of IP addresses, domains, and file hashes. CTI provides essential context for unusual activity, so security personnel can act quickly to protect people and assets.</p>\n<p>The most utilized CTI in SIEM solutions like Azure Sentinel is threat indicator data, sometimes called <em>Indicators of Compromise (IoCs)</em>. Threat indicators associate URLs, file hashes, IP addresses, and other data with known threat activity like phishing, botnets, or malware. This form of threat intelligence is often called <em>tactical threat intelligence</em>, because security products and automation can use it in large scale to protect and detect potential threats. Azure Sentinel can help detect, respond to, and provide CTI context for malicious cyber activity. </p>",
            "sample_code": true,
            "github_url": "https://github.com/Azure/Azure-Sentinel",
            "code_languages": [
                "json"
            ],
            "name": "sentinel-threat-intelligence",
            "popularity": 0,
            "topic": "Security"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-tiered-data-for-analytics-'",
                "acom-architecture",
                "all-items",
                "analytics",
                "application-tier",
                "data-flow",
                "data-tier",
                "hybrid-application",
                "interactive-diagram",
                "solution-idea",
                "tier-application-architecture",
                "tier-architecture",
                "tier-data"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/tiered-data-for-analytics.md",
            "http_url": "/azure/architecture/solution-ideas/articles/tiered-data-for-analytics",
            "word_count": 186,
            "read_time": "1 min read",
            "Title": "Tier Applications & Data for Analytics",
            "MetaDescription": "Tier applications and data with a solution architecture that includes Azure Stack. Optimize data analytics with a step-by-step flowchart and detailed instructions.",
            "category": [
                "analytics",
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/tiered-data-for-analytics.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\tiered-data-for-analytics.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/storage\">Storage</a>: Durable, highly available, and massively scalable cloud storage</p>",
                "<p><a href=\"https://azure.microsoft.com/services/functions\">Azure Functions</a>: Process events with serverless code</p>",
                "<p><a href=\"https://azure.microsoft.com/overview/azure-stack\">Azure Stack</a>: Build and run innovative hybrid applications across cloud boundaries</p>"
            ],
            "Flow": {
                "FlowStep_A": "Data flows into a storage account.",
                "FlowStep_B": "Function on Azure Stack analyzes the data for anomalies or compliance.",
                "FlowStep_C": "Locally-relevant insights are displayed on the Azure Stack app.",
                "FlowStep_D": "Insights and anomalies are placed into a queue.",
                "FlowStep_E": "The bulk of the data is placed into an archive storage account.",
                "FlowStep_F": "Function sends data from queue to Azure Storage.",
                "FlowStep_G": "Globally-relevant and compliant insights are available in the global app."
            },
            "name": "tiered-data-for-analytics",
            "popularity": 129,
            "topic": "Analytics"
        },
        {
            "tags": [
                "all-items",
                "azcat-ai",
                "example-code",
                "github",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/ai/training-python-models.md",
            "http_url": "/azure/architecture/reference-architectures/ai/training-python-models",
            "word_count": 1449,
            "read_time": "6 min read",
            "Title": "Training Python models on Azure",
            "MetaDescription": "This reference architecture shows recommended practices for tuning the hyperparameters (training parameters) of a scikit-learn Python model.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/reference-architectures/ai/_images/training-python-models.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\ai\\_images\\training-python-models.png",
            "publish_date": "7/17/2019",
            "sample_code": true,
            "github_url": "https://github.com/Microsoft/MLHyperparameterTuning",
            "name": "training-python-models",
            "popularity": 174,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-training-and-procedural-guidance-powered-by-mixed-reality-'",
                "acom-architecture",
                "ai-ml",
                "all-items",
                "azure-active-directory",
                "azure-app-service",
                "azure-cosmos-db",
                "azure-spatial-anchors",
                "data-flow",
                "interactive-diagram",
                "media-services",
                "microsoft-hololens",
                "solution-idea",
                "video-indexer"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/training-and-procedural-guidance-powered-by-mixed-reality.md",
            "http_url": "/azure/architecture/solution-ideas/articles/training-and-procedural-guidance-powered-by-mixed-reality",
            "word_count": 524,
            "read_time": "3 min read",
            "Title": "Training and procedural guidance powered by mixed reality",
            "MetaDescription": "Enable your team and employees to learn new processes and materials faster, with fewer errors, and greater confidence by providing persistent holographic instructions mapped to precise locations in their physical workspace.",
            "category": [
                "mixed-reality"
            ],
            "image": "/azure/architecture/solution-ideas/media/training-and-procedural-guidance-powered-by-mixed-reality.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\training-and-procedural-guidance-powered-by-mixed-reality.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/spatial-anchors\">Spatial Anchors</a>: Create multi-user, spatially aware mixed reality experiences</p>",
                "<p><a href=\"https://azure.microsoft.com/services/active-directory\">Azure Active Directory</a>: Synchronize on-premises directories and enable single sign-on</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cosmos-db\">Azure Cosmos DB</a>: Globally distributed, multi-model database for any scale</p>",
                "<p><a href=\"https://azure.microsoft.com/services/app-service\">App Service</a>: Quickly create powerful cloud apps for web and mobile</p>",
                "<p><a href=\"https://azure.microsoft.com/services/media-services\">Media Services</a>: Encode, store, and stream video and audio at scale</p>",
                "<p><a href=\"https://azure.microsoft.com/services/media-services/video-indexer\">Video Indexer</a>: Make your media more discoverable and accessible</p>"
            ],
            "Summary": "<p>Enable your team and employees to learn new processes and materials faster, with fewer errors, and greater confidence by providing persistent holographic instructions mapped to precise locations in their physical workspace. Jumpstart employee comprehension with head-up, hands-free experiences using HoloLens devices. And with Azure Spatial Anchors, you can place directions on the procedure's most important objects and return to this content over time.</p>",
            "Flow": {
                "FlowStep_A": "The user creating the training session authenticates using their Azure Active Directory credentials from HoloLens.",
                "FlowStep_B": "The client application connects to its own web service to create a training session. Metadata about that training session is stored in Azure Cosmos DB.",
                "FlowStep_C": "The user scans the environment and places a first anchor where the first step of the procedure needs to happen. Azure Spatial Anchors validates that the user has sufficient permissions to create anchors via Azure AD, and then stores the anchor.",
                "FlowStep_D": "The user records a video of the procedure on HoloLens and uploads it to Azure",
                "FlowStep_E": "The video is encoded with Media Services and prepared for on-demand viewing, as well as processed with Video Indexer for better content search. Video Indexer stores the metadata on Azure Cosmos DB.",
                "FlowStep_F": "The app saves against its web service the anchor ID for that first step, alongside a link to the video.",
                "FlowStep_G": "The user, in the same session, then moves on to step 2, places an anchor there, and again records a video of the procedure and saves the resulting anchor ID and video link to its web service. That process is then repeated until all steps in the procedure are executed. As the user moves from step to step, previous anchors are still visible with their respective step number.",
                "FlowStep_H": "A trainee comes in, selects the training session, retrieves anchor IDs and links to videos that are part of the procedure.",
                "FlowStep_I": "The trainee scans the room to find the anchors indicating the real-world location of each step in the procedure. As soon as one is found, all anchors are retrieved and shown in the app.",
                "FlowStep_J": "The trainee can then retrace the exact steps of the expert who recorded the procedure, and view holographic videos of each step at the right location in the lab."
            },
            "name": "training-and-procedural-guidance-powered-by-mixed-reality",
            "popularity": 66,
            "topic": "Mixed Reality"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "networking",
                "powershell",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/hybrid-networking/troubleshoot-vpn.yml",
            "http_url": "/azure/architecture/reference-architectures/hybrid-networking/troubleshoot-vpn",
            "word_count": 1751,
            "read_time": "8 min read",
            "Title": "Troubleshoot a hybrid VPN connection",
            "MetaDescription": "Troubleshoot a VPN gateway connection between an on-premises network and Azure.",
            "category": [
                "hybrid",
                "networking"
            ],
            "image": "/azure/architecture/reference-architectures/_images/guidance-hybrid-network-vpn/RRAS-perf-counters.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\_images\\guidance-hybrid-network-vpn\\RRAS-perf-counters.png",
            "publish_date": "10/08/2018",
            "Summary": "<p>This article gives some tips for troubleshooting a VPN gateway connection between an on-premises network and Azure. For general information on troubleshooting common VPN-related errors, see <a href=\"https://learn.microsoft.com/archive/blogs/asksbs/troubleshooting-common-vpn-issues\">Troubleshooting common VPN related errors</a>.</p>",
            "code_languages": [
                "powershell"
            ],
            "sample_code": true,
            "name": "troubleshoot-vpn",
            "popularity": 100,
            "topic": "Networking",
            "hybrid-topic": "Networking"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "fcp",
                "github",
                "iot",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/uven-disinfection.md",
            "http_url": "/azure/architecture/solution-ideas/articles/uven-disinfection",
            "word_count": 1123,
            "read_time": "5 min read",
            "Title": "UVEN smart and secure disinfection and lighting",
            "MetaDescription": "See how BrainLit's UVEN system uses IoT and Azure Sphere to provide smart, safe, secure virus disinfection and healthy, human-optimized lighting.",
            "category": [
                "iot"
            ],
            "image": "/azure/architecture/solution-ideas/media/uven-system.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\uven-system.png",
            "publish_date": "7/15/2020",
            "Summary": "<p>Smart, connected Internet of Things (IoT) devices can make life healthier and safer. For example, research increasingly confirms the importance of high-quality light and natural light cycles for promoting human alertness, health, well-being, and productivity. BrainLit's patented BioCentric Lighting\u2122 (BCL) system is a dynamic, self-learning, IoT-based system that creates high-quality natural lighting for indoor environments. </p>\n<p>The BCL system can also deliver radiant energy in the non-visible ultraviolet (UV) spectrum to kill viruses. All UV radiation has antimicrobial capabilities. The shortest wavelength, 200-300 nm UVC radiation, causes DNA inactivation and prevents viral replication. UVC radiation disinfection is an important weapon in the fight against COVID. BrainLit's new UVEN concept combines BCL light control with UVC disinfection to promote health and well-being and help kill viruses.</p>\n<p>Other UVC virus-killing technology that uses plug-in devices, robots, drones, and wands can't provide overall space coverage or performance and effectiveness data. To operate these devices safely and efficiently disrupts business and personnel, resulting in loss of productivity and lower space utilization. UVEN disinfection operates in unoccupied spaces during non-use times, providing safe, comprehensive, autonomous microbe deactivation without business disruption.</p>\n<p>Because IoT devices work directly on the physical environment and may use and collect sensitive data, device safety and security are paramount. UVEN double fail-safe features ensure occupants receive beneficial light only. The <a href=\"https://azure.microsoft.com/services/azure-sphere/\">Azure Sphere</a> standalone microprocessor unit (MCU)-based platform securely runs IoT apps and connects directly to the cloud for complete Azure-based security and the latest OS and app updates.</p>\n<p>The system can continually integrate new research developments and public health updates via its cloud connection, ensuring an up-to-date and scientifically based lighting and disinfection system.</p>\n<p>UVEN combined BCL and UVC technology offers:\n- A smart, safe, and secure integrated system solution for lighting and disinfection, with optimal usage of floor areas.\n- Long-term solutions that can adapt lighting and disinfection doses and recipes to changing circumstances.\n- Overall better health and improved immune systems for occupants through optimized lighting and a virus-free environment.</p>",
            "sample_code": true,
            "github_url": "https://github.com/Azure/azure-sphere-samples",
            "name": "uven-disinfection",
            "popularity": 0,
            "topic": "Internet of Things"
        },
        {
            "tags": [
                "all-items",
                "data-flow",
                "example-code",
                "example-workload",
                "fcp",
                "github",
                "json"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/logging/unified-logging.md",
            "http_url": "/azure/architecture/example-scenario/logging/unified-logging",
            "word_count": 1985,
            "read_time": "8 min read",
            "Title": "Unified logging for microservices applications",
            "MetaDescription": "Learn about logging, tracing, and monitoring for microservices apps. Run synthetic logging for testing, and create structured logs for analysis.",
            "category": [
                "devops"
            ],
            "image": "/azure/architecture/example-scenario/logging/media/paas-tracing-logging.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\logging\\media\\paas-tracing-logging.png",
            "publish_date": "7/13/2020",
            "Summary": "<p><em>Logging</em> uses discrete event messages to track and report application data in a centralized way. Log events provide an overview of application execution state, track code errors or application failures, and deliver informational messages. Automation can read event logs and notify relevant parties if events meet a criterion or threshold.</p>\n<p><em>Tracing</em> focuses on the continuous flow of an application. Tracing follows program execution through various methods and services from beginning to end, while understanding data state and transitions.</p>\n<p><em>Monitoring</em> applies application instrumentation to both tracing or logging data to provide metrics that teams can use to make informed decisions. These metrics can aggregate log or trace data in a dashboard that gives a holistic view of application health, from utilization to error count.</p>\n<p>Whenever an application fails, teams need to know:</p>\n<ul>\n<li>Why did the application fail?</li>\n<li>When did the application exception occur?</li>\n<li>Which method caused the exception?</li>\n<li>What were the events recorded up to the point of application failure?</li>\n<li>Did this exception lead to potential data corruption?</li>\n</ul>\n<p>Logging, tracing, and monitoring can provide the answers to these questions, as well as monitor application usage and performance.</p>\n<p>For traditional on-premises or monolithic applications, logging, tracing, and monitoring happen within a single process domain. The application consists of a single executable and its dependencies. The executable runs under the single process space on a single virtual machine (VM), or across multiple VMs to increase performance.</p>\n<p>Cloud-native development differs from on-premises methodology. Many cloud-native applications consist of platform-as-a-service (PaaS) services built around the <a >microservices</a> architectural paradigm. Microservices architectures involve discrete, loosely coupled services that work within their own process boundaries. Microservices architectures:</p>\n<ul>\n<li>Consist of discrete services that are easier to build and simpler to maintain.</li>\n<li>Focus on business capabilities.</li>\n<li>Work well with automated continuous integration (CI) and continuous delivery (CD) systems.</li>\n<li>Are more fault-tolerant, because a single service failure doesn't bring down the application.</li>\n<li>Allow services to scale independently of each other to provide better utilization and cost optimization.</li>\n</ul>\n<p>Logging and tracing for cloud-native distributed applications can be complicated. A single application request can interact with many microservices. Each microservice generates its own logging, and determining the application execution process flow can be difficult. Because microservices can handle hundreds of requests concurrently, wading through logs to manually determine event correlations can be a laborious task.</p>\n<p>Several Azure services and strategies can help automate and manage effective logging, tracing, and monitoring for microservices applications. With unified logging, development and operations teams can gain deep insights from within as well as from outside application domains. Unified logging and monitoring help ensure that deployed cloud-native applications remain reliable, scalable, redundant, resilient, and secure.</p>",
            "Flow": {
                "FlowStep_A": "A Logic Apps job calls the representational state transfer (REST) endpoint of an Information Technology Service Management (ITSM) system, and sends notifications to the development team.",
                "FlowStep_B": "Azure Sentinel automation uses Playbooks powered by Azure Logic Apps to generate security alerts.",
                "FlowStep_C": "Keeping event logs in long-term storage allows later analysis and diagnostics with Log Analytics."
            },
            "sample_code": true,
            "github_url": "https://github.com/serilog",
            "code_languages": [
                "json"
            ],
            "name": "unified-logging",
            "popularity": 0,
            "topic": "DevOps"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-unlock-legacy-data-'",
                "acom-architecture",
                "all-items",
                "app-modernization",
                "data",
                "data-flow",
                "data-preservation",
                "interactive-diagram",
                "legacy-data",
                "legacy-data-integration",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/unlock-legacy-data.md",
            "http_url": "/azure/architecture/solution-ideas/articles/unlock-legacy-data",
            "word_count": 148,
            "read_time": "1 min read",
            "Title": "Unlock Legacy Data with Azure Stack",
            "MetaDescription": "Follow a step-by-step flowchart to unlock and preserve legacy data from mainframe applications using Azure Stack.",
            "category": [
                "migration",
                "databases"
            ],
            "image": "/azure/architecture/solution-ideas/media/unlock-legacy-data.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\unlock-legacy-data.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/virtual-network\">Virtual Network</a>: Provision private networks, optionally connect to on-premises datacenters</p>",
                "<p><a href=\"https://azure.microsoft.com/services/vpn-gateway\">VPN Gateway</a>: Establish secure, cross-premises connectivity</p>"
            ],
            "Summary": "<p>Use Azure Stack to update and extend your legacy application data with the latest cloud technology such as Azure web services, containers, serverless computing, and microservices architectures. This is a solution to create new applications while integrating and preserving legacy data in mainframe and core business process applications.</p>",
            "Flow": {
                "FlowStep_A": "User enters data into Azure-based web app.",
                "FlowStep_B": "Application commits data to database over virtual network-to-virtual network VPN connection to Azure Stack.",
                "FlowStep_C": "Data is processed by applications running on a Kubernetes cluster on Azure Stack.",
                "FlowStep_D": "Kubernetes cluster communicates with legacy system on corporate network."
            },
            "name": "unlock-legacy-data",
            "popularity": 95,
            "topic": "Migration"
        },
        {
            "tags": [
                "all-items",
                "cse",
                "data-flow",
                "example-code",
                "example-workload",
                "fcp",
                "github"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/cobalt/cobalt-extensible-cloud-framework.md",
            "http_url": "/azure/architecture/example-scenario/cobalt/cobalt-extensible-cloud-framework",
            "word_count": 2289,
            "read_time": "9 min read",
            "Title": "Use Cobalt to create an extensible cloud framework",
            "MetaDescription": "Cobalt is an extensible framework that uses templates to define the automated process of creating complex and enterprise-grade CI/CD implementations to deploy highly available applications to Web App for Containers.",
            "category": [
                "management-and-governance"
            ],
            "image": "/azure/architecture/example-scenario/cobalt/media/single-region-architecture.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\cobalt\\media\\single-region-architecture.png",
            "publish_date": "7/31/2020",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/active-directory/\">Azure Active Directory</a></p>",
                "<p><a href=\"https://azure.microsoft.com/services/app-service/\">Azure App Service</a></p>",
                "<p><a href=\"https://azure.microsoft.com/services/app-service/containers/\">Web App for Containers</a></p>",
                "<p><a href=\"https://azure.microsoft.com/services/container-registry/\">Azure Container Registry (ACR)</a></p>",
                "<p><a href=\"https://azure.microsoft.com/services/devops/\">Azure DevOps</a></p>",
                "<p><a href=\"https://azure.microsoft.com/services/key-vault/\">Azure Key Vault</a></p>",
                "<p><a href=\"https://azure.microsoft.com/services/devops/pipelines/\">Azure Pipelines</a></p>"
            ],
            "Summary": "<p>Standardizing and automating the process of building production-ready cloud native managed service solutions is an important need for major enterprise customers. The customers need to achieve higher productivity, higher efficiency, and easier compliance with security, governance, and privacy. The Microsoft commercial software engineering (CSE) team engaged with a Fortune 50 retailer.</p>\n<p>The goal was to enable the customer's teams to build such solutions based on one or more specified patterns in an enterprise pattern library. There was a need to elevate this effort by creating a framework that can materialize such patterns. The CSE team leveraged the Cobalt framework to achieve that goal.</p>\n<p>Cobalt is an extensible framework that uses templates. The templates define the automated process of creating complex and enterprise-grade continuous integration and continuous deployment (CI/CD) implementations. The system is used to deploy highly available applications to <em>Web App for Containers</em>. Developers deploy the infrastructure using versioned files containing the reusable templates. The templates contain the infrastructure and platform details and developers can customize or reuse them as needed.</p>\n<p>Using Cobalt reduces the amount of time required to get apps through customers' security and compliance review process. With Cobalt, they can abstract the complexities of cloud-native computing away from app developer teams. The app developer teams can concentrate on rapidly building apps in a repeatable way that not only follows DevOps best practices, but are highly secure and resilient. Apps like this can take advantage of managed services and continuous delivery for better reliability. Cobalt also dramatically reduces time required to deploy complex applications.</p>",
            "Flow": {
                "FlowStep_A": "Customize an existing Cobalt template or create a new one.",
                "FlowStep_B": "Code, test, and commit changes to the template to an upstream GitHub repository.",
                "FlowStep_C": "Finally, Cobalt automatically provisions and configures the cloud resources specified in the template."
            },
            "sample_code": true,
            "github_url": "https://github.com/microsoft/cobalt/tree/master/infra/templates/az-isolated-service-single-region",
            "name": "cobalt-extensible-cloud-framework",
            "popularity": 0,
            "topic": "Management and Governance"
        },
        {
            "tags": [
                "all-items",
                "fcp",
                "reference-architecture",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "hybrid/azure-file-share.md",
            "http_url": "/azure/architecture/hybrid/azure-file-share",
            "word_count": 2398,
            "read_time": "10 min read",
            "Title": "Using Azure file shares in a hybrid environment",
            "MetaDescription": "Azure file shares can replace traditional file servers. With identity-based authentication you can control access to Azure file shares by using AD DS users and groups.",
            "category": [
                "hybrid",
                "storage"
            ],
            "image": "/azure/architecture/hybrid/images/azure-file-share.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\hybrid\\images\\azure-file-share.png",
            "publish_date": "7/26/2020",
            "Summary": "<p>This architecture shows how to include Azure file shares in your hybrid environment. Azure file shares are used as serverless file shares. By integrating them with Active Directory Directory Services (AD DS), you can control and limit access to AD DS users and Azure file shares can replace traditional file servers.</p>\n<p><img alt=\"Azure file shares architecture diagram that shows how clients can access Azure file share directly over TCP port 445 (SMB 3.0) or by establishing VPN connection first.\" src=\"https://learn.microsoft.com/azure/architecture/hybrid/images/azure-file-share.png\" /></p>\n<p><em>Download a <a href=\"https://arch-center.azureedge.net/azure-file-share.vsdx\">Visio file</a> of this architecture.</em></p>\n<p>Typical uses for this architecture include:</p>\n<ul>\n<li>*<em>Replace or supplement on-premises file servers</em>. All companies use file servers. Azure Files can completely replace or supplement traditional on-premises file servers or network-attached storage devices. With Azure file shares and AD DS authentication, you can migrate data to Azure Files and take the advantage of high availability and scalability while minimizing client changes.</li>\n<li><strong>Lift and shift</strong>. Azure Files makes it easy to \"lift and shift\" applications that expect a file share to store application or user data to the cloud.</li>\n<li><strong>Backup and disaster recovery</strong>. You can use Azure file shares as storage for backups or for disaster recovery to improve business continuity. You can use Azure file shares to back up your data from existing file servers while preserving configured Windows discretionary access control lists. Data that's stored on Azure file shares isn't affected by disasters that might affect on-premises locations.</li>\n<li><strong>Azure File Sync</strong>. With Azure File Sync, Azure file shares can replicate to Windows Server, either on-premises or in the cloud, for performance and distributed caching of data where it's being used.</li>\n</ul>",
            "visio_diagram": "https://arch-center.azureedge.net/azure-file-share.vsdx",
            "name": "azure-file-share",
            "popularity": 0,
            "topic": "Storage",
            "hybrid-topic": "Data"
        },
        {
            "tags": [
                "all-items",
                "app-modernization",
                "application-development",
                "example-workload",
                "fasttrack",
                "pricing-calculator",
                "pricing-guidance"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/infrastructure/service-fabric-microservices.yml",
            "http_url": "/azure/architecture/example-scenario/infrastructure/service-fabric-microservices",
            "word_count": 1386,
            "read_time": "6 min read",
            "Title": "Using Service Fabric to decompose applications",
            "MetaDescription": "Learn about Azure Service Fabric as a platform for decomposing an unwieldy monolithic application into multiple, manageable microservices.",
            "category": [
                "migration",
                "developer-tools"
            ],
            "image": "/azure/architecture/example-scenario/infrastructure/media/architecture-service-fabric-complete.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\infrastructure\\media\\architecture-service-fabric-complete.png",
            "publish_date": "9/20/2018",
            "pricing_calculator": "https://azure.com/e/52dea096e5844d5495a7b22a9b2ccdde",
            "pricing_guidance": "pricing",
            "Summary": "<p>In this example scenario, we walk through an approach using <a href=\"https://learn.microsoft.com/azure/service-fabric/service-fabric-overview\">Service Fabric</a> as a platform for decomposing an unwieldy monolithic application. Here we consider an iterative approach to decomposing an IIS/ASP.NET web site into an application composed of multiple, manageable microservices.</p>\n<p>Moving from a monolithic architecture to a microservice architecture provides the following benefits:</p>\n<ul>\n<li>You can change one small, understandable unit of code and deploy only that unit.</li>\n<li>Each code unit requires just a few minutes or less to deploy.</li>\n<li>If there is an error in that small unit, only that unit stops working, not the whole application.</li>\n<li>Small units of code can be distributed easily and discretely among multiple development teams.</li>\n<li>New developers can quickly and easily grasp the discrete functionality of each unit.</li>\n</ul>\n<p>A large IIS application on a server farm is used in this example, but the concepts of iterative decomposition and hosting can be used for any type of large application. While this solution uses Windows, Service Fabric can also run on Linux. It can be run on-premises, in Azure, or on VM nodes in the cloud provider of your choice.</p>",
            "name": "service-fabric-microservices",
            "popularity": 189,
            "topic": "Migration"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-digital-media-video-'",
                "acom-architecture",
                "all-items",
                "media",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/digital-media-video.md",
            "http_url": "/azure/architecture/solution-ideas/articles/digital-media-video",
            "word_count": 346,
            "read_time": "2 min read",
            "Title": "Video-on-demand digital media",
            "MetaDescription": "A basic video-on-demand solution that gives you the capability to stream recorded video content such as movies, news clips, sports segments, training videos, and customer support tutorials to any video-capable endpoint device, mobile application, or desktop browser. Video files are uploaded to Azure Blob storage, encoded to a multi-bitrate standard format, and then distributed via all major adaptive bit-rate streaming protocols (HLS, MPEG-DASH, Smooth) to the Azure Media Player client.",
            "category": [
                "media",
                "web"
            ],
            "image": "/azure/architecture/solution-ideas/media/digital-media-video.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\digital-media-video.png",
            "publish_date": "12/16/2019",
            "components": [
                "<p><a href=\"https://azure.microsoft.com/services/storage/blobs\">Blob Storage</a>: Stores large amounts of unstructured data, such as text or binary data, that can be accessed from anywhere in the world via HTTP or HTTPS. You can use Blob storage to expose data publicly to the world, or to store application data privately.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/media-services/encoding\">Azure Encoder</a>: Encoding jobs are one of the most common processing operations in Media Services. You create encoding jobs to convert media files from one encoding to another.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/media-services/live-on-demand\">Azure streaming endpoint</a>: A streaming service that can deliver content directly to a client player application, or to a content delivery network (CDN) for further distribution.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/cdn\">Content Delivery Network</a>: Provides secure, reliable content delivery with broad global reach and a rich feature set.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/media-services/media-player\">Azure Media Player</a>: Uses industry standards, such as HTML5 (MSE/EME), to provide a rich adaptive streaming experience. Regardless of the playback technology used, developers have a unified JavaScript interface to access APIs.</p>",
                "<p><a href=\"https://azure.microsoft.com/services/media-services/content-protection\">Multi-DRM content protection</a>: Delivers content securely using multi-DRM (PlayReady, Widevine, FairPlay Streaming) or AES clear key encryption</p>"
            ],
            "name": "digital-media-video",
            "popularity": 136,
            "topic": "Media"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "example-workload",
                "fcp",
                "github"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/dronerescue/vision-classifier-model-with-custom-vision.md",
            "http_url": "/azure/architecture/example-scenario/dronerescue/vision-classifier-model-with-custom-vision",
            "word_count": 479,
            "read_time": "2 min read",
            "Title": "Vision classifier model with Azure Custom Vision Cognitive Service",
            "MetaDescription": "Create an image classifier with a solution architecture that includes Microsoft AirSim Drone simulator and Azure Custom Vision Cognitive Service.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/example-scenario/dronerescue/media/drone-rescue.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\dronerescue\\media\\drone-rescue.png",
            "publish_date": "6/03/2020",
            "Summary": "<p>Azure Cognitive Services offers many possibilities for Artificial Intelligence (AI) solutions. One of them is <a href=\"https://learn.microsoft.com/azure/cognitive-services/custom-vision-service/\">Azure Custom Vision</a>, which allows you to build, deploy, and improve your image classifiers. This architecture uses Custom Vision to classify images taken by a simulated drone. It provides a way to combine AI and the Internet of Things (IoT).</p>",
            "sample_code": true,
            "github_url": "https://github.com/Microsoft/DroneRescue",
            "name": "vision-classifier-model-with-custom-vision",
            "popularity": 0,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "'https:--azure.microsoft.com-solutions-architecture-visual-assistant-'",
                "acom-architecture",
                "ai-ml",
                "all-items",
                "cognitive-services",
                "data-flow",
                "interactive-diagram",
                "solution-idea",
                "visual-assistant",
                "visual-assistant-scenarios",
                "visual-capabilities"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/visual-assistant.md",
            "http_url": "/azure/architecture/solution-ideas/articles/visual-assistant",
            "word_count": 127,
            "read_time": "1 min read",
            "Title": "Visual Assistant",
            "MetaDescription": "Visual assistant provides rich information based on content of the image with capabilities such as reading business card, identifying barcode, and recognizing popular people, places, objects, artworks, and monuments.",
            "category": [
                "ai-machine-learning"
            ],
            "image": "/azure/architecture/solution-ideas/media/visual-assistant.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\visual-assistant.png",
            "publish_date": "12/16/2019",
            "Summary": "<p>Visual assistant provides rich information based on content of the image with capabilities such as reading business card, identifying barcode, and recognizing popular people, places, objects, artworks, and monuments.</p>",
            "Flow": {
                "FlowStep_A": "Users interact with bot",
                "FlowStep_B": "Bot understands context from LUIS",
                "FlowStep_C": "Bot passes visual context to the Bing Visual Search API",
                "FlowStep_D": "Bot gets additional information from Bing Entity Search for rich context on people, place, artwork, monument, and objects.",
                "FlowStep_E": "Bot gets additional information for barcodes.",
                "FlowStep_F": "Optionally Bot gets more information on barcodes/queries exclusively from your domain through the Bing Custom Search API."
            },
            "name": "visual-assistant",
            "popularity": 12,
            "topic": "AI + Machine Learning"
        },
        {
            "tags": [
                "all-items",
                "data-flow",
                "solution-idea"
            ],
            "type": "solution-idea",
            "file_url": "solution-ideas/articles/front-end.md",
            "http_url": "/azure/architecture/solution-ideas/articles/front-end",
            "word_count": 234,
            "read_time": "2 min read",
            "Title": "Web and Mobile Front Ends",
            "MetaDescription": "This example scenario demonstrates how you can accelerate frontend and business process development with drag and drop visual designer.",
            "category": [
                "mobile",
                "web",
                "front"
            ],
            "image": "/azure/architecture/solution-ideas/media/front-end.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\solution-ideas\\media\\front-end.png",
            "publish_date": "8/24/2020",
            "Summary": "",
            "Flow": {
                "FlowStep_A": "Power Apps reads data from custom web APIs surfaced through Functions",
                "FlowStep_B": "Functions, upon calls from Power Automate, convert raw data into HTML",
                "FlowStep_C": "Power Automate reads and writes data from Azure Table Storage and retrieve data from 3rd party auditing system",
                "FlowStep_D": "Telemetry data is written to Azure Table Storage",
                "FlowStep_E": "Power Apps presents rich information across iOS, Android and web."
            },
            "name": "front-end",
            "popularity": 0,
            "topic": "Mobile"
        },
        {
            "tags": [
                "all-items",
                "alternative-choices",
                "azcat",
                "data-flow",
                "reference-architecture"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/app-service-web-app/app-monitoring.yml",
            "http_url": "/azure/architecture/reference-architectures/app-service-web-app/app-monitoring",
            "word_count": 1818,
            "read_time": "7 min read",
            "Title": "Web application monitoring on Azure",
            "MetaDescription": "Learn about the monitoring services and a dataflow model for use with multiple data sources. Many monitoring tools and services work with Azure deployments.",
            "category": [
                "web",
                "management-and-governance"
            ],
            "image": "/azure/architecture/reference-architectures/app-service-web-app/images/architecture-diagram-app-monitoring.svg",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\app-service-web-app\\images\\architecture-diagram-app-monitoring.svg",
            "publish_date": "12/12/2018",
            "alternative_choices": "alternatives",
            "components": [
                "<p><a href=\"https://learn.microsoft.com/azure/app-service/\">Azure App Service</a> is a PaaS service for building and hosting apps in managed virtual machines. The underlying compute infrastructures on which your apps run is managed for you. App Service provides monitoring of resource usage quotas and app metrics, logging of diagnostic information, and alerts based on metrics. Even better, you can use Application Insights to create <a href=\"https://learn.microsoft.com/azure/application-insights/app-insights-monitor-web-app-availability\">availability tests</a> for testing your application from different regions.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/application-insights/app-insights-overview\">Application Insights</a> is an extensible Application Performance Management (APM) service for developers and supports multiple platforms. It monitors the application, detects application anomalies such as poor performance and failures, and sends telemetry to the Azure portal. Application Insights can also be used for logging, distributed tracing, and custom application metrics.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/monitoring-and-diagnostics/monitoring-overview-azure-monitor\">Azure Monitor</a> provides base-level infrastructure <a href=\"https://learn.microsoft.com/azure/monitoring-and-diagnostics/monitoring-supported-metrics\">metrics and logs</a> for most services in Azure. You can interact with the metrics in several ways, including charting them in Azure portal, accessing them through the REST API, or querying them using PowerShell or CLI. Azure Monitor also offers its data directly into <a href=\"https://learn.microsoft.com/azure/log-analytics/log-analytics-azure-storage\">Log Analytics and other services</a>, where you can query and combine it with data from other sources on premises or in the cloud.</p>",
                "<p><a href=\"https://learn.microsoft.com/azure/log-analytics/log-analytics-overview\">Log Analytics</a> helps correlate the usage and performance data collected by Application Insights with configuration and performance data across the Azure resources that support the app. This scenario uses the <a href=\"https://learn.microsoft.com/archive/blogs/sqlsecurity/azure-log-analytics-oms-agent-now-collects-sql-server-audit-logs\">Azure Log Analytics agent</a> to push SQL Server audit logs into Log Analytics. You can write queries and view data in the Log Analytics blade of the Azure portal.</p>"
            ],
            "Summary": "<p>Azure platform as a service (PaaS) offerings manage compute resources for you and affect how you monitor deployments. Azure includes multiple monitoring services, each of which performs a specific role. Together, these services deliver a comprehensive solution for collecting, analyzing, and acting on telemetry from your applications and the Azure resources they consume.</p>\n<p>This scenario addresses the monitoring services you can use and describes a dataflow model for use with multiple data sources. When it comes to monitoring, many tools and services work with Azure deployments. In this scenario, we choose readily available services precisely because they are easy to consume. Other monitoring options are discussed later in this article.</p>",
            "Flow": {
                "FlowStep_A": "A user interacts with the application.",
                "FlowStep_B": "The browser and app service emit telemetry.",
                "FlowStep_C": "Application Insights collects and analyzes application health, performance, and usage data.",
                "FlowStep_D": "Developers and administrators can review health, performance, and usage information.",
                "FlowStep_E": "Azure SQL Database emits telemetry.",
                "FlowStep_F": "Azure Monitor collects and analyzes infrastructure metrics and quotas.",
                "FlowStep_G": "Log Analytics collects and analyzes logs and metrics.",
                "FlowStep_H": "Developers and administrators can review health, performance, and usage information."
            },
            "name": "app-monitoring",
            "popularity": 215,
            "topic": "Web"
        },
        {
            "tags": [
                "all-items",
                "bash",
                "example-code",
                "github",
                "reference-architecture",
                "visio-diagram"
            ],
            "type": "reference-architecture",
            "file_url": "reference-architectures/n-tier/n-tier-sql-server.yml",
            "http_url": "/azure/architecture/reference-architectures/n-tier/n-tier-sql-server",
            "word_count": 3386,
            "read_time": "13 min read",
            "Title": "Windows N-tier application on Azure",
            "MetaDescription": "Implement a multi-tier architecture on Azure for availability, security, scalability, and manageability.",
            "category": [
                "databases",
                "web",
                "management-and-governance"
            ],
            "image": "/azure/architecture/reference-architectures/n-tier/images/n-tier-sql-server.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\reference-architectures\\n-tier\\images\\n-tier-sql-server.png",
            "publish_date": "9/25/2020",
            "sample_code": true,
            "github_url": "https://github.com/mspnp/reference-architectures/tree/master/virtual-machines/n-tier-windows",
            "visio_diagram": "https://arch-center.azureedge.net/vm-reference-architectures.vsdx",
            "code_languages": [
                "bash"
            ],
            "name": "n-tier-sql-server",
            "popularity": 218,
            "topic": "Databases"
        },
        {
            "tags": [
                "all-items",
                "example-code",
                "example-workload",
                "fcp",
                "github",
                "pricing-guidance"
            ],
            "type": "example-workload",
            "file_url": "example-scenario/wvd/windows-virtual-desktop.md",
            "http_url": "/azure/architecture/example-scenario/wvd/windows-virtual-desktop",
            "word_count": 1829,
            "read_time": "8 min read",
            "Title": "Azure Virtual Desktop for the enterprise",
            "MetaDescription": "Explore Azure Virtual Desktop, and learn to build virtual desktop infrastructure solutions at enterprise scale.",
            "category": [
                "windows-virtual-desktop"
            ],
            "image": "/azure/architecture/example-scenario/wvd/images/windows-virtual-desktop.png",
            "imagepath": "C:\\jvPnpRepos\\architecture-center-pr\\docs\\example-scenario\\wvd\\images\\windows-virtual-desktop.png",
            "publish_date": "7/16/2020",
            "pricing_guidance": "pricing",
            "Summary": "<p><a href=\"https://azure.microsoft.com/services/virtual-desktop/\">Azure Virtual Desktop</a> is a desktop and application virtualization service that runs in the Azure cloud. This article helps Desktop Infrastructure Architects, Cloud Architects, Desktop Administrators, or System Administrators explore Azure Virtual Desktop and build virtualized desktop infrastructure (VDI) solutions at enterprise scale. Enterprise-scale solutions generally cover 1,000 virtual desktops and above.</p>",
            "sample_code": true,
            "github_url": "https://github.com/Azure/RDS-Templates/tree/master/ARM-wvd-templates",
            "name": "windows-virtual-desktop",
            "popularity": 0,
            "topic": "Azure Virtual Desktop"
        }
    ]
}